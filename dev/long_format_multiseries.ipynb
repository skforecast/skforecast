{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import psutil\n",
    "import skforecast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from skforecast.recursive import ForecasterRecursiveMultiSeries\n",
    "from skforecast.model_selection import grid_search_forecaster_multiseries\n",
    "from skforecast.utils.utils import align_series_and_exog_multiseries\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from skforecast.preprocessing import series_long_to_dict\n",
    "from skforecast.preprocessing import exog_long_to_dict\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.utils import check_preprocess_series\n",
    "\n",
    "\n",
    "%load_ext pyinstrument\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('series_id', 'datetime')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "value",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "a9f502af-1354-4357-b0bd-b2730a3c8df1",
       "rows": [
        [
         "('series_1', Timestamp('2023-01-01 00:00:00'))",
         "55"
        ],
        [
         "('series_1', Timestamp('2023-01-02 00:00:00'))",
         "70"
        ],
        [
         "('series_1', Timestamp('2023-01-03 00:00:00'))",
         "96"
        ],
        [
         "('series_1', Timestamp('2023-01-04 00:00:00'))",
         "57"
        ],
        [
         "('series_1', Timestamp('2023-01-05 00:00:00'))",
         "49"
        ],
        [
         "('series_1', Timestamp('2023-01-06 00:00:00'))",
         "79"
        ],
        [
         "('series_1', Timestamp('2023-01-07 00:00:00'))",
         "84"
        ],
        [
         "('series_1', Timestamp('2023-01-08 00:00:00'))",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-01-09 00:00:00'))",
         "54"
        ],
        [
         "('series_1', Timestamp('2023-01-10 00:00:00'))",
         "73"
        ],
        [
         "('series_1', Timestamp('2023-01-11 00:00:00'))",
         "6"
        ],
        [
         "('series_1', Timestamp('2023-01-12 00:00:00'))",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-13 00:00:00'))",
         "64"
        ],
        [
         "('series_1', Timestamp('2023-01-14 00:00:00'))",
         "71"
        ],
        [
         "('series_1', Timestamp('2023-01-15 00:00:00'))",
         "83"
        ],
        [
         "('series_1', Timestamp('2023-01-16 00:00:00'))",
         "66"
        ],
        [
         "('series_1', Timestamp('2023-01-17 00:00:00'))",
         "53"
        ],
        [
         "('series_1', Timestamp('2023-01-18 00:00:00'))",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-19 00:00:00'))",
         "57"
        ],
        [
         "('series_1', Timestamp('2023-01-20 00:00:00'))",
         "23"
        ],
        [
         "('series_1', Timestamp('2023-01-21 00:00:00'))",
         "47"
        ],
        [
         "('series_1', Timestamp('2023-01-22 00:00:00'))",
         "51"
        ],
        [
         "('series_1', Timestamp('2023-01-23 00:00:00'))",
         "40"
        ],
        [
         "('series_1', Timestamp('2023-01-24 00:00:00'))",
         "62"
        ],
        [
         "('series_1', Timestamp('2023-01-25 00:00:00'))",
         "76"
        ],
        [
         "('series_1', Timestamp('2023-01-26 00:00:00'))",
         "83"
        ],
        [
         "('series_1', Timestamp('2023-01-27 00:00:00'))",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-01-28 00:00:00'))",
         "79"
        ],
        [
         "('series_1', Timestamp('2023-01-29 00:00:00'))",
         "52"
        ],
        [
         "('series_1', Timestamp('2023-01-30 00:00:00'))",
         "87"
        ],
        [
         "('series_1', Timestamp('2023-01-31 00:00:00'))",
         "17"
        ],
        [
         "('series_1', Timestamp('2023-02-01 00:00:00'))",
         "11"
        ],
        [
         "('series_1', Timestamp('2023-02-02 00:00:00'))",
         "73"
        ],
        [
         "('series_1', Timestamp('2023-02-03 00:00:00'))",
         "19"
        ],
        [
         "('series_1', Timestamp('2023-02-04 00:00:00'))",
         "46"
        ],
        [
         "('series_1', Timestamp('2023-02-05 00:00:00'))",
         "57"
        ],
        [
         "('series_1', Timestamp('2023-02-06 00:00:00'))",
         "25"
        ],
        [
         "('series_1', Timestamp('2023-02-07 00:00:00'))",
         "43"
        ],
        [
         "('series_1', Timestamp('2023-02-08 00:00:00'))",
         "34"
        ],
        [
         "('series_1', Timestamp('2023-02-09 00:00:00'))",
         "88"
        ],
        [
         "('series_1', Timestamp('2023-02-10 00:00:00'))",
         "43"
        ],
        [
         "('series_1', Timestamp('2023-02-11 00:00:00'))",
         "53"
        ],
        [
         "('series_1', Timestamp('2023-02-12 00:00:00'))",
         "91"
        ],
        [
         "('series_1', Timestamp('2023-02-13 00:00:00'))",
         "39"
        ],
        [
         "('series_1', Timestamp('2023-02-14 00:00:00'))",
         "55"
        ],
        [
         "('series_1', Timestamp('2023-02-15 00:00:00'))",
         "78"
        ],
        [
         "('series_1', Timestamp('2023-02-16 00:00:00'))",
         "89"
        ],
        [
         "('series_1', Timestamp('2023-02-17 00:00:00'))",
         "15"
        ],
        [
         "('series_1', Timestamp('2023-02-18 00:00:00'))",
         "51"
        ],
        [
         "('series_1', Timestamp('2023-02-19 00:00:00'))",
         "27"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4995000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">series_1</th>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">series_999</th>\n",
       "      <th>2036-09-04</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-05</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-06</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-07</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-08</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4995000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       value\n",
       "series_id  datetime         \n",
       "series_1   2023-01-01     55\n",
       "           2023-01-02     70\n",
       "           2023-01-03     96\n",
       "           2023-01-04     57\n",
       "           2023-01-05     49\n",
       "...                      ...\n",
       "series_999 2036-09-04     35\n",
       "           2036-09-05      9\n",
       "           2036-09-06     86\n",
       "           2036-09-07     51\n",
       "           2036-09-08      5\n",
       "\n",
       "[4995000 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('series_id', 'datetime')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "exog_1",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "exog_2",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "exog_3",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "exog_4",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "exog_5",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "exog_6",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "f22f51ae-5bf8-4d12-a626-8cdc644575a1",
       "rows": [
        [
         "('series_1', Timestamp('2023-01-01 00:00:00'))",
         "3",
         "9",
         "1",
         "5",
         "5",
         "9"
        ],
        [
         "('series_1', Timestamp('2023-01-02 00:00:00'))",
         "8",
         "9",
         "9",
         "4",
         "3",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-03 00:00:00'))",
         "6",
         "5",
         "8",
         "3",
         "1",
         "9"
        ],
        [
         "('series_1', Timestamp('2023-01-04 00:00:00'))",
         "1",
         "3",
         "8",
         "9",
         "3",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-01-05 00:00:00'))",
         "8",
         "5",
         "9",
         "3",
         "6",
         "9"
        ],
        [
         "('series_1', Timestamp('2023-01-06 00:00:00'))",
         "1",
         "4",
         "8",
         "8",
         "6",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-01-07 00:00:00'))",
         "8",
         "5",
         "2",
         "9",
         "4",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-01-08 00:00:00'))",
         "1",
         "7",
         "3",
         "3",
         "5",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-01-09 00:00:00'))",
         "7",
         "2",
         "9",
         "9",
         "6",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-10 00:00:00'))",
         "2",
         "5",
         "4",
         "5",
         "4",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-11 00:00:00'))",
         "7",
         "4",
         "5",
         "4",
         "8",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-01-12 00:00:00'))",
         "8",
         "3",
         "4",
         "3",
         "6",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-13 00:00:00'))",
         "8",
         "3",
         "9",
         "3",
         "2",
         "9"
        ],
        [
         "('series_1', Timestamp('2023-01-14 00:00:00'))",
         "8",
         "8",
         "5",
         "5",
         "3",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-15 00:00:00'))",
         "1",
         "9",
         "8",
         "8",
         "1",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-16 00:00:00'))",
         "3",
         "9",
         "7",
         "8",
         "1",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-01-17 00:00:00'))",
         "5",
         "2",
         "1",
         "4",
         "8",
         "9"
        ],
        [
         "('series_1', Timestamp('2023-01-18 00:00:00'))",
         "9",
         "4",
         "7",
         "5",
         "2",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-01-19 00:00:00'))",
         "1",
         "7",
         "7",
         "8",
         "5",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-20 00:00:00'))",
         "4",
         "8",
         "5",
         "9",
         "9",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-01-21 00:00:00'))",
         "2",
         "9",
         "1",
         "3",
         "6",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-22 00:00:00'))",
         "8",
         "3",
         "8",
         "1",
         "4",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-23 00:00:00'))",
         "9",
         "4",
         "1",
         "4",
         "7",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-01-24 00:00:00'))",
         "7",
         "6",
         "1",
         "5",
         "8",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-25 00:00:00'))",
         "7",
         "7",
         "5",
         "4",
         "6",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-01-26 00:00:00'))",
         "9",
         "4",
         "7",
         "6",
         "6",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-01-27 00:00:00'))",
         "6",
         "2",
         "3",
         "4",
         "4",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-01-28 00:00:00'))",
         "7",
         "5",
         "2",
         "6",
         "3",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-01-29 00:00:00'))",
         "5",
         "1",
         "1",
         "1",
         "3",
         "6"
        ],
        [
         "('series_1', Timestamp('2023-01-30 00:00:00'))",
         "4",
         "8",
         "2",
         "4",
         "5",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-01-31 00:00:00'))",
         "5",
         "1",
         "3",
         "6",
         "3",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-02-01 00:00:00'))",
         "3",
         "6",
         "9",
         "2",
         "7",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-02-02 00:00:00'))",
         "2",
         "9",
         "9",
         "3",
         "1",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-02-03 00:00:00'))",
         "6",
         "1",
         "1",
         "1",
         "6",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-02-04 00:00:00'))",
         "6",
         "2",
         "1",
         "9",
         "4",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-02-05 00:00:00'))",
         "6",
         "7",
         "6",
         "4",
         "6",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-02-06 00:00:00'))",
         "7",
         "4",
         "4",
         "3",
         "5",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-02-07 00:00:00'))",
         "4",
         "6",
         "2",
         "2",
         "4",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-02-08 00:00:00'))",
         "6",
         "9",
         "8",
         "8",
         "9",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-02-09 00:00:00'))",
         "5",
         "9",
         "9",
         "5",
         "3",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-02-10 00:00:00'))",
         "4",
         "8",
         "4",
         "7",
         "5",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-02-11 00:00:00'))",
         "1",
         "5",
         "1",
         "4",
         "8",
         "6"
        ],
        [
         "('series_1', Timestamp('2023-02-12 00:00:00'))",
         "5",
         "8",
         "5",
         "8",
         "5",
         "9"
        ],
        [
         "('series_1', Timestamp('2023-02-13 00:00:00'))",
         "1",
         "6",
         "6",
         "7",
         "7",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-02-14 00:00:00'))",
         "6",
         "8",
         "2",
         "3",
         "2",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-02-15 00:00:00'))",
         "4",
         "6",
         "6",
         "1",
         "7",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-02-16 00:00:00'))",
         "6",
         "7",
         "4",
         "8",
         "4",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-02-17 00:00:00'))",
         "2",
         "8",
         "4",
         "2",
         "4",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-02-18 00:00:00'))",
         "4",
         "2",
         "3",
         "3",
         "1",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-02-19 00:00:00'))",
         "9",
         "8",
         "7",
         "5",
         "2",
         "2"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 4995000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>exog_1</th>\n",
       "      <th>exog_2</th>\n",
       "      <th>exog_3</th>\n",
       "      <th>exog_4</th>\n",
       "      <th>exog_5</th>\n",
       "      <th>exog_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">series_1</th>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">series_999</th>\n",
       "      <th>2036-09-04</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-05</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-06</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-07</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-08</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4995000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       exog_1  exog_2  exog_3  exog_4  exog_5  exog_6\n",
       "series_id  datetime                                                  \n",
       "series_1   2023-01-01       3       9       1       5       5       9\n",
       "           2023-01-02       8       9       9       4       3       3\n",
       "           2023-01-03       6       5       8       3       1       9\n",
       "           2023-01-04       1       3       8       9       3       2\n",
       "           2023-01-05       8       5       9       3       6       9\n",
       "...                       ...     ...     ...     ...     ...     ...\n",
       "series_999 2036-09-04       1       3       1       1       8       6\n",
       "           2036-09-05       9       3       6       7       9       3\n",
       "           2036-09-06       3       1       1       5       5       3\n",
       "           2036-09-07       4       1       7       3       6       9\n",
       "           2036-09-08       5       3       2       9       8       2\n",
       "\n",
       "[4995000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5000\n",
    "n_series = 1000\n",
    "series = pd.DataFrame(\n",
    "    {f\"series_{i}\": np.random.randint(1, 100, n) for i in range(1, n_series)\n",
    "    },\n",
    "    index=pd.date_range(start=\"2023-01-01\", periods=n, freq=\"D\"),\n",
    ")\n",
    "\n",
    "freq = series.index.freq\n",
    "series.index.name = \"datetime\"\n",
    "series = series.reset_index()\n",
    "series = pd.melt(series, id_vars=\"datetime\", var_name=\"series_id\", value_name=\"value\")\n",
    "series = series.groupby(\"series_id\").apply(\n",
    "    lambda x: x.set_index(\"datetime\").asfreq(\"D\"), include_groups=False\n",
    ")\n",
    "display(series)\n",
    "\n",
    "exog = pd.DataFrame(\n",
    "    {\n",
    "        \"exog_1\": np.random.randint(1, 10, n),\n",
    "        \"exog_2\": np.random.randint(1, 10, n),\n",
    "        \"exog_3\": np.random.randint(1, 10, n),\n",
    "        \"exog_4\": np.random.randint(1, 10, n),\n",
    "        \"exog_5\": np.random.randint(1, 10, n),\n",
    "        \"exog_6\": np.random.randint(1, 10, n),\n",
    "    },\n",
    "    index=pd.date_range(start=\"2023-01-01\", periods=n, freq=\"D\"),\n",
    ")\n",
    "exog.index.name= \"datetime\"\n",
    "exog = [exog.assign(series_id=f\"series_{i}\") for i in range(1, n_series)]\n",
    "# exog = [exog_i.copy().sample(frac=0.8).sort_index() for exog_i in exog]\n",
    "exog = pd.concat(exog)\n",
    "exog = exog.set_index([\"series_id\", exog.index])\n",
    "display(exog)\n",
    "\n",
    "# Formato dict\n",
    "series_dict = {\n",
    "    sid: series.loc[sid]['value'] for sid in series.index.levels[0]\n",
    "}\n",
    "\n",
    "exog_dict = {\n",
    "    sid: exog.loc[sid]for sid in exog.index.levels[0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343 Î¼s Â± 18.3 Î¼s per loop (mean Â± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "l = []\n",
    "for v in series_dict.values():\n",
    "    l.append(v.index.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 ms Â± 24.8 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "l = set()\n",
    "series_names_in_ = series.index.levels[0].to_list()\n",
    "for series_id in series_names_in_:\n",
    "    l.add(series.loc[series_id].index.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 ms Â± 6.05 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "l = set()\n",
    "series_names_in_ = series.index.levels[0].to_list()\n",
    "for series_id in series_names_in_:\n",
    "    l.add(series.xs(series_id).index.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644.3148688046647"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "221000/343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 Î¼s Â± 30.7 Î¼s per loop (mean Â± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "series.xs('series_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 Î¼s Â± 15.3 Î¼s per loop (mean Â± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "series.loc['series_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimedeltaIndex([NaT, '1 days', '-4999 days'], dtype='timedelta64[ns]', name='datetime', freq=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "l = []\n",
    "for v in series_dict.values():\n",
    "    l.append(v.index.freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cf9c71bd-ec97-4805-8420-9898176c4bb1",
       "rows": [],
       "shape": {
        "columns": 0,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_por_serie = series.groupby(level='series_id').apply(\n",
    "    lambda x: x.index.get_level_values('datetime').freqstr\n",
    ")\n",
    "freq_por_serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "series = pd.DataFrame(\n",
    "    {f\"series_{i}\": np.random.randint(1, 100, n) for i in range(1, 100)\n",
    "    },\n",
    "    index=pd.date_range(start=\"2023-01-01\", periods=n, freq=\"D\"),\n",
    ")\n",
    "\n",
    "freq = series.index.freq\n",
    "series.index.name = \"datetime\"\n",
    "series = series.reset_index()\n",
    "series = pd.melt(series, id_vars=\"datetime\", var_name=\"series_id\", value_name=\"value\")\n",
    "series = series.groupby(\"series_id\").apply(\n",
    "    lambda x: x.set_index(\"datetime\").asfreq(\"D\"), include_groups=False\n",
    ")\n",
    "\n",
    "# Delete one random row\n",
    "# sample_idx = series.sample(1).index\n",
    "# print(sample_idx)\n",
    "# series = series.drop(sample_idx)\n",
    "# series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_train = series.loc[series.index.get_level_values('datetime') < '2023-01-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n",
       "               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n",
       "               '2023-01-09', '2023-01-10', '2023-01-11', '2023-01-12',\n",
       "               '2023-01-13', '2023-01-14', '2023-01-15', '2023-01-16',\n",
       "               '2023-01-17', '2023-01-18', '2023-01-19'],\n",
       "              dtype='datetime64[ns]', name='datetime', freq='D')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_train.loc['series_1'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n",
       "               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n",
       "               '2023-01-09', '2023-01-10',\n",
       "               ...\n",
       "               '2036-08-30', '2036-08-31', '2036-09-01', '2036-09-02',\n",
       "               '2036-09-03', '2036-09-04', '2036-09-05', '2036-09-06',\n",
       "               '2036-09-07', '2036-09-08'],\n",
       "              dtype='datetime64[ns]', name='datetime', length=5000, freq=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = []\n",
    "\n",
    "for sid, group in series:\n",
    "    if int(sid[-1]) % 2 == 0:\n",
    "        group = group.set_index(\"datetime\").asfreq(\"D\")\n",
    "    else:\n",
    "        group = group.set_index(\"datetime\").asfreq(\"ME\")\n",
    "    group['series_id'] = sid  # Mantener columna identificadora si se pierde\n",
    "    resultados.append(group)\n",
    "\n",
    "series_final = pd.concat(resultados)\n",
    "series_final.query('series_id == \"series_2\"').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_1 = series.index.levels[1] \n",
    "option_2 = pd.date_range(start=series.index.get_level_values('datetime').min(),\n",
    "                        end=series.index.get_level_values('datetime').max(),\n",
    "                        freq=None)\n",
    "\n",
    "assert option_1.equals(option_2), \"Los Ã­ndices de las series no son iguales a la fecha de inicio y fin de las series.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serie A frecuencia: None\n",
      "Serie B frecuencia: None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dos series con distinta frecuencia\n",
    "df1 = pd.DataFrame({\n",
    "    'series_id': 'A',\n",
    "    'datetime': pd.date_range('2023-01-01', periods=5, freq='D'),\n",
    "    'value': np.random.randn(5)\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'series_id': 'B',\n",
    "    'datetime': pd.date_range('2023-01-01', periods=5, freq='ME'),\n",
    "    'value': np.random.randn(5)\n",
    "})\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "df = df.set_index(['series_id', 'datetime'])\n",
    "\n",
    "# Obtener la frecuencia de cada grupo\n",
    "for serie, grupo in df.groupby(level=0):\n",
    "    freq = grupo.index.get_level_values('datetime').freqstr\n",
    "    print(f\"Serie {serie} frecuencia: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimedeltaIndex([         NaT,    '28 days',    '31 days',    '30 days',\n",
       "                   '29 days', '-4991 days',     '1 days', '-4969 days',\n",
       "                '-4999 days', '-4961 days'],\n",
       "               dtype='timedelta64[ns]', name='datetime', freq=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.index.get_level_values('datetime').diff().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimedeltaArray>\n",
       "[NaT, '28 days', '31 days', '30 days', '29 days', '1 days']\n",
       "Length: 6, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_1 = series.index.get_level_values('datetime')\n",
    "index_0 = series.index.get_level_values('series_id')\n",
    "\n",
    "index_1.to_series().groupby(index_0).diff().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterRecursiveMultiSeries(regressor=LGBMRegressor(), lags=5, transformer_exog=StandardScaler())\n",
    "forecaster.transformer_series_ = {k: StandardScaler() for k in series.index.get_level_values(0).unique()}\n",
    "forecaster.differentiator_ = {k: None for k in series.index.get_level_values(0).unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from skforecast.exceptions import MissingValuesWarning\n",
    "\n",
    "warnings.simplefilter('ignore', category=MissingValuesWarning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 5 -n 5\n",
    "# _ = forecaster._create_train_X_y(\n",
    "#     series = series,\n",
    "#     exog=exog\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 ms Â± 9.64 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 5 -n 5\n",
    "_ = forecaster._create_train_X_y_v2(\n",
    "    series = series,\n",
    "    exog=exog\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m _ = \u001b[43mforecaster\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_train_X_y_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexog\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:107\u001b[39m, in \u001b[36m_create_train_X_y_v2\u001b[39m\u001b[34m(self, series, exog, store_last_window)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\recursive\\_forecaster_recursive_multiseries.py:886\u001b[39m, in \u001b[36mForecasterRecursiveMultiSeries._create_train_X_y_single_series\u001b[39m\u001b[34m(self, y, ignore_exog, exog)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    885\u001b[39m     fit_transformer = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_fitted \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m     transformer_series = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer_series_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseries_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    888\u001b[39m y_values = y.to_numpy()\n\u001b[32m    889\u001b[39m y_index = y.index\n",
      "\u001b[31mKeyError\u001b[39m: 'value'"
     ]
    }
   ],
   "source": [
    "_ = forecaster._create_train_X_y_v2(\n",
    "                            series = series,\n",
    "                            exog=exog\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,   5000,  10000,  15000,  20000,  25000,  30000,  35000,\n",
       "        40000,  45000,  50000,  55000,  60000,  65000,  70000,  75000,\n",
       "        80000,  85000,  90000,  95000, 100000, 105000, 110000, 115000,\n",
       "       120000, 125000, 130000, 135000, 140000, 145000, 150000, 155000,\n",
       "       160000, 165000, 170000, 175000, 180000, 185000, 190000, 195000,\n",
       "       200000, 205000, 210000, 215000, 220000, 225000, 230000, 235000,\n",
       "       240000, 245000, 250000, 255000, 260000, 265000, 270000, 275000,\n",
       "       280000, 285000, 290000, 295000, 300000, 305000, 310000, 315000,\n",
       "       320000, 325000, 330000, 335000, 340000, 345000, 350000, 355000,\n",
       "       360000, 365000, 370000, 375000, 380000, 385000, 390000, 395000,\n",
       "       400000, 405000, 410000, 415000, 420000, 425000, 430000, 435000,\n",
       "       440000, 445000, 450000, 455000, 460000, 465000, 470000, 475000,\n",
       "       480000, 485000, 490000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_level_0 = series.index.get_level_values(0)\n",
    "unique_series = series_level_0.unique()\n",
    "\n",
    "# Opcional: crea un buffer de posiciones de inicio/fin para cada serie\n",
    "idx_start = series_level_0.searchsorted(unique_series, side='left')\n",
    "idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.66638 s\n",
      "File: c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\recursive\\_forecaster_recursive_multiseries.py\n",
      "Function: _create_train_X_y_v2 at line 1272\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1272                                               def _create_train_X_y_v2(\n",
      "  1273                                                   self,\n",
      "  1274                                                   series: pd.DataFrame,\n",
      "  1275                                                   exog: pd.Series | pd.DataFrame | None = None,\n",
      "  1276                                                   store_last_window: bool | list[str] = True,\n",
      "  1277                                               ) -> tuple[\n",
      "  1278                                                   pd.DataFrame,\n",
      "  1279                                                   pd.Series,\n",
      "  1280                                                   dict[str, pd.Index],\n",
      "  1281                                                   list[str],\n",
      "  1282                                                   list[str],\n",
      "  1283                                                   list[str],\n",
      "  1284                                                   list[str],\n",
      "  1285                                                   list[str],\n",
      "  1286                                                   dict[str, type],\n",
      "  1287                                                   dict[str, pd.Series],\n",
      "  1288                                               ]:\n",
      "  1289                                                   \"\"\"\n",
      "  1290                                                   Create training matrices from multiple time series and exogenous\n",
      "  1291                                                   variables.\n",
      "  1292                                                   \n",
      "  1293                                                   Parameters\n",
      "  1294                                                   ----------\n",
      "  1295                                                   series : pandas DataFrame\n",
      "  1296                                                       Pandas DataFrame with the time series to be used for training. Two \n",
      "  1297                                                       formats are accepted:\n",
      "  1298                                           \n",
      "  1299                                                       - Wide format: pandas DataFrame where each column is a time series\n",
      "  1300                                                       (level). The same index is shared by all series and it must be a\n",
      "  1301                                                       pandas DatetimeIndex with a frequency. \n",
      "  1302                                                       - Long format: pandas DataFrame with two level multi-index. The first\n",
      "  1303                                                       level is the series name and the second level is the datetime index.\n",
      "  1304                                                       The datetime index must be a pandas DatetimeIndex with a frequency. And\n",
      "  1305                                                       all series must have the same frequency.\n",
      "  1306                                                   exog : pandas Series, pandas DataFrame default None\n",
      "  1307                                                       Exogenous variable/s included as predictor/s. Two formats are accepted:\n",
      "  1308                                           \n",
      "  1309                                                       - Same exog for all series: pandas Series or DataFrame with a single\n",
      "  1310                                                       DatetimeIndex. Same exog values are used for all series.\n",
      "  1311                                                       - Different exog for each series: a pandas DataFrame with a\n",
      "  1312                                                       multi-index where the first level is the series name and the second\n",
      "  1313                                                       level is the datetime index. The datetime index must be a pandas\n",
      "  1314                                                       DatetimeIndex.\n",
      "  1315                                                   store_last_window : bool, list, default True\n",
      "  1316                                                       Whether or not to store the last window (`last_window_`) of training data.\n",
      "  1317                                           \n",
      "  1318                                                       - If `True`, last window is stored for all series. \n",
      "  1319                                                       - If `list`, last window is stored for the series present in the list.\n",
      "  1320                                                       - If `False`, last window is not stored.\n",
      "  1321                                           \n",
      "  1322                                                   Returns\n",
      "  1323                                                   -------\n",
      "  1324                                                   X_train : pandas DataFrame\n",
      "  1325                                                       Training values (predictors).\n",
      "  1326                                                   y_train : pandas Series\n",
      "  1327                                                       Values of the time series related to each row of `X_train`.\n",
      "  1328                                                   series_indexes : dict\n",
      "  1329                                                       Dictionary with the index of each series.\n",
      "  1330                                                   series_names_in_ : list\n",
      "  1331                                                       Names of the series (levels) provided by the user during training.\n",
      "  1332                                                   X_train_series_names_in_ : list\n",
      "  1333                                                       Names of the series (levels) included in the matrix `X_train` created\n",
      "  1334                                                       internally for training. It can be different from `series_names_in_` if\n",
      "  1335                                                       some series are dropped during the training process because of NaNs or\n",
      "  1336                                                       because they are not present in the training period.\n",
      "  1337                                                   exog_names_in_ : list\n",
      "  1338                                                       Names of the exogenous variables used during training.\n",
      "  1339                                                   X_train_window_features_names_out_ : list\n",
      "  1340                                                       Names of the window features included in the matrix `X_train` created\n",
      "  1341                                                       internally for training.\n",
      "  1342                                                   X_train_exog_names_out_ : list\n",
      "  1343                                                       Names of the exogenous variables included in the matrix `X_train` created\n",
      "  1344                                                       internally for training. It can be different from `exog_names_in_` if\n",
      "  1345                                                       some exogenous variables are transformed during the training process.\n",
      "  1346                                                   exog_dtypes_in_ : dict\n",
      "  1347                                                       Type of each exogenous variable/s used in training. If `transformer_exog` \n",
      "  1348                                                       is used, the dtypes are calculated before the transformation.\n",
      "  1349                                                   last_window_ : dict\n",
      "  1350                                                       Last window of training data for each series. It stores the values \n",
      "  1351                                                       needed to predict the next `step` immediately after the training data.\n",
      "  1352                                                   \n",
      "  1353                                                   \"\"\"\n",
      "  1354                                           \n",
      "  1355         1       2672.0   2672.0      0.0          series = check_preprocess_series(series=series)\n",
      "  1356                                                   # TODO: do we care about the order?\n",
      "  1357         1        738.0    738.0      0.0          series_names_in_ = series.index.levels[0].to_list()\n",
      "  1358                                           \n",
      "  1359         1         29.0     29.0      0.0          if self.is_fitted and not set(series_names_in_).issubset(set(self.series_names_in_)):\n",
      "  1360                                                       raise ValueError(\n",
      "  1361                                                           f\"Once the Forecaster has been trained, `series` must contain \"\n",
      "  1362                                                           f\"the same series names as those used during training:\\n\"\n",
      "  1363                                                           f\" Got      : {series_names_in_}\\n\"\n",
      "  1364                                                           f\" Expected : {self.series_names_in_}\"\n",
      "  1365                                                       )\n",
      "  1366                                           \n",
      "  1367         1         13.0     13.0      0.0          exog_names_in_ = None\n",
      "  1368         1          7.0      7.0      0.0          X_train_exog_names_out_ = None\n",
      "  1369         1         12.0     12.0      0.0          if exog is not None:\n",
      "  1370         2      53793.0  26896.5      0.8              exog, exog_names_in_ = check_preprocess_exog_multiseries(\n",
      "  1371         1         14.0     14.0      0.0                                          series_indexes       = series.index,\n",
      "  1372         1          3.0      3.0      0.0                                          series_names_in_     = series_names_in_,\n",
      "  1373         1          2.0      2.0      0.0                                          exog                 = exog,\n",
      "  1374                                                                               )\n",
      "  1375                                           \n",
      "  1376         1         29.0     29.0      0.0              if self.is_fitted:\n",
      "  1377                                                           if self.exog_names_in_ is None:\n",
      "  1378                                                               raise ValueError(\n",
      "  1379                                                                   \"Once the Forecaster has been trained, `exog` must be `None` \"\n",
      "  1380                                                                   \"because no exogenous variables were added during training.\"\n",
      "  1381                                                               )\n",
      "  1382                                                           else:\n",
      "  1383                                                               if not set(exog_names_in_) == set(self.exog_names_in_):\n",
      "  1384                                                                   raise ValueError(\n",
      "  1385                                                                       f\"Once the Forecaster has been trained, `exog` must contain \"\n",
      "  1386                                                                       f\"the same exogenous variables as those used during training:\\n\"\n",
      "  1387                                                                       f\" Got      : {exog_names_in_}\\n\"\n",
      "  1388                                                                       f\" Expected : {self.exog_names_in_}\"\n",
      "  1389                                                                   )\n",
      "  1390                                                       \n",
      "  1391                                                       # TODO: para que esto funcione el indice debe llamarse igual, por ejemplo, \"datetime\"\n",
      "  1392         1     694979.0 694979.0     10.4              series = pd.merge(series, exog, left_index=True, right_index=True, how='left')\n",
      "  1393                                           \n",
      "  1394         1         31.0     31.0      0.0          if not self.is_fitted:\n",
      "  1395         2        807.0    403.5      0.0              self.transformer_series_ = initialize_transformer_series(\n",
      "  1396         1         32.0     32.0      0.0                                             forecaster_name    = type(self).__name__,\n",
      "  1397         1          4.0      4.0      0.0                                             series_names_in_   = series_names_in_,\n",
      "  1398         1         19.0     19.0      0.0                                             encoding           = self.encoding,\n",
      "  1399         1         17.0     17.0      0.0                                             transformer_series = self.transformer_series\n",
      "  1400                                                                                  )\n",
      "  1401                                                       \n",
      "  1402         2        317.0    158.5      0.0              self.differentiator_ = initialize_differentiator_multiseries(\n",
      "  1403         1          5.0      5.0      0.0                                         series_names_in_ = series_names_in_,\n",
      "  1404         1          6.0      6.0      0.0                                         differentiator   = self.differentiator\n",
      "  1405                                                                              )\n",
      "  1406                                           \n",
      "  1407                                                   # TODO: ignore_exog is not needed anymore\n",
      "  1408         1          4.0      4.0      0.0          ignore_exog = True if exog is None else False\n",
      "  1409                                           \n",
      "  1410                                                   # idx_by_group = series.groupby(level=0, sort=False).indices\n",
      "  1411                                                   # exog = series.iloc[:, 1:].droplevel(level=0) if exog is not None else None\n",
      "  1412                                                   # series = series.iloc[:, 0].droplevel(level=0)\n",
      "  1413                                                   \n",
      "  1414         1      31623.0  31623.0      0.5          exog = series.iloc[:, 1:] if exog is not None else None\n",
      "  1415         1       8379.0   8379.0      0.1          series = series.iloc[:, 0]\n",
      "  1416                                           \n",
      "  1417         1         76.0     76.0      0.0          if not self.is_fitted and self.transformer_series_['_unknown_level'] is not None:\n",
      "  1418                                                       self.transformer_series_['_unknown_level'].fit(series)\n",
      "  1419                                                   \n",
      "  1420         1       1222.0   1222.0      0.0          is_datetime_index = True if isinstance(series.index.levels[1], pd.DatetimeIndex) else False\n",
      "  1421         1          4.0      4.0      0.0          series_indexes = {}\n",
      "  1422         1          9.0      9.0      0.0          indexes_freq = set()\n",
      "  1423                                           \n",
      "  1424         1          4.0      4.0      0.0          X_train_autoreg_buffer = []\n",
      "  1425         1          3.0      3.0      0.0          X_train_exog_buffer = []\n",
      "  1426         1          9.0      9.0      0.0          y_train_buffer = []\n",
      "  1427                                                   # TODO: trabajar con numpy en lugar de pandas\n",
      "  1428                                                   # for series_id, idx in idx_by_group.items():\n",
      "  1429                                                       \n",
      "  1430                                                   #     series_i = series.iloc[idx].rename(series_id)\n",
      "  1431                                                   #     exog_i = exog.iloc[idx, :] if exog is not None else None\n",
      "  1432                                                       \n",
      "  1433                                                   #     series_indexes[series_id] = series_i.index\n",
      "  1434                                                   #     if is_datetime_index:\n",
      "  1435                                                   #         indexes_freq.add(series_i.index.freqstr)\n",
      "  1436                                                   #     else:\n",
      "  1437                                                   #         indexes_freq.add(series_i.index.step)\n",
      "  1438                                           \n",
      "  1439       100        764.0      7.6      0.0          for series_id in series_names_in_:\n",
      "  1440                                                       \n",
      "  1441        99     679344.0   6862.1     10.2              series_i = series.loc[series_id].rename(series_id)\n",
      "  1442        99     572890.0   5786.8      8.6              exog_i = exog.loc[series_id, :] if exog is not None else None\n",
      "  1443                                                       \n",
      "  1444        99       1575.0     15.9      0.0              series_indexes[series_id] = series_i.index\n",
      "  1445        99        248.0      2.5      0.0              if is_datetime_index:\n",
      "  1446        99      22615.0    228.4      0.3                  indexes_freq.add(series_i.index.freqstr)\n",
      "  1447                                                       else:\n",
      "  1448                                                           indexes_freq.add(series_i.index.step)\n",
      "  1449                                           \n",
      "  1450        99     171623.0   1733.6      2.6              if series_i.isna().to_numpy().all():\n",
      "  1451                                                           raise ValueError(\n",
      "  1452                                                               f\"All values of series '{series_id}' are NaN. Please, \"\n",
      "  1453                                                               f\"remove series with all NaN values before training the forecaster.\"\n",
      "  1454                                                           )\n",
      "  1455                                           \n",
      "  1456        99        428.0      4.3      0.0              (\n",
      "  1457        99        564.0      5.7      0.0                  X_train_autoreg,\n",
      "  1458        99        192.0      1.9      0.0                  X_train_window_features_names_out_,\n",
      "  1459        99        204.0      2.1      0.0                  X_train_exog,\n",
      "  1460        99        224.0      2.3      0.0                  y_train\n",
      "  1461       198    1181799.0   5968.7     17.7              ) = self._create_train_X_y_single_series(\n",
      "  1462        99        228.0      2.3      0.0                      y           = series_i,\n",
      "  1463        99        200.0      2.0      0.0                      ignore_exog = ignore_exog,\n",
      "  1464        99        176.0      1.8      0.0                      exog        = exog_i\n",
      "  1465                                                           )\n",
      "  1466                                                       \n",
      "  1467        99        755.0      7.6      0.0              X_train_autoreg_buffer.append(X_train_autoreg)\n",
      "  1468        99        453.0      4.6      0.0              X_train_exog_buffer.append(X_train_exog)\n",
      "  1469        99        840.0      8.5      0.0              y_train_buffer.append(y_train)\n",
      "  1470                                           \n",
      "  1471         1         15.0     15.0      0.0          if not len(indexes_freq) == 1:\n",
      "  1472                                                       pass\n",
      "  1473         1         11.0     11.0      0.0          if indexes_freq == [None]:\n",
      "  1474                                                       pass\n",
      "  1475                                           \n",
      "  1476         1     243765.0 243765.0      3.7          X_train = pd.concat(X_train_autoreg_buffer, axis=0)\n",
      "  1477         1      42149.0  42149.0      0.6          y_train = pd.concat(y_train_buffer, axis=0)\n",
      "  1478                                           \n",
      "  1479         1         18.0     18.0      0.0          if self.is_fitted:\n",
      "  1480                                                       encoded_values = self.encoder.transform(X_train[['_level_skforecast']])\n",
      "  1481                                                   else:\n",
      "  1482         1    1450446.0    1e+06     21.8              encoded_values = self.encoder.fit_transform(X_train[['_level_skforecast']])\n",
      "  1483       100        454.0      4.5      0.0              for i, code in enumerate(self.encoder.categories_[0]):\n",
      "  1484        99        283.0      2.9      0.0                  self.encoding_mapping_[code] = i\n",
      "  1485                                           \n",
      "  1486         1         15.0     15.0      0.0          if self.encoding == 'onehot': \n",
      "  1487                                                       X_train = pd.concat([\n",
      "  1488                                                                     X_train.drop(columns='_level_skforecast'),\n",
      "  1489                                                                     encoded_values\n",
      "  1490                                                                 ], axis=1)\n",
      "  1491                                                       X_train.columns = X_train.columns.str.replace('_level_skforecast_', '')\n",
      "  1492                                                   else:\n",
      "  1493         1      22761.0  22761.0      0.3              X_train['_level_skforecast'] = encoded_values\n",
      "  1494                                           \n",
      "  1495         1         31.0     31.0      0.0          if self.encoding == 'ordinal_category':\n",
      "  1496                                                       X_train['_level_skforecast'] = (\n",
      "  1497                                                           X_train['_level_skforecast'].astype('category')\n",
      "  1498                                                       )\n",
      "  1499                                           \n",
      "  1500         1       2017.0   2017.0      0.0          del encoded_values\n",
      "  1501                                           \n",
      "  1502         1          6.0      6.0      0.0          exog_dtypes_in_ = None\n",
      "  1503         1          8.0      8.0      0.0          if exog is not None:\n",
      "  1504                                           \n",
      "  1505         1     114352.0 114352.0      1.7              X_train_exog = pd.concat(X_train_exog_buffer, axis=0)\n",
      "  1506                                                       # TODO: check if this is needed\n",
      "  1507         1        611.0    611.0      0.0              if '_dummy_exog_col_to_keep_shape' in X_train_exog.columns:\n",
      "  1508                                                           X_train_exog = (\n",
      "  1509                                                               X_train_exog.drop(columns=['_dummy_exog_col_to_keep_shape'])\n",
      "  1510                                                           )\n",
      "  1511                                           \n",
      "  1512         1         53.0     53.0      0.0              exog_names_in_ = X_train_exog.columns.to_list()\n",
      "  1513         1       3095.0   3095.0      0.0              exog_dtypes_in_ = get_exog_dtypes(exog=X_train_exog)\n",
      "  1514                                           \n",
      "  1515         1         16.0     16.0      0.0              fit_transformer = False if self.is_fitted else True\n",
      "  1516         2     511415.0 255707.5      7.7              X_train_exog = transform_dataframe(\n",
      "  1517         1          3.0      3.0      0.0                                 df                = X_train_exog,\n",
      "  1518         1         16.0     16.0      0.0                                 transformer       = self.transformer_exog,\n",
      "  1519         1          2.0      2.0      0.0                                 fit               = fit_transformer,\n",
      "  1520         1          1.0      1.0      0.0                                 inverse_transform = False\n",
      "  1521                                                                      )\n",
      "  1522                                           \n",
      "  1523         1       9186.0   9186.0      0.1              check_exog_dtypes(X_train_exog, call_check_exog=False)\n",
      "  1524         1      15162.0  15162.0      0.2              if not (X_train_exog.index == X_train.index).all():\n",
      "  1525                                                           raise ValueError(\n",
      "  1526                                                               \"Different index for `series` and `exog` after transformation. \"\n",
      "  1527                                                               \"They must be equal to ensure the correct alignment of values.\"\n",
      "  1528                                                           )\n",
      "  1529                                           \n",
      "  1530         1        123.0    123.0      0.0              X_train_exog_names_out_ = X_train_exog.columns.to_list()\n",
      "  1531         1     155575.0 155575.0      2.3              X_train = pd.concat([X_train, X_train_exog], axis=1)\n",
      "  1532                                           \n",
      "  1533         1       6345.0   6345.0      0.1          if y_train.isna().to_numpy().any():\n",
      "  1534                                                       mask = y_train.notna().to_numpy()\n",
      "  1535                                                       y_train = y_train.iloc[mask]\n",
      "  1536                                                       X_train = X_train.iloc[mask,]\n",
      "  1537                                                       warnings.warn(\n",
      "  1538                                                           \"NaNs detected in `y_train`. They have been dropped because the \"\n",
      "  1539                                                           \"target variable cannot have NaN values. Same rows have been \"\n",
      "  1540                                                           \"dropped from `X_train` to maintain alignment. This is caused by \"\n",
      "  1541                                                           \"series with interspersed NaNs.\",\n",
      "  1542                                                           MissingValuesWarning\n",
      "  1543                                                       )\n",
      "  1544                                           \n",
      "  1545         1         17.0     17.0      0.0          if self.dropna_from_series:\n",
      "  1546                                                       if np.any(X_train.isnull().to_numpy()):\n",
      "  1547                                                           mask = X_train.notna().all(axis=1).to_numpy()\n",
      "  1548                                                           X_train = X_train.iloc[mask, ]\n",
      "  1549                                                           y_train = y_train.iloc[mask]\n",
      "  1550                                                           warnings.warn(\n",
      "  1551                                                               \"NaNs detected in `X_train`. They have been dropped. If \"\n",
      "  1552                                                               \"you want to keep them, set `forecaster.dropna_from_series = False`. \"\n",
      "  1553                                                               \"Same rows have been removed from `y_train` to maintain alignment. \"\n",
      "  1554                                                               \"This caused by series with interspersed NaNs.\",\n",
      "  1555                                                               MissingValuesWarning\n",
      "  1556                                                           )\n",
      "  1557                                                   else:\n",
      "  1558         1      56709.0  56709.0      0.9              if np.any(X_train.isnull().to_numpy()):\n",
      "  1559                                                           warnings.warn(\n",
      "  1560                                                               \"NaNs detected in `X_train`. Some regressors do not allow \"\n",
      "  1561                                                               \"NaN values during training. If you want to drop them, \"\n",
      "  1562                                                               \"set `forecaster.dropna_from_series = True`.\",\n",
      "  1563                                                               MissingValuesWarning\n",
      "  1564                                                           )\n",
      "  1565                                           \n",
      "  1566         1        311.0    311.0      0.0          if X_train.empty:\n",
      "  1567                                                       raise ValueError(\n",
      "  1568                                                           \"All samples have been removed due to NaNs. Set \"\n",
      "  1569                                                           \"`forecaster.dropna_from_series = False` or review `exog` values.\"\n",
      "  1570                                                       )\n",
      "  1571                                                   \n",
      "  1572                                                   # TODO: do we care about the order?\n",
      "  1573         1         28.0     28.0      0.0          if self.encoding == 'onehot':\n",
      "  1574                                                       X_train_series_names_in_ = [\n",
      "  1575                                                           col for col in series_names_in_ if X_train[col].sum() > 0\n",
      "  1576                                                       ]\n",
      "  1577                                                   else:\n",
      "  1578         1      28385.0  28385.0      0.4              unique_levels = X_train['_level_skforecast'].unique()\n",
      "  1579         2       4254.0   2127.0      0.1              X_train_series_names_in_ = [\n",
      "  1580         1         17.0     17.0      0.0                  k for k, v in self.encoding_mapping_.items()\n",
      "  1581                                                           if v in unique_levels\n",
      "  1582                                                       ]\n",
      "  1583                                           \n",
      "  1584                                                   # The last time window of training data is stored so that lags needed as\n",
      "  1585                                                   # predictors in the first iteration of `predict()` can be calculated.\n",
      "  1586         1          7.0      7.0      0.0          last_window_ = None\n",
      "  1587         1          5.0      5.0      0.0          if store_last_window:\n",
      "  1588                                           \n",
      "  1589         1          6.0      6.0      0.0              series_to_store = (\n",
      "  1590         1          5.0      5.0      0.0                  X_train_series_names_in_ if store_last_window is True else store_last_window\n",
      "  1591                                                       )\n",
      "  1592                                           \n",
      "  1593         1        177.0    177.0      0.0              series_not_in_series_dict = set(series_to_store) - set(X_train_series_names_in_)\n",
      "  1594         1          6.0      6.0      0.0              if series_not_in_series_dict:\n",
      "  1595                                                           warnings.warn(\n",
      "  1596                                                               f\"Series {series_not_in_series_dict} are not present in \"\n",
      "  1597                                                               f\"`series`. No last window is stored for them.\",\n",
      "  1598                                                               IgnoredArgumentWarning\n",
      "  1599                                                           )\n",
      "  1600                                                           series_to_store = [\n",
      "  1601                                                               s for s in series_to_store \n",
      "  1602                                                               if s not in series_not_in_series_dict\n",
      "  1603                                                           ]\n",
      "  1604                                           \n",
      "  1605         1          6.0      6.0      0.0              if series_to_store:\n",
      "  1606         2     565893.0 282946.5      8.5                  last_window_ = {\n",
      "  1607                                                               series_id: series.loc[series_id].iloc[-self.window_size:].rename(series_id)\n",
      "  1608         1          3.0      3.0      0.0                      for series_id in series_to_store\n",
      "  1609                                                           }\n",
      "  1610                                           \n",
      "  1611         1          4.0      4.0      0.0          return (\n",
      "  1612         1          5.0      5.0      0.0              X_train,\n",
      "  1613         1          5.0      5.0      0.0              y_train,\n",
      "  1614         1          4.0      4.0      0.0              series_indexes,\n",
      "  1615         1          3.0      3.0      0.0              series_names_in_,\n",
      "  1616         1          2.0      2.0      0.0              X_train_series_names_in_,\n",
      "  1617         1          7.0      7.0      0.0              exog_names_in_,\n",
      "  1618         1          4.0      4.0      0.0              X_train_window_features_names_out_,\n",
      "  1619         1          8.0      8.0      0.0              X_train_exog_names_out_,\n",
      "  1620         1          5.0      5.0      0.0              exog_dtypes_in_,\n",
      "  1621         1          2.0      2.0      0.0              last_window_\n",
      "  1622                                                   )"
     ]
    }
   ],
   "source": [
    "def funt_to_profile(forecaster, series, exog):\n",
    "    _ = forecaster._create_train_X_y_v2(\n",
    "                            series = series,\n",
    "                            exog=exog\n",
    "                        )\n",
    "\n",
    "%lprun -f forecaster._create_train_X_y_v2 funt_to_profile(forecaster, series, exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493 ms Â± 46.1 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 5 -n 5\n",
    "_ = forecaster._create_train_X_y_v3(\n",
    "    series = series,\n",
    "    exog=exog\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funt_to_profile(forecaster, series, exog):\n",
    "    _ = forecaster._create_train_X_y_v3(\n",
    "                            series = series,\n",
    "                            exog=exog\n",
    "                        )\n",
    "\n",
    "%lprun -f forecaster._create_train_X_y_v2 funt_to_profile(forecaster, series, exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.4 ms Â± 5.9 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 5 -n 5\n",
    "{\n",
    "    sid: series.loc[sid]['value'] for sid in series.index.levels[0]\n",
    "}\n",
    "\n",
    "{\n",
    "    sid: exog.loc[sid]for sid in exog.index.levels[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413 ms Â± 44.8 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 5 -n 5\n",
    "_ = forecaster._create_train_X_y(\n",
    "    series = series_dict,\n",
    "    exog=exog_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.701712 s\n",
      "File: c:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\skforecast\\recursive\\_forecaster_recursive_multiseries.py\n",
      "Function: _create_train_X_y at line 1087\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1087                                               def _create_train_X_y(\n",
      "  1088                                                   self,\n",
      "  1089                                                   series: pd.DataFrame | dict[str, pd.Series | pd.DataFrame],\n",
      "  1090                                                   exog: pd.Series | pd.DataFrame | dict[str, pd.Series | pd.DataFrame] | None = None,\n",
      "  1091                                                   store_last_window: bool | list[str] = True,\n",
      "  1092                                               ) -> tuple[\n",
      "  1093                                                   pd.DataFrame,\n",
      "  1094                                                   pd.Series,\n",
      "  1095                                                   dict[str, pd.Index],\n",
      "  1096                                                   list[str],\n",
      "  1097                                                   list[str],\n",
      "  1098                                                   list[str],\n",
      "  1099                                                   list[str],\n",
      "  1100                                                   list[str],\n",
      "  1101                                                   dict[str, type],\n",
      "  1102                                                   dict[str, pd.Series],\n",
      "  1103                                               ]:\n",
      "  1104                                                   \"\"\"\n",
      "  1105                                                   Create training matrices from multiple time series and exogenous\n",
      "  1106                                                   variables. See Notes section for more details depending on the type of\n",
      "  1107                                                   `series` and `exog`.\n",
      "  1108                                                   \n",
      "  1109                                                   Parameters\n",
      "  1110                                                   ----------\n",
      "  1111                                                   series : pandas DataFrame, dict\n",
      "  1112                                                       Training time series.\n",
      "  1113                                                   exog : pandas Series, pandas DataFrame, dict, default None\n",
      "  1114                                                       Exogenous variable/s included as predictor/s.\n",
      "  1115                                                   store_last_window : bool, list, default True\n",
      "  1116                                                       Whether or not to store the last window (`last_window_`) of training data.\n",
      "  1117                                           \n",
      "  1118                                                       - If `True`, last window is stored for all series. \n",
      "  1119                                                       - If `list`, last window is stored for the series present in the list.\n",
      "  1120                                                       - If `False`, last window is not stored.\n",
      "  1121                                           \n",
      "  1122                                                   Returns\n",
      "  1123                                                   -------\n",
      "  1124                                                   X_train : pandas DataFrame\n",
      "  1125                                                       Training values (predictors).\n",
      "  1126                                                   y_train : pandas Series\n",
      "  1127                                                       Values of the time series related to each row of `X_train`.\n",
      "  1128                                                   series_indexes : dict\n",
      "  1129                                                       Dictionary with the index of each series.\n",
      "  1130                                                   series_names_in_ : list\n",
      "  1131                                                       Names of the series (levels) provided by the user during training.\n",
      "  1132                                                   X_train_series_names_in_ : list\n",
      "  1133                                                       Names of the series (levels) included in the matrix `X_train` created\n",
      "  1134                                                       internally for training. It can be different from `series_names_in_` if\n",
      "  1135                                                       some series are dropped during the training process because of NaNs or\n",
      "  1136                                                       because they are not present in the training period.\n",
      "  1137                                                   exog_names_in_ : list\n",
      "  1138                                                       Names of the exogenous variables used during training.\n",
      "  1139                                                   X_train_window_features_names_out_ : list\n",
      "  1140                                                       Names of the window features included in the matrix `X_train` created\n",
      "  1141                                                       internally for training.\n",
      "  1142                                                   X_train_exog_names_out_ : list\n",
      "  1143                                                       Names of the exogenous variables included in the matrix `X_train` created\n",
      "  1144                                                       internally for training. It can be different from `exog_names_in_` if\n",
      "  1145                                                       some exogenous variables are transformed during the training process.\n",
      "  1146                                                   exog_dtypes_in_ : dict\n",
      "  1147                                                       Type of each exogenous variable/s used in training. If `transformer_exog` \n",
      "  1148                                                       is used, the dtypes are calculated before the transformation.\n",
      "  1149                                                   last_window_ : dict\n",
      "  1150                                                       Last window of training data for each series. It stores the values \n",
      "  1151                                                       needed to predict the next `step` immediately after the training data.\n",
      "  1152                                           \n",
      "  1153                                                   Notes\n",
      "  1154                                                   -----\n",
      "  1155                                                   - If `series` is a pandas DataFrame and `exog` is a pandas Series or \n",
      "  1156                                                   DataFrame, each exog is duplicated for each series. Exog must have the\n",
      "  1157                                                   same index as `series` (type, length and frequency).\n",
      "  1158                                                   - If `series` is a pandas DataFrame and `exog` is a dict of pandas Series \n",
      "  1159                                                   or DataFrames. Each key in `exog` must be a column in `series` and the \n",
      "  1160                                                   values are the exog for each series. Exog must have the same index as \n",
      "  1161                                                   `series` (type, length and frequency).\n",
      "  1162                                                   - If `series` is a dict of pandas Series, `exog` must be a dict of pandas\n",
      "  1163                                                   Series or DataFrames. The keys in `series` and `exog` must be the same.\n",
      "  1164                                                   All series and exog must have a pandas DatetimeIndex with the same \n",
      "  1165                                                   frequency.\n",
      "  1166                                                   \n",
      "  1167                                                   \"\"\"\n",
      "  1168                                           \n",
      "  1169         1     201399.0 201399.0      2.9          series_dict, series_indexes = check_preprocess_series(series=series)\n",
      "  1170         1         26.0     26.0      0.0          input_series_is_dict = isinstance(series, dict)\n",
      "  1171         1         54.0     54.0      0.0          series_names_in_ = list(series_dict.keys())\n",
      "  1172                                           \n",
      "  1173         1         42.0     42.0      0.0          if self.is_fitted and not set(series_names_in_).issubset(set(self.series_names_in_)):\n",
      "  1174                                                       raise ValueError(\n",
      "  1175                                                           f\"Once the Forecaster has been trained, `series` must contain \"\n",
      "  1176                                                           f\"the same series names as those used during training:\\n\"\n",
      "  1177                                                           f\" Got      : {series_names_in_}\\n\"\n",
      "  1178                                                           f\" Expected : {self.series_names_in_}\"\n",
      "  1179                                                       )\n",
      "  1180                                           \n",
      "  1181         1        287.0    287.0      0.0          exog_dict = {serie: None for serie in series_names_in_}\n",
      "  1182         1          4.0      4.0      0.0          exog_names_in_ = None\n",
      "  1183         1          3.0      3.0      0.0          X_train_exog_names_out_ = None\n",
      "  1184         1          4.0      4.0      0.0          if exog is not None:\n",
      "  1185         2     464439.0 232219.5      6.6              exog_dict, exog_names_in_ = check_preprocess_exog_multiseries(\n",
      "  1186         1          2.0      2.0      0.0                                              input_series_is_dict = input_series_is_dict,\n",
      "  1187         1          3.0      3.0      0.0                                              series_indexes       = series_indexes,\n",
      "  1188         1          1.0      1.0      0.0                                              series_names_in_     = series_names_in_,\n",
      "  1189         1          1.0      1.0      0.0                                              exog                 = exog,\n",
      "  1190         1          2.0      2.0      0.0                                              exog_dict            = exog_dict\n",
      "  1191                                                                                   )\n",
      "  1192                                           \n",
      "  1193         1         21.0     21.0      0.0              if self.is_fitted:\n",
      "  1194                                                           if self.exog_names_in_ is None:\n",
      "  1195                                                               raise ValueError(\n",
      "  1196                                                                   \"Once the Forecaster has been trained, `exog` must be `None` \"\n",
      "  1197                                                                   \"because no exogenous variables were added during training.\"\n",
      "  1198                                                               )\n",
      "  1199                                                           else:\n",
      "  1200                                                               if not set(exog_names_in_) == set(self.exog_names_in_):\n",
      "  1201                                                                   raise ValueError(\n",
      "  1202                                                                       f\"Once the Forecaster has been trained, `exog` must contain \"\n",
      "  1203                                                                       f\"the same exogenous variables as those used during training:\\n\"\n",
      "  1204                                                                       f\" Got      : {exog_names_in_}\\n\"\n",
      "  1205                                                                       f\" Expected : {self.exog_names_in_}\"\n",
      "  1206                                                                   )\n",
      "  1207                                           \n",
      "  1208         1          4.0      4.0      0.0          if not self.is_fitted:\n",
      "  1209         2        503.0    251.5      0.0              self.transformer_series_ = initialize_transformer_series(\n",
      "  1210         1         13.0     13.0      0.0                                             forecaster_name    = type(self).__name__,\n",
      "  1211         1          2.0      2.0      0.0                                             series_names_in_   = series_names_in_,\n",
      "  1212         1         20.0     20.0      0.0                                             encoding           = self.encoding,\n",
      "  1213         1         15.0     15.0      0.0                                             transformer_series = self.transformer_series\n",
      "  1214                                                                                  )\n",
      "  1215                                                       \n",
      "  1216         2        317.0    158.5      0.0              self.differentiator_ = initialize_differentiator_multiseries(\n",
      "  1217         1          2.0      2.0      0.0                                         series_names_in_ = series_names_in_,\n",
      "  1218         1          6.0      6.0      0.0                                         differentiator   = self.differentiator\n",
      "  1219                                                                              )\n",
      "  1220                                           \n",
      "  1221         2    1288362.0 644181.0     18.4          series_dict, exog_dict = align_series_and_exog_multiseries(\n",
      "  1222         1         10.0     10.0      0.0                                       series_dict          = series_dict,\n",
      "  1223         1          3.0      3.0      0.0                                       input_series_is_dict = input_series_is_dict,\n",
      "  1224         1          3.0      3.0      0.0                                       exog_dict            = exog_dict\n",
      "  1225                                                                            )\n",
      "  1226                                                   \n",
      "  1227         1         28.0     28.0      0.0          if not self.is_fitted and self.transformer_series_['_unknown_level'] is not None:\n",
      "  1228                                                       self.transformer_series_['_unknown_level'].fit(\n",
      "  1229                                                           np.concatenate(list(series_dict.values())).reshape(-1, 1)\n",
      "  1230                                                       )\n",
      "  1231                                           \n",
      "  1232         1          6.0      6.0      0.0          ignore_exog = True if exog is None else False\n",
      "  1233         2       1088.0    544.0      0.0          input_matrices = [\n",
      "  1234                                                       [series_dict[k], exog_dict[k], ignore_exog]\n",
      "  1235         1          5.0      5.0      0.0               for k in series_dict.keys()\n",
      "  1236                                                   ]\n",
      "  1237                                           \n",
      "  1238         1          4.0      4.0      0.0          X_train_autoreg_buffer = []\n",
      "  1239         1          3.0      3.0      0.0          X_train_exog_buffer = []\n",
      "  1240         1          4.0      4.0      0.0          y_train_buffer = []\n",
      "  1241       100        686.0      6.9      0.0          for matrices in input_matrices:\n",
      "  1242                                           \n",
      "  1243        99        453.0      4.6      0.0              (\n",
      "  1244        99        342.0      3.5      0.0                  X_train_autoreg,\n",
      "  1245        99        201.0      2.0      0.0                  X_train_window_features_names_out_,\n",
      "  1246        99        241.0      2.4      0.0                  X_train_exog,\n",
      "  1247        99        243.0      2.5      0.0                  y_train\n",
      "  1248       198    1197187.0   6046.4     17.1              ) = self._create_train_X_y_single_series(\n",
      "  1249        99        637.0      6.4      0.0                  y           = matrices[0],\n",
      "  1250        99        548.0      5.5      0.0                  exog        = matrices[1],\n",
      "  1251        99        289.0      2.9      0.0                  ignore_exog = matrices[2],\n",
      "  1252                                                       )\n",
      "  1253                                           \n",
      "  1254        99        880.0      8.9      0.0              X_train_autoreg_buffer.append(X_train_autoreg)\n",
      "  1255        99        449.0      4.5      0.0              X_train_exog_buffer.append(X_train_exog)\n",
      "  1256        99        531.0      5.4      0.0              y_train_buffer.append(y_train)\n",
      "  1257                                           \n",
      "  1258         1     222665.0 222665.0      3.2          X_train = pd.concat(X_train_autoreg_buffer, axis=0)\n",
      "  1259         1      62816.0  62816.0      0.9          y_train = pd.concat(y_train_buffer, axis=0)\n",
      "  1260                                           \n",
      "  1261         1         24.0     24.0      0.0          if self.is_fitted:\n",
      "  1262                                                       encoded_values = self.encoder.transform(X_train[['_level_skforecast']])\n",
      "  1263                                                   else:\n",
      "  1264         1    1761034.0    2e+06     25.1              encoded_values = self.encoder.fit_transform(X_train[['_level_skforecast']])\n",
      "  1265       100       1308.0     13.1      0.0              for i, code in enumerate(self.encoder.categories_[0]):\n",
      "  1266        99        585.0      5.9      0.0                  self.encoding_mapping_[code] = i\n",
      "  1267                                           \n",
      "  1268         1         51.0     51.0      0.0          if self.encoding == 'onehot': \n",
      "  1269                                                       X_train = pd.concat([\n",
      "  1270                                                                     X_train.drop(columns='_level_skforecast'),\n",
      "  1271                                                                     encoded_values\n",
      "  1272                                                                 ], axis=1)\n",
      "  1273                                                       X_train.columns = X_train.columns.str.replace('_level_skforecast_', '')\n",
      "  1274                                                   else:\n",
      "  1275         1      38713.0  38713.0      0.6              X_train['_level_skforecast'] = encoded_values\n",
      "  1276                                           \n",
      "  1277         1         30.0     30.0      0.0          if self.encoding == 'ordinal_category':\n",
      "  1278                                                       X_train['_level_skforecast'] = (\n",
      "  1279                                                           X_train['_level_skforecast'].astype('category')\n",
      "  1280                                                       )\n",
      "  1281                                           \n",
      "  1282         1       2048.0   2048.0      0.0          del encoded_values\n",
      "  1283                                           \n",
      "  1284         1          6.0      6.0      0.0          exog_dtypes_in_ = None\n",
      "  1285         1          8.0      8.0      0.0          if exog is not None:\n",
      "  1286                                           \n",
      "  1287         1     165760.0 165760.0      2.4              X_train_exog = pd.concat(X_train_exog_buffer, axis=0)\n",
      "  1288         1        337.0    337.0      0.0              if '_dummy_exog_col_to_keep_shape' in X_train_exog.columns:\n",
      "  1289                                                           X_train_exog = (\n",
      "  1290                                                               X_train_exog.drop(columns=['_dummy_exog_col_to_keep_shape'])\n",
      "  1291                                                           )\n",
      "  1292                                           \n",
      "  1293         1        169.0    169.0      0.0              exog_names_in_ = X_train_exog.columns.to_list()\n",
      "  1294         1      10626.0  10626.0      0.2              exog_dtypes_in_ = get_exog_dtypes(exog=X_train_exog)\n",
      "  1295                                           \n",
      "  1296         1        136.0    136.0      0.0              fit_transformer = False if self.is_fitted else True\n",
      "  1297         2    1223639.0 611819.5     17.4              X_train_exog = transform_dataframe(\n",
      "  1298         1         14.0     14.0      0.0                                 df                = X_train_exog,\n",
      "  1299         1         23.0     23.0      0.0                                 transformer       = self.transformer_exog,\n",
      "  1300         1          9.0      9.0      0.0                                 fit               = fit_transformer,\n",
      "  1301         1          3.0      3.0      0.0                                 inverse_transform = False\n",
      "  1302                                                                      )\n",
      "  1303                                           \n",
      "  1304         1      10065.0  10065.0      0.1              check_exog_dtypes(X_train_exog, call_check_exog=False)\n",
      "  1305         1      13845.0  13845.0      0.2              if not (X_train_exog.index == X_train.index).all():\n",
      "  1306                                                           raise ValueError(\n",
      "  1307                                                               \"Different index for `series` and `exog` after transformation. \"\n",
      "  1308                                                               \"They must be equal to ensure the correct alignment of values.\"\n",
      "  1309                                                           )\n",
      "  1310                                           \n",
      "  1311         1         83.0     83.0      0.0              X_train_exog_names_out_ = X_train_exog.columns.to_list()\n",
      "  1312         1     122836.0 122836.0      1.8              X_train = pd.concat([X_train, X_train_exog], axis=1)\n",
      "  1313                                           \n",
      "  1314         1       3850.0   3850.0      0.1          if y_train.isna().to_numpy().any():\n",
      "  1315                                                       mask = y_train.notna().to_numpy()\n",
      "  1316                                                       y_train = y_train.iloc[mask]\n",
      "  1317                                                       X_train = X_train.iloc[mask,]\n",
      "  1318                                                       warnings.warn(\n",
      "  1319                                                           \"NaNs detected in `y_train`. They have been dropped because the \"\n",
      "  1320                                                           \"target variable cannot have NaN values. Same rows have been \"\n",
      "  1321                                                           \"dropped from `X_train` to maintain alignment. This is caused by \"\n",
      "  1322                                                           \"series with interspersed NaNs.\",\n",
      "  1323                                                           MissingValuesWarning\n",
      "  1324                                                       )\n",
      "  1325                                           \n",
      "  1326         1         53.0     53.0      0.0          if self.dropna_from_series:\n",
      "  1327                                                       if np.any(X_train.isnull().to_numpy()):\n",
      "  1328                                                           mask = X_train.notna().all(axis=1).to_numpy()\n",
      "  1329                                                           X_train = X_train.iloc[mask, ]\n",
      "  1330                                                           y_train = y_train.iloc[mask]\n",
      "  1331                                                           warnings.warn(\n",
      "  1332                                                               \"NaNs detected in `X_train`. They have been dropped. If \"\n",
      "  1333                                                               \"you want to keep them, set `forecaster.dropna_from_series = False`. \"\n",
      "  1334                                                               \"Same rows have been removed from `y_train` to maintain alignment. \"\n",
      "  1335                                                               \"This caused by series with interspersed NaNs.\",\n",
      "  1336                                                               MissingValuesWarning\n",
      "  1337                                                           )\n",
      "  1338                                                   else:\n",
      "  1339         1      62581.0  62581.0      0.9              if np.any(X_train.isnull().to_numpy()):\n",
      "  1340         2        204.0    102.0      0.0                  warnings.warn(\n",
      "  1341         1          7.0      7.0      0.0                      \"NaNs detected in `X_train`. Some regressors do not allow \"\n",
      "  1342                                                               \"NaN values during training. If you want to drop them, \"\n",
      "  1343                                                               \"set `forecaster.dropna_from_series = True`.\",\n",
      "  1344         1         10.0     10.0      0.0                      MissingValuesWarning\n",
      "  1345                                                           )\n",
      "  1346                                           \n",
      "  1347         1        315.0    315.0      0.0          if X_train.empty:\n",
      "  1348                                                       raise ValueError(\n",
      "  1349                                                           \"All samples have been removed due to NaNs. Set \"\n",
      "  1350                                                           \"`forecaster.dropna_from_series = False` or review `exog` values.\"\n",
      "  1351                                                       )\n",
      "  1352                                                   \n",
      "  1353         1         40.0     40.0      0.0          if self.encoding == 'onehot':\n",
      "  1354                                                       X_train_series_names_in_ = [\n",
      "  1355                                                           col for col in series_names_in_ if X_train[col].sum() > 0\n",
      "  1356                                                       ]\n",
      "  1357                                                   else:\n",
      "  1358         1      27389.0  27389.0      0.4              unique_levels = X_train['_level_skforecast'].unique()\n",
      "  1359         2       3537.0   1768.5      0.1              X_train_series_names_in_ = [\n",
      "  1360         1         18.0     18.0      0.0                  k for k, v in self.encoding_mapping_.items()\n",
      "  1361                                                           if v in unique_levels\n",
      "  1362                                                       ]\n",
      "  1363                                           \n",
      "  1364                                                   # The last time window of training data is stored so that lags needed as\n",
      "  1365                                                   # predictors in the first iteration of `predict()` can be calculated.\n",
      "  1366         1          5.0      5.0      0.0          last_window_ = None\n",
      "  1367         1          3.0      3.0      0.0          if store_last_window:\n",
      "  1368                                           \n",
      "  1369         1          2.0      2.0      0.0              series_to_store = (\n",
      "  1370         1          6.0      6.0      0.0                  X_train_series_names_in_ if store_last_window is True else store_last_window\n",
      "  1371                                                       )\n",
      "  1372                                           \n",
      "  1373         1        150.0    150.0      0.0              series_not_in_series_dict = set(series_to_store) - set(X_train_series_names_in_)\n",
      "  1374         1         10.0     10.0      0.0              if series_not_in_series_dict:\n",
      "  1375                                                           warnings.warn(\n",
      "  1376                                                               f\"Series {series_not_in_series_dict} are not present in \"\n",
      "  1377                                                               f\"`series`. No last window is stored for them.\",\n",
      "  1378                                                               IgnoredArgumentWarning\n",
      "  1379                                                           )\n",
      "  1380                                                           series_to_store = [\n",
      "  1381                                                               s for s in series_to_store \n",
      "  1382                                                               if s not in series_not_in_series_dict\n",
      "  1383                                                           ]\n",
      "  1384                                           \n",
      "  1385         1          5.0      5.0      0.0              if series_to_store:\n",
      "  1386         2     122692.0  61346.0      1.7                  last_window_ = {\n",
      "  1387                                                               k: v.iloc[-self.window_size:].copy()\n",
      "  1388         1          7.0      7.0      0.0                      for k, v in series_dict.items()\n",
      "  1389                                                               if k in series_to_store\n",
      "  1390                                                           }\n",
      "  1391                                           \n",
      "  1392         1          3.0      3.0      0.0          return (\n",
      "  1393         1          6.0      6.0      0.0              X_train,\n",
      "  1394         1          6.0      6.0      0.0              y_train,\n",
      "  1395         1          2.0      2.0      0.0              series_indexes,\n",
      "  1396         1          2.0      2.0      0.0              series_names_in_,\n",
      "  1397         1          1.0      1.0      0.0              X_train_series_names_in_,\n",
      "  1398         1          3.0      3.0      0.0              exog_names_in_,\n",
      "  1399         1          2.0      2.0      0.0              X_train_window_features_names_out_,\n",
      "  1400         1          5.0      5.0      0.0              X_train_exog_names_out_,\n",
      "  1401         1          1.0      1.0      0.0              exog_dtypes_in_,\n",
      "  1402         1          1.0      1.0      0.0              last_window_\n",
      "  1403                                                   )"
     ]
    }
   ],
   "source": [
    "def funt_to_profile(forecaster, series_dict, exog_dict):\n",
    "    _ = forecaster._create_train_X_y(\n",
    "                            series = series_dict,\n",
    "                            exog=exog_dict\n",
    "                        )\n",
    "\n",
    "%lprun -f forecaster._create_train_X_y funt_to_profile(forecaster, series_dict, exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.064929 s\n",
      "File: c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py\n",
      "Function: check_preprocess_series at line 2448\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  2448                                           def check_preprocess_series(\n",
      "  2449                                               series: pd.DataFrame,\n",
      "  2450                                           ) -> tuple[pd.DataFrame]:\n",
      "  2451                                               \"\"\"\n",
      "  2452                                               Check and preprocess `series` argument in `ForecasterRecursiveMultiSeries`\n",
      "  2453                                               class.\n",
      "  2454                                           \n",
      "  2455                                               Check if the indexes of the series are valid. If the temporal index of the\n",
      "  2456                                               series is not a pandas DatetimeIndex index with frequency, it is overwritten\n",
      "  2457                                               with a pandas RangeIndex.\n",
      "  2458                                               \n",
      "  2459                                               Parameters\n",
      "  2460                                               ----------\n",
      "  2461                                               series : pandas DataFrame\n",
      "  2462                                                   Training time series.\n",
      "  2463                                           \n",
      "  2464                                               Returns\n",
      "  2465                                               -------\n",
      "  2466                                               series : pandas DataFrame\n",
      "  2467                                                   Series used during training.\n",
      "  2468                                               \n",
      "  2469                                               \"\"\"\n",
      "  2470                                           \n",
      "  2471         1         31.0     31.0      0.0      if not isinstance(series, pd.DataFrame):\n",
      "  2472                                                   raise TypeError(\n",
      "  2473                                                       f\"`series` must be a pandas DataFrame with a single DatetimeIndex or \"\n",
      "  2474                                                       f\"a pandas DataFrame with a MultiIndex where the first level is the \"\n",
      "  2475                                                       f\"series ID and the second level is temporal index. \"\n",
      "  2476                                                       f\"Got {type(series)}.\"\n",
      "  2477                                                   )\n",
      "  2478                                           \n",
      "  2479                                               # TODO: deprecate in next release\n",
      "  2480         1         92.0     92.0      0.0      if not isinstance(series.index, pd.MultiIndex):\n",
      "  2481                                                   warnings.warn(\n",
      "  2482                                                       \"In future versions, 'series' must be a pandas Series with a MultiIndex where \"\n",
      "  2483                                                       \"the first level is the series ID and the second level is the temporal index.\",\n",
      "  2484                                                       DeprecationWarning,\n",
      "  2485                                                   )\n",
      "  2486                                           \n",
      "  2487                                                   freq = series.index.freq\n",
      "  2488                                                   series.index.name = 'datetime'\n",
      "  2489                                                   series = series.reset_index()\n",
      "  2490                                                   series = pd.melt(\n",
      "  2491                                                       series,\n",
      "  2492                                                       id_vars='datetime',\n",
      "  2493                                                       var_name='series_id',\n",
      "  2494                                                       value_name='value'\n",
      "  2495                                                   )\n",
      "  2496                                                   series = (\n",
      "  2497                                                       series\n",
      "  2498                                                       .groupby('series_id', sort=False)\n",
      "  2499                                                       .apply(lambda x: x.set_index('datetime').asfreq(freq), include_groups=False)\n",
      "  2500                                                   )\n",
      "  2501                                           \n",
      "  2502         1          7.0      7.0      0.0      if isinstance(series.index, pd.MultiIndex):\n",
      "  2503                                           \n",
      "  2504         1         65.0     65.0      0.0          if not series.index.nlevels == 2:\n",
      "  2505                                                       raise ValueError(\n",
      "  2506                                                           f\"`series` must be a pandas DataFrame with a MultiIndex, where \"\n",
      "  2507                                                           f\"the first level is the seris ID and the second level the temporal \"\n",
      "  2508                                                           f\"index. Found {series.index.names} levels.\"\n",
      "  2509                                                       )\n",
      "  2510                                               \n",
      "  2511                                                   # NOTE: if it is not a DatetimeIndex,or a RangeIndex, raise error instead of warning\n",
      "  2512         1        143.0    143.0      0.0          if not isinstance(series.index.levels[1], (pd.DatetimeIndex, pd.RangeIndex)):\n",
      "  2513                                                       raise TypeError(\n",
      "  2514                                                           f\"The second level of the MultiIndex in `series` must be a \"\n",
      "  2515                                                           f\"pandas DatetimeIndex or RangeIndex. Found {type(series.index.levels[1])}.\"\n",
      "  2516                                                       )\n",
      "  2517                                             \n",
      "  2518                                           \n",
      "  2519         1         19.0     19.0      0.0          if isinstance(series.index.levels[1], pd.DatetimeIndex):\n",
      "  2520         1         11.0     11.0      0.0              indexes_freq = set()\n",
      "  2521         1         18.0     18.0      0.0              unique_ids = series.index.levels[0]\n",
      "  2522       100       1542.0     15.4      0.2              for series_id in unique_ids:\n",
      "  2523        99     539425.0   5448.7     83.1                  series_i = series.loc[series_id]\n",
      "  2524                                                           # TODO: hacer esto solo si es datetime\n",
      "  2525        99      15287.0    154.4      2.4                  indexes_freq.add(series_i.index.freq)\n",
      "  2526        99      92603.0    935.4     14.3                  if series_i.isna().to_numpy().all():\n",
      "  2527                                                               raise ValueError(\n",
      "  2528                                                                   f\"All values of series '{series_id}' are NaN. Please, \",\n",
      "  2529                                                                   f\"remove series with all NaN values before training the forecaster.\"\n",
      "  2530                                                               )\n",
      "  2531                                           \n",
      "  2532         1         25.0     25.0      0.0              if not len(indexes_freq) == 1:\n",
      "  2533                                                           raise ValueError(\n",
      "  2534                                                               f\"When using a DatetimeIndex, all series must have the same \",\n",
      "  2535                                                               f\"frequency. Found frequencies: {indexes_freq}\"\n",
      "  2536                                                           )\n",
      "  2537         1         15.0     15.0      0.0              if indexes_freq == [None]:\n",
      "  2538                                                           raise TypeError(\n",
      "  2539                                                               \"Series have a pandas DatetimeIndex without frequancy. When \"\n",
      "  2540                                                               \"using a DatetimeIndex, all series must have the same frequency. \"\n",
      "  2541                                                               \"To avoid this error, set the frequency of the index using: \"\n",
      "  2542                                                               \"series.groupby('series_id').apply(lambda x: x.set_index('datetime').asfreq('D'),\"\n",
      "  2543                                                               \"include_groups=False)\"\n",
      "  2544                                                           )\n",
      "  2545                                                       \n",
      "  2546                                                           #TODO: remove if agree with the raise error above\n",
      "  2547                                                           # series_grouped = series.groupby(level=0, group_keys=False, sort=False)\n",
      "  2548                                                           # series = series_grouped.apply(\n",
      "  2549                                                           #     lambda g: g.set_index(\n",
      "  2550                                                           #         pd.MultiIndex.from_arrays(\n",
      "  2551                                                           #             [g.index.get_level_values(0), pd.RangeIndex(len(g))],\n",
      "  2552                                                           #             names=g.index.names\n",
      "  2553                                                           #         )\n",
      "  2554                                                           #     )\n",
      "  2555                                                           # )            \n",
      "  2556                                           \n",
      "  2557         1          7.0      7.0      0.0      return series"
     ]
    }
   ],
   "source": [
    "def funt_to_profile(series):\n",
    "    check_preprocess_series(series=series)\n",
    "\n",
    "%lprun -f check_preprocess_series funt_to_profile(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.0202911 s\n",
      "File: c:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\skforecast\\utils\\utils.py\n",
      "Function: check_preprocess_series at line 2448\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  2448                                           def check_preprocess_series(\n",
      "  2449                                               series: pd.DataFrame | dict[str, pd.Series | pd.DataFrame],\n",
      "  2450                                           ) -> tuple[dict[str, pd.Series], dict[str, pd.Index]]:\n",
      "  2451                                               \"\"\"\n",
      "  2452                                               Check and preprocess `series` argument in `ForecasterRecursiveMultiSeries` class.\n",
      "  2453                                           \n",
      "  2454                                               - If `series` is a pandas DataFrame, it is converted to a dict of pandas \n",
      "  2455                                               Series and index is overwritten according to the rules of preprocess_y.\n",
      "  2456                                               - If `series` is a dict, all values are converted to pandas Series. Checks\n",
      "  2457                                               if all index are pandas DatetimeIndex and, at least, one Series has a non-null\n",
      "  2458                                               frequency. No multiple frequency is allowed.\n",
      "  2459                                           \n",
      "  2460                                               Parameters\n",
      "  2461                                               ----------\n",
      "  2462                                               series : pandas DataFrame, dict\n",
      "  2463                                                   Training time series.\n",
      "  2464                                           \n",
      "  2465                                               Returns\n",
      "  2466                                               -------\n",
      "  2467                                               series_dict : dict\n",
      "  2468                                                   Dictionary with the series used during training.\n",
      "  2469                                               series_indexes : dict\n",
      "  2470                                                   Dictionary with the index of each series.\n",
      "  2471                                               \n",
      "  2472                                               \"\"\"\n",
      "  2473                                           \n",
      "  2474         1         41.0     41.0      0.0      if isinstance(series, pd.DataFrame):\n",
      "  2475                                           \n",
      "  2476                                                   _, series_index = preprocess_y(y=series, return_values=False)\n",
      "  2477                                                   series = series.copy()\n",
      "  2478                                                   series.index = series_index\n",
      "  2479                                                   series_dict = series.to_dict(\"series\")\n",
      "  2480                                           \n",
      "  2481         1          6.0      6.0      0.0      elif isinstance(series, dict):\n",
      "  2482                                           \n",
      "  2483         2       1029.0    514.5      0.5          not_valid_series = [\n",
      "  2484                                                       k \n",
      "  2485         1         14.0     14.0      0.0              for k, v in series.items()\n",
      "  2486                                                       if not isinstance(v, (pd.Series, pd.DataFrame))\n",
      "  2487                                                   ]\n",
      "  2488         1          4.0      4.0      0.0          if not_valid_series:\n",
      "  2489                                                       raise TypeError(\n",
      "  2490                                                           f\"If `series` is a dictionary, all series must be a named \"\n",
      "  2491                                                           f\"pandas Series or a pandas DataFrame with a single column. \"\n",
      "  2492                                                           f\"Review series: {not_valid_series}\"\n",
      "  2493                                                       )\n",
      "  2494                                           \n",
      "  2495         2      69205.0  34602.5     34.1          series_dict = {\n",
      "  2496                                                       k: v.copy()\n",
      "  2497         1          4.0      4.0      0.0              for k, v in series.items()\n",
      "  2498                                                   }\n",
      "  2499                                           \n",
      "  2500       100        395.0      4.0      0.2          for k, v in series_dict.items():\n",
      "  2501        99        471.0      4.8      0.2              if isinstance(v, pd.DataFrame):\n",
      "  2502                                                           if v.shape[1] != 1:\n",
      "  2503                                                               raise ValueError(\n",
      "  2504                                                                   f\"If `series` is a dictionary, all series must be a named \"\n",
      "  2505                                                                   f\"pandas Series or a pandas DataFrame with a single column. \"\n",
      "  2506                                                                   f\"Review series: '{k}'\"\n",
      "  2507                                                               )\n",
      "  2508                                                           series_dict[k] = v.iloc[:, 0]\n",
      "  2509                                           \n",
      "  2510        99       6525.0     65.9      3.2              series_dict[k].name = k\n",
      "  2511                                           \n",
      "  2512         2       1200.0    600.0      0.6          not_valid_index = [\n",
      "  2513                                                       k \n",
      "  2514         1         17.0     17.0      0.0              for k, v in series_dict.items()\n",
      "  2515                                                       if not isinstance(v.index, pd.DatetimeIndex)\n",
      "  2516                                                   ]\n",
      "  2517         1          7.0      7.0      0.0          if not_valid_index:\n",
      "  2518                                                       raise TypeError(\n",
      "  2519                                                           f\"If `series` is a dictionary, all series must have a Pandas \"\n",
      "  2520                                                           f\"DatetimeIndex as index with the same frequency. \"\n",
      "  2521                                                           f\"Review series: {not_valid_index}\"\n",
      "  2522                                                       )\n",
      "  2523                                           \n",
      "  2524         1       3040.0   3040.0      1.5          indexes_freq = [f\"{v.index.freq}\" for v in series_dict.values()]\n",
      "  2525         1        101.0    101.0      0.0          indexes_freq = sorted(set(indexes_freq))\n",
      "  2526         1          8.0      8.0      0.0          if not len(indexes_freq) == 1:\n",
      "  2527                                                       raise ValueError(\n",
      "  2528                                                           f\"If `series` is a dictionary, all series must have a Pandas \"\n",
      "  2529                                                           f\"DatetimeIndex as index with the same frequency. \"\n",
      "  2530                                                           f\"Found frequencies: {indexes_freq}\"\n",
      "  2531                                                       )\n",
      "  2532                                               else:\n",
      "  2533                                                   raise TypeError(\n",
      "  2534                                                       f\"`series` must be a pandas DataFrame or a dict of DataFrames or Series. \"\n",
      "  2535                                                       f\"Got {type(series)}.\"\n",
      "  2536                                                   )\n",
      "  2537                                           \n",
      "  2538       100        533.0      5.3      0.3      for k, v in series_dict.items():\n",
      "  2539        99     118845.0   1200.5     58.6          if v.isna().to_numpy().all():\n",
      "  2540                                                       raise ValueError(f\"All values of series '{k}' are NaN.\")\n",
      "  2541                                           \n",
      "  2542         2       1438.0    719.0      0.7      series_indexes = {\n",
      "  2543                                                   k: v.index\n",
      "  2544         1         18.0     18.0      0.0          for k, v in series_dict.items()\n",
      "  2545                                               }\n",
      "  2546                                           \n",
      "  2547         1         10.0     10.0      0.0      return series_dict, series_indexes"
     ]
    }
   ],
   "source": [
    "def funt_to_profile(series_dict):\n",
    "    check_preprocess_series(series=series_dict)\n",
    "\n",
    "%lprun -f check_preprocess_series funt_to_profile(series_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%pyinstrument\n",
    "# x_train, y_train = forecaster.create_train_X_y(\n",
    "#     series = series_dict,\n",
    "#     exog=exog_dict\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "n = 5000\n",
    "series = pd.DataFrame(\n",
    "    {i: np.random.randint(1, 100, n) for i in range(1, 100)\n",
    "    },\n",
    "    index=pd.date_range(start=\"2023-01-01\", periods=n, freq=\"h\"),\n",
    ")\n",
    "\n",
    "freq = series.index.freq\n",
    "series.index.name = \"datetime\"\n",
    "series = series.reset_index()\n",
    "series = pd.melt(series, id_vars=\"datetime\", var_name=\"series_id\", value_name=\"value\")\n",
    "series = series.groupby(\"series_id\").apply(\n",
    "    lambda x: x.set_index(\"datetime\").asfreq(\"D\"), include_groups=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract MultiIndex levels\n",
    "ids = series.index.get_level_values(0).to_numpy()\n",
    "dates = series.index.get_level_values(1).astype('datetime64[ns]').to_numpy()\n",
    "\n",
    "# Ensure sorting by (id, datetime)\n",
    "sort_idx = np.lexsort((dates, ids))\n",
    "ids = ids[sort_idx]\n",
    "dates_ns = dates[sort_idx].view('int64')\n",
    "\n",
    "@njit\n",
    "def most_common_deltas(ids, dates_ns, max_check=1000):\n",
    "    result_ids = []\n",
    "    result_deltas = []\n",
    "\n",
    "    start = 0\n",
    "    n = len(ids)\n",
    "\n",
    "    while start < n:\n",
    "        current_id = ids[start]\n",
    "        end = start + 1\n",
    "        while end < n and ids[end] == current_id:\n",
    "            end += 1\n",
    "\n",
    "        # Extract time series slice\n",
    "        series = dates_ns[start:end]\n",
    "        count = min(len(series) - 1, max_check)\n",
    "        \n",
    "        if count < 1:\n",
    "            result_ids.append(current_id)\n",
    "            result_deltas.append(-1)  # No data\n",
    "            start = end\n",
    "            continue\n",
    "\n",
    "        delta_counts = {}\n",
    "        for i in range(count):\n",
    "            delta = series[i + 1] - series[i]\n",
    "            if delta in delta_counts:\n",
    "                delta_counts[delta] += 1\n",
    "            else:\n",
    "                delta_counts[delta] = 1\n",
    "\n",
    "        # Find most common delta\n",
    "        max_delta = -1\n",
    "        max_count = -1\n",
    "        for delta, cnt in delta_counts.items():\n",
    "            if cnt > max_count:\n",
    "                max_delta = delta\n",
    "                max_count = cnt\n",
    "\n",
    "        result_ids.append(current_id)\n",
    "        result_deltas.append(max_delta)\n",
    "        start = end\n",
    "\n",
    "    return result_ids, result_deltas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_ids, deltas_ns = most_common_deltas(ids, dates_ns)\n",
    "\n",
    "# Convert to pandas timedelta64\n",
    "freqs = {}\n",
    "for uid, delta in zip(unique_ids, deltas_ns):\n",
    "    if delta == -1:\n",
    "        freqs[uid] = None  # Not enough data\n",
    "    else:\n",
    "        freqs[uid] = pd.Timedelta(delta, unit='ns')  # Convert to pandas Timedelta\n",
    "freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqstr_ = pd.date_range(start=\"2023-01-01\", periods=10, freq='ME').freqstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex([], dtype='datetime64[ns]', freq='ME')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range(start=\"2023-01-01\", end=\"2023-01-10\", freq=freqstr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cdb2994c-43d8-472b-859d-11d9f309d1f0",
       "rows": [
        [
         "2023-01-01 00:00:00",
         "0"
        ],
        [
         "2023-01-02 00:00:00",
         "1"
        ],
        [
         "2023-01-03 00:00:00",
         "2"
        ],
        [
         "2023-01-04 00:00:00",
         "3"
        ],
        [
         "2023-01-05 00:00:00",
         "4"
        ],
        [
         "2023-01-06 00:00:00",
         "5"
        ],
        [
         "2023-01-07 00:00:00",
         "6"
        ],
        [
         "2023-01-08 00:00:00",
         "7"
        ],
        [
         "2023-01-09 00:00:00",
         "8"
        ],
        [
         "2023-01-10 00:00:00",
         "9"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "2023-01-01    0\n",
       "2023-01-02    1\n",
       "2023-01-03    2\n",
       "2023-01-04    3\n",
       "2023-01-05    4\n",
       "2023-01-06    5\n",
       "2023-01-07    6\n",
       "2023-01-08    7\n",
       "2023-01-09    8\n",
       "2023-01-10    9\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(np.arange(10), index=pd.date_range(start=\"2023-01-01\", periods=10, freq='D'))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2e9faa8f-4edb-4d46-aaf9-708b1f4f1869",
       "rows": [
        [
         "2023-01-01 00:00:00",
         "0"
        ],
        [
         "2023-01-02 00:00:00",
         "1"
        ],
        [
         "2023-01-03 00:00:00",
         "2"
        ],
        [
         "2023-01-04 00:00:00",
         "3"
        ],
        [
         "2023-01-05 00:00:00",
         "4"
        ],
        [
         "2023-01-06 00:00:00",
         "5"
        ],
        [
         "2023-01-07 00:00:00",
         "6"
        ],
        [
         "2023-01-08 00:00:00",
         "7"
        ],
        [
         "2023-01-09 00:00:00",
         "8"
        ],
        [
         "2023-01-10 00:00:00",
         "9"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "2023-01-01    0\n",
       "2023-01-02    1\n",
       "2023-01-03    2\n",
       "2023-01-04    3\n",
       "2023-01-05    4\n",
       "2023-01-06    5\n",
       "2023-01-07    6\n",
       "2023-01-08    7\n",
       "2023-01-09    8\n",
       "2023-01-10    9\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc['2021-01-01':'2024-01-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py11_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
