{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jaesc2\\\\GitHub\\\\skforecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(1, str(Path.cwd().parent))\n",
    "str(Path.cwd().parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import psutil\n",
    "import skforecast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from skforecast.recursive import ForecasterRecursiveMultiSeries\n",
    "from skforecast.model_selection import grid_search_forecaster_multiseries\n",
    "from skforecast.utils.utils import align_series_and_exog_multiseries\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from skforecast.preprocessing import series_long_to_dict\n",
    "from skforecast.preprocessing import exog_long_to_dict\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.utils import check_preprocess_series\n",
    "\n",
    "\n",
    "%load_ext pyinstrument\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('series_id', 'datetime')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "value",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "ca544943-42af-43d1-8556-bc6bb9903d71",
       "rows": [
        [
         "('series_1', Timestamp('2023-01-01 00:00:00'))",
         "99"
        ],
        [
         "('series_1', Timestamp('2023-01-02 00:00:00'))",
         "61"
        ],
        [
         "('series_1', Timestamp('2023-01-03 00:00:00'))",
         "47"
        ],
        [
         "('series_1', Timestamp('2023-01-04 00:00:00'))",
         "58"
        ],
        [
         "('series_1', Timestamp('2023-01-05 00:00:00'))",
         "78"
        ],
        [
         "('series_1', Timestamp('2023-01-06 00:00:00'))",
         "81"
        ],
        [
         "('series_1', Timestamp('2023-01-07 00:00:00'))",
         "67"
        ],
        [
         "('series_1', Timestamp('2023-01-08 00:00:00'))",
         "68"
        ],
        [
         "('series_1', Timestamp('2023-01-09 00:00:00'))",
         "68"
        ],
        [
         "('series_1', Timestamp('2023-01-10 00:00:00'))",
         "47"
        ],
        [
         "('series_1', Timestamp('2023-01-11 00:00:00'))",
         "94"
        ],
        [
         "('series_1', Timestamp('2023-01-12 00:00:00'))",
         "36"
        ],
        [
         "('series_1', Timestamp('2023-01-13 00:00:00'))",
         "25"
        ],
        [
         "('series_1', Timestamp('2023-01-14 00:00:00'))",
         "22"
        ],
        [
         "('series_1', Timestamp('2023-01-15 00:00:00'))",
         "14"
        ],
        [
         "('series_1', Timestamp('2023-01-16 00:00:00'))",
         "40"
        ],
        [
         "('series_1', Timestamp('2023-01-17 00:00:00'))",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-01-18 00:00:00'))",
         "51"
        ],
        [
         "('series_1', Timestamp('2023-01-19 00:00:00'))",
         "99"
        ],
        [
         "('series_1', Timestamp('2023-01-20 00:00:00'))",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-01-21 00:00:00'))",
         "60"
        ],
        [
         "('series_1', Timestamp('2023-01-22 00:00:00'))",
         "71"
        ],
        [
         "('series_1', Timestamp('2023-01-23 00:00:00'))",
         "25"
        ],
        [
         "('series_1', Timestamp('2023-01-24 00:00:00'))",
         "49"
        ],
        [
         "('series_1', Timestamp('2023-01-25 00:00:00'))",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-01-26 00:00:00'))",
         "71"
        ],
        [
         "('series_1', Timestamp('2023-01-27 00:00:00'))",
         "29"
        ],
        [
         "('series_1', Timestamp('2023-01-28 00:00:00'))",
         "39"
        ],
        [
         "('series_1', Timestamp('2023-01-29 00:00:00'))",
         "99"
        ],
        [
         "('series_1', Timestamp('2023-01-30 00:00:00'))",
         "96"
        ],
        [
         "('series_1', Timestamp('2023-01-31 00:00:00'))",
         "27"
        ],
        [
         "('series_1', Timestamp('2023-02-01 00:00:00'))",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-02-02 00:00:00'))",
         "80"
        ],
        [
         "('series_1', Timestamp('2023-02-03 00:00:00'))",
         "12"
        ],
        [
         "('series_1', Timestamp('2023-02-04 00:00:00'))",
         "19"
        ],
        [
         "('series_1', Timestamp('2023-02-05 00:00:00'))",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-02-06 00:00:00'))",
         "64"
        ],
        [
         "('series_1', Timestamp('2023-02-07 00:00:00'))",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-02-08 00:00:00'))",
         "71"
        ],
        [
         "('series_1', Timestamp('2023-02-09 00:00:00'))",
         "27"
        ],
        [
         "('series_1', Timestamp('2023-02-10 00:00:00'))",
         "82"
        ],
        [
         "('series_1', Timestamp('2023-02-11 00:00:00'))",
         "27"
        ],
        [
         "('series_1', Timestamp('2023-02-12 00:00:00'))",
         "55"
        ],
        [
         "('series_1', Timestamp('2023-02-13 00:00:00'))",
         "10"
        ],
        [
         "('series_1', Timestamp('2023-02-14 00:00:00'))",
         "69"
        ],
        [
         "('series_1', Timestamp('2023-02-15 00:00:00'))",
         "90"
        ],
        [
         "('series_1', Timestamp('2023-02-16 00:00:00'))",
         "39"
        ],
        [
         "('series_1', Timestamp('2023-02-17 00:00:00'))",
         "27"
        ],
        [
         "('series_1', Timestamp('2023-02-18 00:00:00'))",
         "6"
        ],
        [
         "('series_1', Timestamp('2023-02-19 00:00:00'))",
         "13"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2495000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">series_1</th>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">series_499</th>\n",
       "      <th>2036-09-04</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-05</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-06</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-07</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-08</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2495000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       value\n",
       "series_id  datetime         \n",
       "series_1   2023-01-01     99\n",
       "           2023-01-02     61\n",
       "           2023-01-03     47\n",
       "           2023-01-04     58\n",
       "           2023-01-05     78\n",
       "...                      ...\n",
       "series_499 2036-09-04     92\n",
       "           2036-09-05     70\n",
       "           2036-09-06     60\n",
       "           2036-09-07     22\n",
       "           2036-09-08     89\n",
       "\n",
       "[2495000 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('series_id', 'datetime')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "exog_1",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "exog_2",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "exog_3",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "exog_4",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "exog_5",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "exog_6",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "61fff47b-beab-4f70-b810-498aa003b21c",
       "rows": [
        [
         "('series_1', Timestamp('2023-01-01 00:00:00'))",
         "1",
         "6",
         "9",
         "8",
         "1",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-02 00:00:00'))",
         "5",
         "7",
         "2",
         "8",
         "7",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-01-03 00:00:00'))",
         "7",
         "7",
         "1",
         "7",
         "3",
         "9"
        ],
        [
         "('series_1', Timestamp('2023-01-04 00:00:00'))",
         "1",
         "9",
         "5",
         "2",
         "3",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-05 00:00:00'))",
         "8",
         "7",
         "8",
         "2",
         "6",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-06 00:00:00'))",
         "7",
         "9",
         "9",
         "8",
         "2",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-07 00:00:00'))",
         "7",
         "5",
         "8",
         "4",
         "8",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-01-08 00:00:00'))",
         "5",
         "2",
         "9",
         "3",
         "5",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-01-09 00:00:00'))",
         "7",
         "9",
         "6",
         "2",
         "6",
         "6"
        ],
        [
         "('series_1', Timestamp('2023-01-10 00:00:00'))",
         "4",
         "5",
         "8",
         "5",
         "4",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-11 00:00:00'))",
         "2",
         "6",
         "6",
         "1",
         "7",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-01-12 00:00:00'))",
         "8",
         "8",
         "5",
         "4",
         "1",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-13 00:00:00'))",
         "9",
         "8",
         "3",
         "2",
         "9",
         "9"
        ],
        [
         "('series_1', Timestamp('2023-01-14 00:00:00'))",
         "5",
         "2",
         "4",
         "5",
         "5",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-15 00:00:00'))",
         "3",
         "1",
         "1",
         "2",
         "3",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-01-16 00:00:00'))",
         "2",
         "4",
         "8",
         "7",
         "2",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-01-17 00:00:00'))",
         "4",
         "6",
         "4",
         "5",
         "4",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-01-18 00:00:00'))",
         "8",
         "9",
         "3",
         "3",
         "2",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-01-19 00:00:00'))",
         "4",
         "9",
         "6",
         "3",
         "2",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-01-20 00:00:00'))",
         "3",
         "2",
         "2",
         "7",
         "5",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-01-21 00:00:00'))",
         "7",
         "4",
         "5",
         "8",
         "1",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-22 00:00:00'))",
         "4",
         "1",
         "9",
         "7",
         "7",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-23 00:00:00'))",
         "4",
         "1",
         "2",
         "9",
         "6",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-01-24 00:00:00'))",
         "2",
         "3",
         "4",
         "1",
         "9",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-01-25 00:00:00'))",
         "6",
         "5",
         "2",
         "8",
         "6",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-01-26 00:00:00'))",
         "8",
         "6",
         "3",
         "9",
         "6",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-01-27 00:00:00'))",
         "1",
         "7",
         "5",
         "7",
         "7",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-01-28 00:00:00'))",
         "6",
         "8",
         "4",
         "4",
         "9",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-01-29 00:00:00'))",
         "6",
         "3",
         "2",
         "5",
         "5",
         "6"
        ],
        [
         "('series_1', Timestamp('2023-01-30 00:00:00'))",
         "2",
         "6",
         "2",
         "5",
         "7",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-01-31 00:00:00'))",
         "4",
         "9",
         "5",
         "2",
         "8",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-02-01 00:00:00'))",
         "7",
         "8",
         "7",
         "8",
         "5",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-02-02 00:00:00'))",
         "5",
         "7",
         "7",
         "4",
         "2",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-02-03 00:00:00'))",
         "5",
         "6",
         "8",
         "4",
         "6",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-02-04 00:00:00'))",
         "8",
         "8",
         "8",
         "1",
         "7",
         "6"
        ],
        [
         "('series_1', Timestamp('2023-02-05 00:00:00'))",
         "1",
         "3",
         "5",
         "8",
         "8",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-02-06 00:00:00'))",
         "4",
         "9",
         "7",
         "6",
         "8",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-02-07 00:00:00'))",
         "5",
         "1",
         "3",
         "1",
         "5",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-02-08 00:00:00'))",
         "4",
         "1",
         "8",
         "7",
         "2",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-02-09 00:00:00'))",
         "3",
         "6",
         "7",
         "5",
         "7",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-02-10 00:00:00'))",
         "4",
         "3",
         "3",
         "4",
         "9",
         "4"
        ],
        [
         "('series_1', Timestamp('2023-02-11 00:00:00'))",
         "8",
         "3",
         "7",
         "7",
         "7",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-02-12 00:00:00'))",
         "1",
         "7",
         "3",
         "3",
         "9",
         "5"
        ],
        [
         "('series_1', Timestamp('2023-02-13 00:00:00'))",
         "9",
         "1",
         "5",
         "2",
         "6",
         "2"
        ],
        [
         "('series_1', Timestamp('2023-02-14 00:00:00'))",
         "5",
         "6",
         "5",
         "2",
         "8",
         "3"
        ],
        [
         "('series_1', Timestamp('2023-02-15 00:00:00'))",
         "8",
         "7",
         "3",
         "4",
         "9",
         "6"
        ],
        [
         "('series_1', Timestamp('2023-02-16 00:00:00'))",
         "5",
         "9",
         "2",
         "2",
         "9",
         "8"
        ],
        [
         "('series_1', Timestamp('2023-02-17 00:00:00'))",
         "5",
         "9",
         "9",
         "1",
         "5",
         "7"
        ],
        [
         "('series_1', Timestamp('2023-02-18 00:00:00'))",
         "7",
         "1",
         "7",
         "7",
         "6",
         "1"
        ],
        [
         "('series_1', Timestamp('2023-02-19 00:00:00'))",
         "4",
         "1",
         "3",
         "6",
         "3",
         "8"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 2495000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>exog_1</th>\n",
       "      <th>exog_2</th>\n",
       "      <th>exog_3</th>\n",
       "      <th>exog_4</th>\n",
       "      <th>exog_5</th>\n",
       "      <th>exog_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">series_1</th>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">series_499</th>\n",
       "      <th>2036-09-04</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-05</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-06</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-07</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036-09-08</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2495000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       exog_1  exog_2  exog_3  exog_4  exog_5  exog_6\n",
       "series_id  datetime                                                  \n",
       "series_1   2023-01-01       1       6       9       8       1       1\n",
       "           2023-01-02       5       7       2       8       7       8\n",
       "           2023-01-03       7       7       1       7       3       9\n",
       "           2023-01-04       1       9       5       2       3       3\n",
       "           2023-01-05       8       7       8       2       6       3\n",
       "...                       ...     ...     ...     ...     ...     ...\n",
       "series_499 2036-09-04       8       6       7       1       2       8\n",
       "           2036-09-05       9       4       1       8       4       9\n",
       "           2036-09-06       6       4       4       3       6       9\n",
       "           2036-09-07       2       9       1       4       8       6\n",
       "           2036-09-08       7       9       5       9       5       5\n",
       "\n",
       "[2495000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5000\n",
    "n_series = 500\n",
    "series = pd.DataFrame(\n",
    "    {f\"series_{i}\": np.random.randint(1, 100, n) for i in range(1, n_series)\n",
    "    },\n",
    "    index=pd.date_range(start=\"2023-01-01\", periods=n, freq=\"D\"),\n",
    ")\n",
    "\n",
    "freq = series.index.freq\n",
    "series.index.name = \"datetime\"\n",
    "series = series.reset_index()\n",
    "series = pd.melt(series, id_vars=\"datetime\", var_name=\"series_id\", value_name=\"value\")\n",
    "series = series.groupby(\"series_id\", sort=False).apply(\n",
    "    lambda x: x.set_index(\"datetime\").asfreq(\"D\"), include_groups=False\n",
    ")\n",
    "display(series)\n",
    "\n",
    "exog = pd.DataFrame(\n",
    "    {\n",
    "        \"exog_1\": np.random.randint(1, 10, n),\n",
    "        \"exog_2\": np.random.randint(1, 10, n),\n",
    "        \"exog_3\": np.random.randint(1, 10, n),\n",
    "        \"exog_4\": np.random.randint(1, 10, n),\n",
    "        \"exog_5\": np.random.randint(1, 10, n),\n",
    "        \"exog_6\": np.random.randint(1, 10, n),\n",
    "    },\n",
    "    index=pd.date_range(start=\"2023-01-01\", periods=n, freq=\"D\"),\n",
    ")\n",
    "exog.index.name= \"datetime\"\n",
    "exog = [exog.assign(series_id=f\"series_{i}\") for i in range(1, n_series)]\n",
    "# exog = [exog_i.copy().sample(frac=0.8).sort_index() for exog_i in exog]\n",
    "exog = pd.concat(exog)\n",
    "exog = exog.set_index([\"series_id\", exog.index])\n",
    "display(exog)\n",
    "\n",
    "# Formato dict\n",
    "series_dict = {\n",
    "    sid: series.loc[sid]['value'] for sid in series.index.levels[0]\n",
    "}\n",
    "\n",
    "exog_dict = {\n",
    "    sid: exog.loc[sid]for sid in exog.index.levels[0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 ms Â± 4.67 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "series_dict = {\n",
    "    sid: series.loc[sid]['value'] for sid in series.index.levels[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_no_idx = series.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761 ms Â± 15.5 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "series_2 = series_long_to_dict(series_no_idx, series_id=\"series_id\", index=\"datetime\", values=\"value\", freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = pd.DataFrame(\n",
    "    {\n",
    "        \"exog_1\": np.random.randint(1, 10, n),\n",
    "        \"exog_2\": np.random.randint(1, 10, n),\n",
    "        \"exog_3\": np.random.randint(1, 10, n),\n",
    "        \"exog_4\": np.random.randint(1, 10, n),\n",
    "        \"exog_5\": np.random.randint(1, 10, n),\n",
    "        \"exog_6\": np.random.randint(1, 10, n),\n",
    "    },\n",
    "    index=pd.date_range(start=\"2023-01-01\", periods=n, freq=\"D\"),\n",
    ")\n",
    "exog.index.name= \"datetime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "exog_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exog_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exog_6",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "68ddae96-9030-4dc7-9b0d-dd749c19b6c6",
       "rows": [
        [
         "2023-01-01 00:00:00",
         "-0.9128709291752769",
         "-0.8825226081218281",
         "-1.2893167424406087"
        ],
        [
         "2023-01-02 00:00:00",
         "-0.9128709291752769",
         "1.0786387432600122",
         "-0.8864052604279183"
        ],
        [
         "2023-01-03 00:00:00",
         "0.0",
         "1.0786387432600122",
         "1.1281521496355325"
        ],
        [
         "2023-01-04 00:00:00",
         "1.8257418583505538",
         "-1.372812945967288",
         "1.1281521496355325"
        ],
        [
         "2023-01-05 00:00:00",
         "0.0",
         "0.098058067569092",
         "-0.08058229640253804"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exog_4</th>\n",
       "      <th>exog_5</th>\n",
       "      <th>exog_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>-0.912871</td>\n",
       "      <td>-0.882523</td>\n",
       "      <td>-1.289317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>-0.912871</td>\n",
       "      <td>1.078639</td>\n",
       "      <td>-0.886405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.078639</td>\n",
       "      <td>1.128152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>1.825742</td>\n",
       "      <td>-1.372813</td>\n",
       "      <td>1.128152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098058</td>\n",
       "      <td>-0.080582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              exog_4    exog_5    exog_6\n",
       "datetime                                \n",
       "2023-01-01 -0.912871 -0.882523 -1.289317\n",
       "2023-01-02 -0.912871  1.078639 -0.886405\n",
       "2023-01-03  0.000000  1.078639  1.128152\n",
       "2023-01-04  1.825742 -1.372813  1.128152\n",
       "2023-01-05  0.000000  0.098058 -0.080582"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skforecast.utils import transform_dataframe\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "exog_tmp = transform_dataframe(\n",
    "            df                = exog[[\"exog_4\", \"exog_5\", \"exog_6\"]],\n",
    "            transformer       = StandardScaler(),\n",
    "            fit               = True,\n",
    "            inverse_transform = False\n",
    "        )\n",
    "exog_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exog_tmp.columns == exog_names_in_:\n",
    "    exog[[\"exog_4\", \"exog_5\", \"exog_6\"]] = exog_tmp\n",
    "else:\n",
    "    exog = pd.concat([exog, exog_tmp], axis=1)\n",
    "    exog = exog.drop(columns=[col for col in exog.columns if col not in [\"exog_4\", \"exog_5\", \"exog_6\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterRecursiveMultiSeries(regressor=LGBMRegressor(verbose=-1), lags=5, transformer_exog=StandardScaler())\n",
    "forecaster.transformer_series_ = {k: StandardScaler() for k in series.index.get_level_values(0).unique()}\n",
    "forecaster.differentiator_ = {k: None for k in series.index.get_level_values(0).unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = forecaster._create_train_X_y_v2(\n",
    "    series = series,\n",
    "    exog = exog\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2 = forecaster._create_train_X_y(\n",
    "    series = series,\n",
    "    exog = exog\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from skforecast.exceptions import MissingValuesWarning\n",
    "\n",
    "warnings.simplefilter('ignore', category=MissingValuesWarning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491 ms Â± 34.7 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 5\n",
    "\n",
    "forecaster._create_train_X_y(\n",
    "    series = series,\n",
    "    exog = exog\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 ms Â± 49.7 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 5\n",
    "\n",
    "forecaster._create_train_X_y_v2(\n",
    "    series = series,\n",
    "    exog = exog\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([95, 16, 60, ..., 15, 84, 40], shape=(5000,), dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.loc['series_1'].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.loc['series_1'].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mforecaster\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_train_X_y_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:93\u001b[39m, in \u001b[36m_create_train_X_y_v2\u001b[39m\u001b[34m(self, series, exog, store_last_window)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\pandas\\core\\frame.py:5767\u001b[39m, in \u001b[36mDataFrame.rename\u001b[39m\u001b[34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[39m\n\u001b[32m   5636\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrename\u001b[39m(\n\u001b[32m   5637\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5638\u001b[39m     mapper: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5646\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5647\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5648\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5649\u001b[39m \u001b[33;03m    Rename columns or index labels.\u001b[39;00m\n\u001b[32m   5650\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5765\u001b[39m \u001b[33;03m    4  3  6\u001b[39;00m\n\u001b[32m   5766\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5767\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_rename\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5768\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5769\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5770\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5771\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5772\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5773\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5774\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5775\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5776\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\pandas\\core\\generic.py:1132\u001b[39m, in \u001b[36mNDFrame._rename\u001b[39m\u001b[34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[39m\n\u001b[32m   1125\u001b[39m         missing_labels = [\n\u001b[32m   1126\u001b[39m             label\n\u001b[32m   1127\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m index, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(replacements)\n\u001b[32m   1128\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m indexer[index] == -\u001b[32m1\u001b[39m\n\u001b[32m   1129\u001b[39m         ]\n\u001b[32m   1130\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1132\u001b[39m new_index = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_transform_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1133\u001b[39m result._set_axis_nocheck(new_index, axis=axis_no, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1134\u001b[39m result._clear_item_cache()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6537\u001b[39m, in \u001b[36mIndex._transform_index\u001b[39m\u001b[34m(self, func, level)\u001b[39m\n\u001b[32m   6535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_arrays(values)\n\u001b[32m   6536\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m6537\u001b[39m     items = \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   6538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Index(items, name=\u001b[38;5;28mself\u001b[39m.name, tupleize_cols=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6537\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   6535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_arrays(values)\n\u001b[32m   6536\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m6537\u001b[39m     items = [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m]\n\u001b[32m   6538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Index(items, name=\u001b[38;5;28mself\u001b[39m.name, tupleize_cols=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "forecaster._create_train_X_y_v2(\n",
    "    series = series,\n",
    "    exog = exog\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 ms Â± 22.5 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 5\n",
    "\n",
    "forecaster._create_train_X_y(\n",
    "    series = series_dict,\n",
    "    exog = exog_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.datetimes.DatetimeIndex"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.index_type_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.datetimes.DatetimeIndex"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(series.index.levels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pandas.core.indexes.base.Index, pandas.core.indexes.datetimes.DatetimeIndex]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(idx) for idx in series.index.levels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "idx = pd.date_range('2024-01-01', periods=3, freq='D')\n",
    "\n",
    "# OpciÃ³n 1: Comparar como string\n",
    "print(idx.dtype == 'datetime64[ns]')   # True\n",
    "\n",
    "# OpciÃ³n 2: Comparar usando numpy dtype\n",
    "import numpy as np\n",
    "print(idx.dtype == np.dtype('datetime64[ns]'))  # True\n",
    "\n",
    "# OpciÃ³n 3: Comprobar tipo de columna en DataFrame\n",
    "df = pd.DataFrame(index=idx)\n",
    "print(df.index.dtype == 'datetime64[ns]')  # True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dtype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r 5 -n 5\n",
    "# _ = forecaster._create_train_X_y(\n",
    "#     series = series,\n",
    "#     exog=exog\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 ms Â± 9.64 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 5 -n 5\n",
    "_ = forecaster._create_train_X_y_v2(\n",
    "    series = series,\n",
    "    exog=exog\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m _ = \u001b[43mforecaster\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create_train_X_y_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexog\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:107\u001b[39m, in \u001b[36m_create_train_X_y_v2\u001b[39m\u001b[34m(self, series, exog, store_last_window)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\recursive\\_forecaster_recursive_multiseries.py:886\u001b[39m, in \u001b[36mForecasterRecursiveMultiSeries._create_train_X_y_single_series\u001b[39m\u001b[34m(self, y, ignore_exog, exog)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    885\u001b[39m     fit_transformer = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_fitted \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m     transformer_series = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer_series_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mseries_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    888\u001b[39m y_values = y.to_numpy()\n\u001b[32m    889\u001b[39m y_index = y.index\n",
      "\u001b[31mKeyError\u001b[39m: 'value'"
     ]
    }
   ],
   "source": [
    "_ = forecaster._create_train_X_y_v2(\n",
    "                            series = series,\n",
    "                            exog=exog\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,   5000,  10000,  15000,  20000,  25000,  30000,  35000,\n",
       "        40000,  45000,  50000,  55000,  60000,  65000,  70000,  75000,\n",
       "        80000,  85000,  90000,  95000, 100000, 105000, 110000, 115000,\n",
       "       120000, 125000, 130000, 135000, 140000, 145000, 150000, 155000,\n",
       "       160000, 165000, 170000, 175000, 180000, 185000, 190000, 195000,\n",
       "       200000, 205000, 210000, 215000, 220000, 225000, 230000, 235000,\n",
       "       240000, 245000, 250000, 255000, 260000, 265000, 270000, 275000,\n",
       "       280000, 285000, 290000, 295000, 300000, 305000, 310000, 315000,\n",
       "       320000, 325000, 330000, 335000, 340000, 345000, 350000, 355000,\n",
       "       360000, 365000, 370000, 375000, 380000, 385000, 390000, 395000,\n",
       "       400000, 405000, 410000, 415000, 420000, 425000, 430000, 435000,\n",
       "       440000, 445000, 450000, 455000, 460000, 465000, 470000, 475000,\n",
       "       480000, 485000, 490000])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_level_0 = series.index.get_level_values(0)\n",
    "unique_series = series_level_0.unique()\n",
    "\n",
    "# Opcional: crea un buffer de posiciones de inicio/fin para cada serie\n",
    "idx_start = series_level_0.searchsorted(unique_series, side='left')\n",
    "idx_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 1.19015 s\n",
      "File: c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\recursive\\_forecaster_recursive_multiseries.py\n",
      "Function: _create_train_X_y_v2 at line 1426\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1426                                               def _create_train_X_y_v2(\n",
      "  1427                                                   self,\n",
      "  1428                                                   series: pd.DataFrame,\n",
      "  1429                                                   exog: pd.Series | pd.DataFrame | None = None,\n",
      "  1430                                                   store_last_window: bool | list[str] = True,\n",
      "  1431                                               ) -> tuple[\n",
      "  1432                                                   pd.DataFrame,\n",
      "  1433                                                   pd.Series,\n",
      "  1434                                                   dict[str, pd.Index],\n",
      "  1435                                                   list[str],\n",
      "  1436                                                   list[str],\n",
      "  1437                                                   list[str],\n",
      "  1438                                                   list[str],\n",
      "  1439                                                   list[str],\n",
      "  1440                                                   dict[str, type],\n",
      "  1441                                                   dict[str, pd.Series],\n",
      "  1442                                               ]:\n",
      "  1443                                                   \"\"\"\n",
      "  1444                                                   Create training matrices from multiple time series and exogenous\n",
      "  1445                                                   variables.\n",
      "  1446                                                   \n",
      "  1447                                                   Parameters\n",
      "  1448                                                   ----------\n",
      "  1449                                                   series : pandas DataFrame\n",
      "  1450                                                       Pandas DataFrame with the time series to be used for training. Two \n",
      "  1451                                                       formats are accepted:\n",
      "  1452                                           \n",
      "  1453                                                       - Wide format: pandas DataFrame where each column is a time series\n",
      "  1454                                                       (level). The same index is shared by all series and it must be a\n",
      "  1455                                                       pandas DatetimeIndex with a frequency. \n",
      "  1456                                                       - Long format: pandas DataFrame with two level multi-index. The first\n",
      "  1457                                                       level is the series name and the second level is the datetime index.\n",
      "  1458                                                       The datetime index must be a pandas DatetimeIndex with a frequency. And\n",
      "  1459                                                       all series must have the same frequency.\n",
      "  1460                                                   exog : pandas Series, pandas DataFrame default None\n",
      "  1461                                                       Exogenous variable/s included as predictor/s. Two formats are accepted:\n",
      "  1462                                           \n",
      "  1463                                                       - Same exog for all series: pandas Series or DataFrame with a single\n",
      "  1464                                                       DatetimeIndex. Same exog values are used for all series.\n",
      "  1465                                                       - Different exog for each series: a pandas DataFrame with a\n",
      "  1466                                                       multi-index where the first level is the series name and the second\n",
      "  1467                                                       level is the datetime index. The datetime index must be a pandas\n",
      "  1468                                                       DatetimeIndex.\n",
      "  1469                                                   store_last_window : bool, list, default True\n",
      "  1470                                                       Whether or not to store the last window (`last_window_`) of training data.\n",
      "  1471                                           \n",
      "  1472                                                       - If `True`, last window is stored for all series. \n",
      "  1473                                                       - If `list`, last window is stored for the series present in the list.\n",
      "  1474                                                       - If `False`, last window is not stored.\n",
      "  1475                                           \n",
      "  1476                                                   Returns\n",
      "  1477                                                   -------\n",
      "  1478                                                   X_train : pandas DataFrame\n",
      "  1479                                                       Training values (predictors).\n",
      "  1480                                                   y_train : pandas Series\n",
      "  1481                                                       Values of the time series related to each row of `X_train`.\n",
      "  1482                                                   series_indexes : dict\n",
      "  1483                                                       Dictionary with the index of each series.\n",
      "  1484                                                   series_names_in_ : list\n",
      "  1485                                                       Names of the series (levels) provided by the user during training.\n",
      "  1486                                                   X_train_series_names_in_ : list\n",
      "  1487                                                       Names of the series (levels) included in the matrix `X_train` created\n",
      "  1488                                                       internally for training. It can be different from `series_names_in_` if\n",
      "  1489                                                       some series are dropped during the training process because of NaNs or\n",
      "  1490                                                       because they are not present in the training period.\n",
      "  1491                                                   exog_names_in_ : list\n",
      "  1492                                                       Names of the exogenous variables used during training.\n",
      "  1493                                                   X_train_window_features_names_out_ : list\n",
      "  1494                                                       Names of the window features included in the matrix `X_train` created\n",
      "  1495                                                       internally for training.\n",
      "  1496                                                   X_train_exog_names_out_ : list\n",
      "  1497                                                       Names of the exogenous variables included in the matrix `X_train` created\n",
      "  1498                                                       internally for training. It can be different from `exog_names_in_` if\n",
      "  1499                                                       some exogenous variables are transformed during the training process.\n",
      "  1500                                                   exog_dtypes_in_ : dict\n",
      "  1501                                                       Type of each exogenous variable/s used in training. If `transformer_exog` \n",
      "  1502                                                       is used, the dtypes are calculated before the transformation.\n",
      "  1503                                                   last_window_ : dict\n",
      "  1504                                                       Last window of training data for each series. It stores the values \n",
      "  1505                                                       needed to predict the next `step` immediately after the training data.\n",
      "  1506                                                   \n",
      "  1507                                                   \"\"\"\n",
      "  1508                                           \n",
      "  1509         1        735.0    735.0      0.0          series = check_preprocess_series(series=series)\n",
      "  1510         1        277.0    277.0      0.0          series_names_in_ = series.index.levels[0].to_list()\n",
      "  1511                                           \n",
      "  1512         1         33.0     33.0      0.0          if self.is_fitted and not set(series_names_in_).issubset(set(self.series_names_in_)):\n",
      "  1513                                                       raise ValueError(\n",
      "  1514                                                           f\"Once the Forecaster has been trained, `series` must contain \"\n",
      "  1515                                                           f\"the same series names as those used during training:\\n\"\n",
      "  1516                                                           f\" Got      : {series_names_in_}\\n\"\n",
      "  1517                                                           f\" Expected : {self.series_names_in_}\"\n",
      "  1518                                                       )\n",
      "  1519                                           \n",
      "  1520         1          9.0      9.0      0.0          exog_names_in_ = None\n",
      "  1521         1          9.0      9.0      0.0          X_train_exog_names_out_ = None\n",
      "  1522         1          4.0      4.0      0.0          if exog is not None:\n",
      "  1523         2      16465.0   8232.5      0.1              exog, exog_names_in_ = check_preprocess_exog_multiseries(\n",
      "  1524         1          8.0      8.0      0.0                                         series_indexes       = series.index,\n",
      "  1525         1          6.0      6.0      0.0                                         series_names_in_     = series_names_in_,\n",
      "  1526         1          2.0      2.0      0.0                                         exog                 = exog,\n",
      "  1527                                                                              )\n",
      "  1528                                           \n",
      "  1529         1         53.0     53.0      0.0              if self.is_fitted:\n",
      "  1530                                                           if self.exog_names_in_ is None:\n",
      "  1531                                                               raise ValueError(\n",
      "  1532                                                                   \"Once the Forecaster has been trained, `exog` must be `None` \"\n",
      "  1533                                                                   \"because no exogenous variables were added during training.\"\n",
      "  1534                                                               )\n",
      "  1535                                                           else:\n",
      "  1536                                                               if not set(exog_names_in_) == set(self.exog_names_in_):\n",
      "  1537                                                                   raise ValueError(\n",
      "  1538                                                                       f\"Once the Forecaster has been trained, `exog` must contain \"\n",
      "  1539                                                                       f\"the same exogenous variables as those used during training:\\n\"\n",
      "  1540                                                                       f\" Got      : {exog_names_in_}\\n\"\n",
      "  1541                                                                       f\" Expected : {self.exog_names_in_}\"\n",
      "  1542                                                                   )\n",
      "  1543                                                       \n",
      "  1544                                                       # series = pd.merge(series, exog, left_index=True, right_index=True, how='left')\n",
      "  1545                                           \n",
      "  1546         1          4.0      4.0      0.0          if not self.is_fitted:\n",
      "  1547         2        814.0    407.0      0.0              self.transformer_series_ = initialize_transformer_series(\n",
      "  1548         1         20.0     20.0      0.0                                             forecaster_name    = type(self).__name__,\n",
      "  1549         1          4.0      4.0      0.0                                             series_names_in_   = series_names_in_,\n",
      "  1550         1          9.0      9.0      0.0                                             encoding           = self.encoding,\n",
      "  1551         1          4.0      4.0      0.0                                             transformer_series = self.transformer_series\n",
      "  1552                                                                                  )\n",
      "  1553                                                       \n",
      "  1554         2        696.0    348.0      0.0              self.differentiator_ = initialize_differentiator_multiseries(\n",
      "  1555         1          4.0      4.0      0.0                                         series_names_in_ = series_names_in_,\n",
      "  1556         1          8.0      8.0      0.0                                         differentiator   = self.differentiator\n",
      "  1557                                                                              )\n",
      "  1558                                           \n",
      "  1559                                                   # TODO: deprecate in next release\n",
      "  1560         1          8.0      8.0      0.0          ignore_exog = True if exog is None else False\n",
      "  1561                                                   \n",
      "  1562                                                   # exog = series.iloc[:, 1:] if exog is not None else None\n",
      "  1563                                                   # series = series.iloc[:, 0]\n",
      "  1564                                           \n",
      "  1565         1         11.0     11.0      0.0          if not self.is_fitted and self.transformer_series_['_unknown_level'] is not None:\n",
      "  1566                                                       self.transformer_series_['_unknown_level'].fit(series)\n",
      "  1567                                                   \n",
      "  1568         1        160.0    160.0      0.0          is_datetime_index = True if isinstance(series.index.levels[1], pd.DatetimeIndex) else False\n",
      "  1569         1          8.0      8.0      0.0          series_indexes = {}\n",
      "  1570         1         24.0     24.0      0.0          indexes_freq = set()\n",
      "  1571                                           \n",
      "  1572         1          5.0      5.0      0.0          X_train_autoreg_buffer = []\n",
      "  1573                                                   # X_train_exog_buffer = []\n",
      "  1574         1          4.0      4.0      0.0          y_train_buffer = []\n",
      "  1575       100       1137.0     11.4      0.0          for series_id in series_names_in_:\n",
      "  1576                                                       \n",
      "  1577        99    1154340.0  11660.0      9.7              series_i = series.loc[series_id]\n",
      "  1578                                                       # exog_i = exog.loc[series_id, :] if exog is not None else None\n",
      "  1579                                                       \n",
      "  1580        99       2242.0     22.6      0.0              series_indexes[series_id] = series_i.index\n",
      "  1581        99        491.0      5.0      0.0              if is_datetime_index:\n",
      "  1582        99      45587.0    460.5      0.4                  indexes_freq.add(series_i.index.freqstr)\n",
      "  1583                                                       else:\n",
      "  1584                                                           indexes_freq.add(series_i.index.step)\n",
      "  1585                                           \n",
      "  1586        99     189834.0   1917.5      1.6              if series_i.isna().to_numpy().all():\n",
      "  1587                                                           raise ValueError(\n",
      "  1588                                                               f\"All values of series '{series_id}' are NaN. Please, \"\n",
      "  1589                                                               f\"remove series with all NaN values before training the forecaster.\"\n",
      "  1590                                                           )\n",
      "  1591                                           \n",
      "  1592        99        931.0      9.4      0.0              (\n",
      "  1593        99        565.0      5.7      0.0                  X_train_autoreg,\n",
      "  1594        99        348.0      3.5      0.0                  X_train_window_features_names_out_,\n",
      "  1595        99        440.0      4.4      0.0                  X_train_exog,\n",
      "  1596        99        399.0      4.0      0.0                  y_train\n",
      "  1597       198    1825758.0   9221.0     15.3              ) = self._create_train_X_y_single_series_v2(\n",
      "  1598        99        507.0      5.1      0.0                      y           = series_i,\n",
      "  1599        99        525.0      5.3      0.0                      series_id   = series_id,\n",
      "  1600        99        659.0      6.7      0.0                      ignore_exog = True,\n",
      "  1601                                                               # exog        = exog_i\n",
      "  1602                                                           )\n",
      "  1603                                                       \n",
      "  1604        99       1724.0     17.4      0.0              X_train_autoreg_buffer.append(X_train_autoreg)\n",
      "  1605                                                       # X_train_exog_buffer.append(X_train_exog)\n",
      "  1606        99       1294.0     13.1      0.0              y_train_buffer.append(y_train)\n",
      "  1607                                           \n",
      "  1608         1         15.0     15.0      0.0          if not len(indexes_freq) == 1:\n",
      "  1609                                                       raise ValueError(\n",
      "  1610                                                           f\"When using a DatetimeIndex, all series must have the same \"\n",
      "  1611                                                           f\"frequency. Found frequencies: {indexes_freq}\"\n",
      "  1612                                                       )\n",
      "  1613         1         15.0     15.0      0.0          if indexes_freq == [None]:\n",
      "  1614                                                       raise TypeError(\n",
      "  1615                                                           \"Series have a pandas DatetimeIndex without frequancy. When \"\n",
      "  1616                                                           \"using a DatetimeIndex, all series must have the same frequency. \"\n",
      "  1617                                                           \"To avoid this error, set the frequency of the index using: \"\n",
      "  1618                                                           \"series.groupby('series_id').apply(lambda x: x.set_index('datetime').asfreq('D'),\"\n",
      "  1619                                                           \"include_groups=False)\"\n",
      "  1620                                                       )\n",
      "  1621                                           \n",
      "  1622         1     351489.0 351489.0      3.0          X_train = pd.concat(X_train_autoreg_buffer, axis=0)\n",
      "  1623         1      72974.0  72974.0      0.6          y_train = pd.concat(y_train_buffer, axis=0)\n",
      "  1624                                           \n",
      "  1625         1      50722.0  50722.0      0.4          X_train['series_id'] = X_train['_level_skforecast']\n",
      "  1626         1    1577066.0    2e+06     13.3          X_train = X_train.reset_index().set_index(['series_id', 'datetime'])\n",
      "  1627                                           \n",
      "  1628         1        191.0    191.0      0.0          if self.is_fitted:\n",
      "  1629                                                       encoded_values = self.encoder.transform(X_train[['_level_skforecast']])\n",
      "  1630                                                   else:\n",
      "  1631         1    2795711.0    3e+06     23.5              encoded_values = self.encoder.fit_transform(X_train[['_level_skforecast']])\n",
      "  1632       100       1407.0     14.1      0.0              for i, code in enumerate(self.encoder.categories_[0]):\n",
      "  1633        99        935.0      9.4      0.0                  self.encoding_mapping_[code] = i\n",
      "  1634                                           \n",
      "  1635         1        139.0    139.0      0.0          if self.encoding == 'onehot': \n",
      "  1636                                                       X_train = pd.concat([\n",
      "  1637                                                                     X_train.drop(columns='_level_skforecast'),\n",
      "  1638                                                                     encoded_values\n",
      "  1639                                                                 ], axis=1)\n",
      "  1640                                                       X_train.columns = X_train.columns.str.replace('_level_skforecast_', '')\n",
      "  1641                                                   else:\n",
      "  1642         1      70800.0  70800.0      0.6              X_train['_level_skforecast'] = encoded_values\n",
      "  1643                                           \n",
      "  1644         1        104.0    104.0      0.0          if self.encoding == 'ordinal_category':\n",
      "  1645                                                       X_train['_level_skforecast'] = (\n",
      "  1646                                                           X_train['_level_skforecast'].astype('category')\n",
      "  1647                                                       )\n",
      "  1648                                           \n",
      "  1649         1       4751.0   4751.0      0.0          del encoded_values\n",
      "  1650                                           \n",
      "  1651         1         13.0     13.0      0.0          exog_dtypes_in_ = None\n",
      "  1652         1         17.0     17.0      0.0          if exog is not None:\n",
      "  1653         1     977971.0 977971.0      8.2              X_train = pd.merge(X_train, exog, left_index=True, right_index=True, how='left')\n",
      "  1654         1      44733.0  44733.0      0.4              exog_tmp = X_train.iloc[:, -len(exog.columns):]\n",
      "  1655                                           \n",
      "  1656         1        118.0    118.0      0.0              exog_names_in_ = exog_tmp.columns.to_list()\n",
      "  1657         1       4763.0   4763.0      0.0              exog_dtypes_in_ = get_exog_dtypes(exog=exog_tmp)\n",
      "  1658                                           \n",
      "  1659         1         24.0     24.0      0.0              fit_transformer = False if self.is_fitted else True\n",
      "  1660         2    1173126.0 586563.0      9.9              exog_tmp = transform_dataframe(\n",
      "  1661         1          3.0      3.0      0.0                             df                = exog_tmp,\n",
      "  1662         1         16.0     16.0      0.0                             transformer       = self.transformer_exog,\n",
      "  1663         1          3.0      3.0      0.0                             fit               = fit_transformer,\n",
      "  1664         1          3.0      3.0      0.0                             inverse_transform = False\n",
      "  1665                                                                  )\n",
      "  1666                                           \n",
      "  1667         1      17841.0  17841.0      0.1              check_exog_dtypes(exog_tmp, call_check_exog=False)\n",
      "  1668         1         63.0     63.0      0.0              X_train_exog_names_out_ = exog_tmp.columns.to_list()\n",
      "  1669                                           \n",
      "  1670         1        720.0    720.0      0.0              if exog.columns.equals(exog_tmp.columns):\n",
      "  1671         1     115350.0 115350.0      1.0                  X_train[exog.columns] = exog_tmp\n",
      "  1672                                                       else:\n",
      "  1673                                                           X_train = pd.concat([X_train.iloc[:, :-len(exog_tmp.columns)], exog_tmp], axis=1)\n",
      "  1674                                           \n",
      "  1675         1      19980.0  19980.0      0.2              del exog_tmp\n",
      "  1676                                           \n",
      "  1677         1      10649.0  10649.0      0.1          if y_train.isna().to_numpy().any():\n",
      "  1678                                                       mask = y_train.notna().to_numpy()\n",
      "  1679                                                       y_train = y_train.iloc[mask]\n",
      "  1680                                                       X_train = X_train.iloc[mask,]\n",
      "  1681                                                       warnings.warn(\n",
      "  1682                                                           \"NaNs detected in `y_train`. They have been dropped because the \"\n",
      "  1683                                                           \"target variable cannot have NaN values. Same rows have been \"\n",
      "  1684                                                           \"dropped from `X_train` to maintain alignment. This is caused by \"\n",
      "  1685                                                           \"series with interspersed NaNs.\",\n",
      "  1686                                                           MissingValuesWarning\n",
      "  1687                                                       )\n",
      "  1688                                           \n",
      "  1689         1         48.0     48.0      0.0          if self.dropna_from_series:\n",
      "  1690                                                       if np.any(X_train.isnull().to_numpy()):\n",
      "  1691                                                           mask = X_train.notna().all(axis=1).to_numpy()\n",
      "  1692                                                           X_train = X_train.iloc[mask, ]\n",
      "  1693                                                           y_train = y_train.iloc[mask]\n",
      "  1694                                                           warnings.warn(\n",
      "  1695                                                               \"NaNs detected in `X_train`. They have been dropped. If \"\n",
      "  1696                                                               \"you want to keep them, set `forecaster.dropna_from_series = False`. \"\n",
      "  1697                                                               \"Same rows have been removed from `y_train` to maintain alignment. \"\n",
      "  1698                                                               \"This caused by series with interspersed NaNs.\",\n",
      "  1699                                                               MissingValuesWarning\n",
      "  1700                                                           )\n",
      "  1701                                                   else:\n",
      "  1702         1     252420.0 252420.0      2.1              if np.any(X_train.isnull().to_numpy()):\n",
      "  1703                                                           warnings.warn(\n",
      "  1704                                                               \"NaNs detected in `X_train`. Some regressors do not allow \"\n",
      "  1705                                                               \"NaN values during training. If you want to drop them, \"\n",
      "  1706                                                               \"set `forecaster.dropna_from_series = True`.\",\n",
      "  1707                                                               MissingValuesWarning\n",
      "  1708                                                           )\n",
      "  1709                                           \n",
      "  1710         1       1199.0   1199.0      0.0          if X_train.empty:\n",
      "  1711                                                       raise ValueError(\n",
      "  1712                                                           \"All samples have been removed due to NaNs. Set \"\n",
      "  1713                                                           \"`forecaster.dropna_from_series = False` or review `exog` values.\"\n",
      "  1714                                                       )\n",
      "  1715                                                   \n",
      "  1716         1         88.0     88.0      0.0          if self.encoding == 'onehot':\n",
      "  1717                                                       X_train_series_names_in_ = [\n",
      "  1718                                                           col for col in series_names_in_ if X_train[col].sum() > 0\n",
      "  1719                                                       ]\n",
      "  1720                                                   else:\n",
      "  1721         1      64132.0  64132.0      0.5              unique_levels = X_train['_level_skforecast'].unique()\n",
      "  1722         2      11137.0   5568.5      0.1              X_train_series_names_in_ = [\n",
      "  1723         1         31.0     31.0      0.0                  k for k, v in self.encoding_mapping_.items()\n",
      "  1724                                                           if v in unique_levels\n",
      "  1725                                                       ]\n",
      "  1726                                           \n",
      "  1727                                                   # NOTE: The last time window of training data is stored so that lags needed \n",
      "  1728                                                   # as predictors in the first iteration of `predict()` can be calculated.\n",
      "  1729         1          9.0      9.0      0.0          last_window_ = None\n",
      "  1730         1         10.0     10.0      0.0          if store_last_window:\n",
      "  1731                                           \n",
      "  1732         1          5.0      5.0      0.0              series_to_store = (\n",
      "  1733         1          8.0      8.0      0.0                  X_train_series_names_in_ if store_last_window is True else store_last_window\n",
      "  1734                                                       )\n",
      "  1735                                           \n",
      "  1736         1        320.0    320.0      0.0              series_not_in_series_dict = set(series_to_store) - set(X_train_series_names_in_)\n",
      "  1737         1        144.0    144.0      0.0              if series_not_in_series_dict:\n",
      "  1738                                                           warnings.warn(\n",
      "  1739                                                               f\"Series {series_not_in_series_dict} are not present in \"\n",
      "  1740                                                               f\"`series`. No last window is stored for them.\",\n",
      "  1741                                                               IgnoredArgumentWarning\n",
      "  1742                                                           )\n",
      "  1743                                                           series_to_store = [\n",
      "  1744                                                               s for s in series_to_store \n",
      "  1745                                                               if s not in series_not_in_series_dict\n",
      "  1746                                                           ]\n",
      "  1747                                           \n",
      "  1748         1         10.0     10.0      0.0              if series_to_store:\n",
      "  1749         2    1034048.0 517024.0      8.7                  last_window_ = {\n",
      "  1750                                                               series_id: series.loc[series_id].iloc[-self.window_size:]\n",
      "  1751         1          3.0      3.0      0.0                      for series_id in series_to_store\n",
      "  1752                                                           }\n",
      "  1753                                           \n",
      "  1754         1          6.0      6.0      0.0          return (\n",
      "  1755         1          6.0      6.0      0.0              X_train,\n",
      "  1756         1          6.0      6.0      0.0              y_train,\n",
      "  1757         1          3.0      3.0      0.0              series_indexes,\n",
      "  1758         1          6.0      6.0      0.0              series_names_in_,\n",
      "  1759         1          2.0      2.0      0.0              X_train_series_names_in_,\n",
      "  1760         1          3.0      3.0      0.0              exog_names_in_,\n",
      "  1761         1          2.0      2.0      0.0              X_train_window_features_names_out_,\n",
      "  1762         1          4.0      4.0      0.0              X_train_exog_names_out_,\n",
      "  1763         1          5.0      5.0      0.0              exog_dtypes_in_,\n",
      "  1764         1          4.0      4.0      0.0              last_window_\n",
      "  1765                                                   )"
     ]
    }
   ],
   "source": [
    "def funt_to_profile(forecaster, series, exog):\n",
    "    _ = forecaster._create_train_X_y_v2(\n",
    "                            series = series,\n",
    "                            exog=exog\n",
    "                        )\n",
    "\n",
    "%lprun -f forecaster._create_train_X_y_v2 funt_to_profile(forecaster, series, exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493 ms Â± 46.1 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 5 -n 5\n",
    "_ = forecaster._create_train_X_y_v3(\n",
    "    series = series,\n",
    "    exog=exog\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.98568 s\n",
      "File: c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\recursive\\_forecaster_recursive_multiseries.py\n",
      "Function: _create_train_X_y at line 959\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   959                                               def _create_train_X_y(\n",
      "   960                                                   self,\n",
      "   961                                                   series: pd.DataFrame,\n",
      "   962                                                   exog: pd.Series | pd.DataFrame | None = None,\n",
      "   963                                                   store_last_window: bool | list[str] = True,\n",
      "   964                                               ) -> tuple[\n",
      "   965                                                   pd.DataFrame,\n",
      "   966                                                   pd.Series,\n",
      "   967                                                   dict[str, pd.Index],\n",
      "   968                                                   list[str],\n",
      "   969                                                   list[str],\n",
      "   970                                                   list[str],\n",
      "   971                                                   list[str],\n",
      "   972                                                   list[str],\n",
      "   973                                                   dict[str, type],\n",
      "   974                                                   dict[str, pd.Series],\n",
      "   975                                               ]:\n",
      "   976                                                   \"\"\"\n",
      "   977                                                   Create training matrices from multiple time series and exogenous\n",
      "   978                                                   variables.\n",
      "   979                                                   \n",
      "   980                                                   Parameters\n",
      "   981                                                   ----------\n",
      "   982                                                   series : pandas DataFrame\n",
      "   983                                                       Pandas DataFrame with the time series to be used for training. Two \n",
      "   984                                                       formats are accepted:\n",
      "   985                                           \n",
      "   986                                                       - Wide format: pandas DataFrame where each column is a time series\n",
      "   987                                                       (level). The same index is shared by all series and it must be a\n",
      "   988                                                       pandas DatetimeIndex with a frequency. \n",
      "   989                                                       - Long format: pandas DataFrame with two level multi-index. The first\n",
      "   990                                                       level is the series name and the second level is the datetime index.\n",
      "   991                                                       The datetime index must be a pandas DatetimeIndex with a frequency. And\n",
      "   992                                                       all series must have the same frequency.\n",
      "   993                                                   exog : pandas Series, pandas DataFrame default None\n",
      "   994                                                       Exogenous variable/s included as predictor/s. Two formats are accepted:\n",
      "   995                                           \n",
      "   996                                                       - Same exog for all series: pandas Series or DataFrame with a single\n",
      "   997                                                       DatetimeIndex. Same exog values are used for all series.\n",
      "   998                                                       - Different exog for each series: a pandas DataFrame with a\n",
      "   999                                                       multi-index where the first level is the series name and the second\n",
      "  1000                                                       level is the datetime index. The datetime index must be a pandas\n",
      "  1001                                                       DatetimeIndex.\n",
      "  1002                                                   store_last_window : bool, list, default True\n",
      "  1003                                                       Whether or not to store the last window (`last_window_`) of training data.\n",
      "  1004                                           \n",
      "  1005                                                       - If `True`, last window is stored for all series. \n",
      "  1006                                                       - If `list`, last window is stored for the series present in the list.\n",
      "  1007                                                       - If `False`, last window is not stored.\n",
      "  1008                                           \n",
      "  1009                                                   Returns\n",
      "  1010                                                   -------\n",
      "  1011                                                   X_train : pandas DataFrame\n",
      "  1012                                                       Training values (predictors).\n",
      "  1013                                                   y_train : pandas Series\n",
      "  1014                                                       Values of the time series related to each row of `X_train`.\n",
      "  1015                                                   series_indexes : dict\n",
      "  1016                                                       Dictionary with the index of each series.\n",
      "  1017                                                   series_names_in_ : list\n",
      "  1018                                                       Names of the series (levels) provided by the user during training.\n",
      "  1019                                                   X_train_series_names_in_ : list\n",
      "  1020                                                       Names of the series (levels) included in the matrix `X_train` created\n",
      "  1021                                                       internally for training. It can be different from `series_names_in_` if\n",
      "  1022                                                       some series are dropped during the training process because of NaNs or\n",
      "  1023                                                       because they are not present in the training period.\n",
      "  1024                                                   exog_names_in_ : list\n",
      "  1025                                                       Names of the exogenous variables used during training.\n",
      "  1026                                                   X_train_window_features_names_out_ : list\n",
      "  1027                                                       Names of the window features included in the matrix `X_train` created\n",
      "  1028                                                       internally for training.\n",
      "  1029                                                   X_train_exog_names_out_ : list\n",
      "  1030                                                       Names of the exogenous variables included in the matrix `X_train` created\n",
      "  1031                                                       internally for training. It can be different from `exog_names_in_` if\n",
      "  1032                                                       some exogenous variables are transformed during the training process.\n",
      "  1033                                                   exog_dtypes_in_ : dict\n",
      "  1034                                                       Type of each exogenous variable/s used in training. If `transformer_exog` \n",
      "  1035                                                       is used, the dtypes are calculated before the transformation.\n",
      "  1036                                                   last_window_ : dict\n",
      "  1037                                                       Last window of training data for each series. It stores the values \n",
      "  1038                                                       needed to predict the next `step` immediately after the training data.\n",
      "  1039                                                   \n",
      "  1040                                                   \"\"\"\n",
      "  1041                                           \n",
      "  1042         1        644.0    644.0      0.0          series = check_preprocess_series(series=series)\n",
      "  1043         1        218.0    218.0      0.0          series_names_in_ = series.index.levels[0].to_list()\n",
      "  1044                                           \n",
      "  1045         1         10.0     10.0      0.0          if self.is_fitted and not set(series_names_in_).issubset(set(self.series_names_in_)):\n",
      "  1046                                                       raise ValueError(\n",
      "  1047                                                           f\"Once the Forecaster has been trained, `series` must contain \"\n",
      "  1048                                                           f\"the same series names as those used during training:\\n\"\n",
      "  1049                                                           f\" Got      : {series_names_in_}\\n\"\n",
      "  1050                                                           f\" Expected : {self.series_names_in_}\"\n",
      "  1051                                                       )\n",
      "  1052                                           \n",
      "  1053         1          7.0      7.0      0.0          exog_names_in_ = None\n",
      "  1054         1          8.0      8.0      0.0          X_train_exog_names_out_ = None\n",
      "  1055         1          7.0      7.0      0.0          if exog is not None:\n",
      "  1056         2       4705.0   2352.5      0.0              exog, exog_names_in_ = check_preprocess_exog_multiseries(\n",
      "  1057         1          7.0      7.0      0.0                                         series_indexes       = series.index,\n",
      "  1058         1          5.0      5.0      0.0                                         series_names_in_     = series_names_in_,\n",
      "  1059         1          6.0      6.0      0.0                                         exog                 = exog,\n",
      "  1060                                                                              )\n",
      "  1061                                           \n",
      "  1062         1         22.0     22.0      0.0              if self.is_fitted:\n",
      "  1063                                                           if self.exog_names_in_ is None:\n",
      "  1064                                                               raise ValueError(\n",
      "  1065                                                                   \"Once the Forecaster has been trained, `exog` must be `None` \"\n",
      "  1066                                                                   \"because no exogenous variables were added during training.\"\n",
      "  1067                                                               )\n",
      "  1068                                                           else:\n",
      "  1069                                                               if not set(exog_names_in_) == set(self.exog_names_in_):\n",
      "  1070                                                                   raise ValueError(\n",
      "  1071                                                                       f\"Once the Forecaster has been trained, `exog` must contain \"\n",
      "  1072                                                                       f\"the same exogenous variables as those used during training:\\n\"\n",
      "  1073                                                                       f\" Got      : {exog_names_in_}\\n\"\n",
      "  1074                                                                       f\" Expected : {self.exog_names_in_}\"\n",
      "  1075                                                                   )\n",
      "  1076                                                       \n",
      "  1077         1     799183.0 799183.0      8.1              series = pd.merge(series, exog, left_index=True, right_index=True, how='left')\n",
      "  1078                                           \n",
      "  1079         1        111.0    111.0      0.0          if not self.is_fitted:\n",
      "  1080         2        980.0    490.0      0.0              self.transformer_series_ = initialize_transformer_series(\n",
      "  1081         1        109.0    109.0      0.0                                             forecaster_name    = type(self).__name__,\n",
      "  1082         1         11.0     11.0      0.0                                             series_names_in_   = series_names_in_,\n",
      "  1083         1         18.0     18.0      0.0                                             encoding           = self.encoding,\n",
      "  1084         1          9.0      9.0      0.0                                             transformer_series = self.transformer_series\n",
      "  1085                                                                                  )\n",
      "  1086                                                       \n",
      "  1087         2        571.0    285.5      0.0              self.differentiator_ = initialize_differentiator_multiseries(\n",
      "  1088         1         19.0     19.0      0.0                                         series_names_in_ = series_names_in_,\n",
      "  1089         1         80.0     80.0      0.0                                         differentiator   = self.differentiator\n",
      "  1090                                                                              )\n",
      "  1091                                           \n",
      "  1092                                                   # TODO: deprecate in next release\n",
      "  1093         1         14.0     14.0      0.0          ignore_exog = True if exog is None else False\n",
      "  1094                                                   \n",
      "  1095         1     130207.0 130207.0      1.3          exog = series.iloc[:, 1:] if exog is not None else None\n",
      "  1096         1      17836.0  17836.0      0.2          series = series.iloc[:, 0]\n",
      "  1097                                           \n",
      "  1098         1        190.0    190.0      0.0          if not self.is_fitted and self.transformer_series_['_unknown_level'] is not None:\n",
      "  1099                                                       self.transformer_series_['_unknown_level'].fit(series)\n",
      "  1100                                                   \n",
      "  1101         1       3813.0   3813.0      0.0          is_datetime_index = True if isinstance(series.index.levels[1], pd.DatetimeIndex) else False\n",
      "  1102         1         13.0     13.0      0.0          series_indexes = {}\n",
      "  1103         1         96.0     96.0      0.0          indexes_freq = set()\n",
      "  1104                                           \n",
      "  1105         1          6.0      6.0      0.0          X_train_autoreg_buffer = []\n",
      "  1106         1         19.0     19.0      0.0          X_train_exog_buffer = []\n",
      "  1107         1          8.0      8.0      0.0          y_train_buffer = []\n",
      "  1108       100       1121.0     11.2      0.0          for series_id in series_names_in_:\n",
      "  1109                                                       \n",
      "  1110        99    1146723.0  11583.1     11.6              series_i = series.loc[series_id].rename(series_id)\n",
      "  1111        99     981791.0   9917.1     10.0              exog_i = exog.loc[series_id, :] if exog is not None else None\n",
      "  1112                                                       \n",
      "  1113        99       2480.0     25.1      0.0              series_indexes[series_id] = series_i.index\n",
      "  1114        99        448.0      4.5      0.0              if is_datetime_index:\n",
      "  1115        99      40488.0    409.0      0.4                  indexes_freq.add(series_i.index.freqstr)\n",
      "  1116                                                       else:\n",
      "  1117                                                           indexes_freq.add(series_i.index.step)\n",
      "  1118                                           \n",
      "  1119        99     295879.0   2988.7      3.0              if series_i.isna().to_numpy().all():\n",
      "  1120                                                           raise ValueError(\n",
      "  1121                                                               f\"All values of series '{series_id}' are NaN. Please, \"\n",
      "  1122                                                               f\"remove series with all NaN values before training the forecaster.\"\n",
      "  1123                                                           )\n",
      "  1124                                           \n",
      "  1125        99        697.0      7.0      0.0              (\n",
      "  1126        99        648.0      6.5      0.0                  X_train_autoreg,\n",
      "  1127        99        363.0      3.7      0.0                  X_train_window_features_names_out_,\n",
      "  1128        99        372.0      3.8      0.0                  X_train_exog,\n",
      "  1129        99        454.0      4.6      0.0                  y_train\n",
      "  1130       198    1980678.0  10003.4     20.1              ) = self._create_train_X_y_single_series(\n",
      "  1131        99        420.0      4.2      0.0                      y           = series_i,\n",
      "  1132        99        348.0      3.5      0.0                      ignore_exog = ignore_exog,\n",
      "  1133        99        324.0      3.3      0.0                      exog        = exog_i\n",
      "  1134                                                           )\n",
      "  1135                                                       \n",
      "  1136        99       1651.0     16.7      0.0              X_train_autoreg_buffer.append(X_train_autoreg)\n",
      "  1137        99        833.0      8.4      0.0              X_train_exog_buffer.append(X_train_exog)\n",
      "  1138        99       1260.0     12.7      0.0              y_train_buffer.append(y_train)\n",
      "  1139                                           \n",
      "  1140         1         38.0     38.0      0.0          if not len(indexes_freq) == 1:\n",
      "  1141                                                       raise ValueError(\n",
      "  1142                                                           f\"When using a DatetimeIndex, all series must have the same \"\n",
      "  1143                                                           f\"frequency. Found frequencies: {indexes_freq}\"\n",
      "  1144                                                       )\n",
      "  1145         1         21.0     21.0      0.0          if indexes_freq == [None]:\n",
      "  1146                                                       raise TypeError(\n",
      "  1147                                                           \"Series have a pandas DatetimeIndex without frequancy. When \"\n",
      "  1148                                                           \"using a DatetimeIndex, all series must have the same frequency. \"\n",
      "  1149                                                           \"To avoid this error, set the frequency of the index using: \"\n",
      "  1150                                                           \"series.groupby('series_id').apply(lambda x: x.set_index('datetime').asfreq('D'),\"\n",
      "  1151                                                           \"include_groups=False)\"\n",
      "  1152                                                       )\n",
      "  1153                                           \n",
      "  1154         1     268752.0 268752.0      2.7          X_train = pd.concat(X_train_autoreg_buffer, axis=0)\n",
      "  1155         1      53096.0  53096.0      0.5          y_train = pd.concat(y_train_buffer, axis=0)\n",
      "  1156                                           \n",
      "  1157         1         27.0     27.0      0.0          if self.is_fitted:\n",
      "  1158                                                       encoded_values = self.encoder.transform(X_train[['_level_skforecast']])\n",
      "  1159                                                   else:\n",
      "  1160         1    2165720.0    2e+06     22.0              encoded_values = self.encoder.fit_transform(X_train[['_level_skforecast']])\n",
      "  1161       100        573.0      5.7      0.0              for i, code in enumerate(self.encoder.categories_[0]):\n",
      "  1162        99        399.0      4.0      0.0                  self.encoding_mapping_[code] = i\n",
      "  1163                                           \n",
      "  1164         1         31.0     31.0      0.0          if self.encoding == 'onehot': \n",
      "  1165                                                       X_train = pd.concat([\n",
      "  1166                                                                     X_train.drop(columns='_level_skforecast'),\n",
      "  1167                                                                     encoded_values\n",
      "  1168                                                                 ], axis=1)\n",
      "  1169                                                       X_train.columns = X_train.columns.str.replace('_level_skforecast_', '')\n",
      "  1170                                                   else:\n",
      "  1171         1      28880.0  28880.0      0.3              X_train['_level_skforecast'] = encoded_values\n",
      "  1172                                           \n",
      "  1173         1         23.0     23.0      0.0          if self.encoding == 'ordinal_category':\n",
      "  1174                                                       X_train['_level_skforecast'] = (\n",
      "  1175                                                           X_train['_level_skforecast'].astype('category')\n",
      "  1176                                                       )\n",
      "  1177                                           \n",
      "  1178         1       2555.0   2555.0      0.0          del encoded_values\n",
      "  1179                                           \n",
      "  1180         1          7.0      7.0      0.0          exog_dtypes_in_ = None\n",
      "  1181         1          5.0      5.0      0.0          if exog is not None:\n",
      "  1182                                           \n",
      "  1183         1     146203.0 146203.0      1.5              X_train_exog = pd.concat(X_train_exog_buffer, axis=0)\n",
      "  1184                                                       # TODO: deprecate in next release\n",
      "  1185         1       2000.0   2000.0      0.0              if '_dummy_exog_col_to_keep_shape' in X_train_exog.columns:\n",
      "  1186                                                           X_train_exog = (\n",
      "  1187                                                               X_train_exog.drop(columns=['_dummy_exog_col_to_keep_shape'])\n",
      "  1188                                                           )\n",
      "  1189                                           \n",
      "  1190         1        120.0    120.0      0.0              exog_names_in_ = X_train_exog.columns.to_list()\n",
      "  1191         1       7863.0   7863.0      0.1              exog_dtypes_in_ = get_exog_dtypes(exog=X_train_exog)\n",
      "  1192                                           \n",
      "  1193         1         49.0     49.0      0.0              fit_transformer = False if self.is_fitted else True\n",
      "  1194         2     748849.0 374424.5      7.6              X_train_exog = transform_dataframe(\n",
      "  1195         1          7.0      7.0      0.0                                 df                = X_train_exog,\n",
      "  1196         1         15.0     15.0      0.0                                 transformer       = self.transformer_exog,\n",
      "  1197         1          6.0      6.0      0.0                                 fit               = fit_transformer,\n",
      "  1198         1          7.0      7.0      0.0                                 inverse_transform = False\n",
      "  1199                                                                      )\n",
      "  1200                                           \n",
      "  1201         1      29326.0  29326.0      0.3              check_exog_dtypes(X_train_exog, call_check_exog=False)\n",
      "  1202         1      27571.0  27571.0      0.3              if not (X_train_exog.index == X_train.index).all():\n",
      "  1203                                                           raise ValueError(\n",
      "  1204                                                               \"Different index for `series` and `exog` after transformation. \"\n",
      "  1205                                                               \"They must be equal to ensure the correct alignment of values.\"\n",
      "  1206                                                           )\n",
      "  1207                                           \n",
      "  1208         1        152.0    152.0      0.0              X_train_exog_names_out_ = X_train_exog.columns.to_list()\n",
      "  1209         1     171865.0 171865.0      1.7              X_train = pd.concat([X_train, X_train_exog], axis=1)\n",
      "  1210                                           \n",
      "  1211         1      11550.0  11550.0      0.1          if y_train.isna().to_numpy().any():\n",
      "  1212                                                       mask = y_train.notna().to_numpy()\n",
      "  1213                                                       y_train = y_train.iloc[mask]\n",
      "  1214                                                       X_train = X_train.iloc[mask,]\n",
      "  1215                                                       warnings.warn(\n",
      "  1216                                                           \"NaNs detected in `y_train`. They have been dropped because the \"\n",
      "  1217                                                           \"target variable cannot have NaN values. Same rows have been \"\n",
      "  1218                                                           \"dropped from `X_train` to maintain alignment. This is caused by \"\n",
      "  1219                                                           \"series with interspersed NaNs.\",\n",
      "  1220                                                           MissingValuesWarning\n",
      "  1221                                                       )\n",
      "  1222                                           \n",
      "  1223         1         91.0     91.0      0.0          if self.dropna_from_series:\n",
      "  1224                                                       if np.any(X_train.isnull().to_numpy()):\n",
      "  1225                                                           mask = X_train.notna().all(axis=1).to_numpy()\n",
      "  1226                                                           X_train = X_train.iloc[mask, ]\n",
      "  1227                                                           y_train = y_train.iloc[mask]\n",
      "  1228                                                           warnings.warn(\n",
      "  1229                                                               \"NaNs detected in `X_train`. They have been dropped. If \"\n",
      "  1230                                                               \"you want to keep them, set `forecaster.dropna_from_series = False`. \"\n",
      "  1231                                                               \"Same rows have been removed from `y_train` to maintain alignment. \"\n",
      "  1232                                                               \"This caused by series with interspersed NaNs.\",\n",
      "  1233                                                               MissingValuesWarning\n",
      "  1234                                                           )\n",
      "  1235                                                   else:\n",
      "  1236         1      98784.0  98784.0      1.0              if np.any(X_train.isnull().to_numpy()):\n",
      "  1237                                                           warnings.warn(\n",
      "  1238                                                               \"NaNs detected in `X_train`. Some regressors do not allow \"\n",
      "  1239                                                               \"NaN values during training. If you want to drop them, \"\n",
      "  1240                                                               \"set `forecaster.dropna_from_series = True`.\",\n",
      "  1241                                                               MissingValuesWarning\n",
      "  1242                                                           )\n",
      "  1243                                           \n",
      "  1244         1        395.0    395.0      0.0          if X_train.empty:\n",
      "  1245                                                       raise ValueError(\n",
      "  1246                                                           \"All samples have been removed due to NaNs. Set \"\n",
      "  1247                                                           \"`forecaster.dropna_from_series = False` or review `exog` values.\"\n",
      "  1248                                                       )\n",
      "  1249                                                   \n",
      "  1250         1         39.0     39.0      0.0          if self.encoding == 'onehot':\n",
      "  1251                                                       X_train_series_names_in_ = [\n",
      "  1252                                                           col for col in series_names_in_ if X_train[col].sum() > 0\n",
      "  1253                                                       ]\n",
      "  1254                                                   else:\n",
      "  1255         1      37397.0  37397.0      0.4              unique_levels = X_train['_level_skforecast'].unique()\n",
      "  1256         2       4442.0   2221.0      0.0              X_train_series_names_in_ = [\n",
      "  1257         1         30.0     30.0      0.0                  k for k, v in self.encoding_mapping_.items()\n",
      "  1258                                                           if v in unique_levels\n",
      "  1259                                                       ]\n",
      "  1260                                           \n",
      "  1261                                                   # NOTE: The last time window of training data is stored so that lags needed \n",
      "  1262                                                   # as predictors in the first iteration of `predict()` can be calculated.\n",
      "  1263         1          5.0      5.0      0.0          last_window_ = None\n",
      "  1264         1          4.0      4.0      0.0          if store_last_window:\n",
      "  1265                                           \n",
      "  1266         1          2.0      2.0      0.0              series_to_store = (\n",
      "  1267         1         10.0     10.0      0.0                  X_train_series_names_in_ if store_last_window is True else store_last_window\n",
      "  1268                                                       )\n",
      "  1269                                           \n",
      "  1270         1        164.0    164.0      0.0              series_not_in_series_dict = set(series_to_store) - set(X_train_series_names_in_)\n",
      "  1271         1          5.0      5.0      0.0              if series_not_in_series_dict:\n",
      "  1272                                                           warnings.warn(\n",
      "  1273                                                               f\"Series {series_not_in_series_dict} are not present in \"\n",
      "  1274                                                               f\"`series`. No last window is stored for them.\",\n",
      "  1275                                                               IgnoredArgumentWarning\n",
      "  1276                                                           )\n",
      "  1277                                                           series_to_store = [\n",
      "  1278                                                               s for s in series_to_store \n",
      "  1279                                                               if s not in series_not_in_series_dict\n",
      "  1280                                                           ]\n",
      "  1281                                           \n",
      "  1282         1          4.0      4.0      0.0              if series_to_store:\n",
      "  1283         2     633765.0 316882.5      6.4                  last_window_ = {\n",
      "  1284                                                               series_id: series.loc[series_id].iloc[-self.window_size:]\n",
      "  1285         1          3.0      3.0      0.0                      for series_id in series_to_store\n",
      "  1286                                                           }\n",
      "  1287                                           \n",
      "  1288         1          6.0      6.0      0.0          return (\n",
      "  1289         1          7.0      7.0      0.0              X_train,\n",
      "  1290         1          6.0      6.0      0.0              y_train,\n",
      "  1291         1          3.0      3.0      0.0              series_indexes,\n",
      "  1292         1          4.0      4.0      0.0              series_names_in_,\n",
      "  1293         1          2.0      2.0      0.0              X_train_series_names_in_,\n",
      "  1294         1          4.0      4.0      0.0              exog_names_in_,\n",
      "  1295         1          2.0      2.0      0.0              X_train_window_features_names_out_,\n",
      "  1296         1          3.0      3.0      0.0              X_train_exog_names_out_,\n",
      "  1297         1          5.0      5.0      0.0              exog_dtypes_in_,\n",
      "  1298         1          2.0      2.0      0.0              last_window_\n",
      "  1299                                                   )"
     ]
    }
   ],
   "source": [
    "def funt_to_profile(forecaster, series, exog):\n",
    "    _ = forecaster._create_train_X_y(\n",
    "                            series = series,\n",
    "                            exog=exog\n",
    "                        )\n",
    "\n",
    "%lprun -f forecaster._create_train_X_y funt_to_profile(forecaster, series, exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.4 ms Â± 5.9 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 5 -n 5\n",
    "{\n",
    "    sid: series.loc[sid]['value'] for sid in series.index.levels[0]\n",
    "}\n",
    "\n",
    "{\n",
    "    sid: exog.loc[sid]for sid in exog.index.levels[0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413 ms Â± 44.8 ms per loop (mean Â± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 5 -n 5\n",
    "_ = forecaster._create_train_X_y(\n",
    "    series = series_dict,\n",
    "    exog=exog_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.701712 s\n",
      "File: c:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\skforecast\\recursive\\_forecaster_recursive_multiseries.py\n",
      "Function: _create_train_X_y at line 1087\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  1087                                               def _create_train_X_y(\n",
      "  1088                                                   self,\n",
      "  1089                                                   series: pd.DataFrame | dict[str, pd.Series | pd.DataFrame],\n",
      "  1090                                                   exog: pd.Series | pd.DataFrame | dict[str, pd.Series | pd.DataFrame] | None = None,\n",
      "  1091                                                   store_last_window: bool | list[str] = True,\n",
      "  1092                                               ) -> tuple[\n",
      "  1093                                                   pd.DataFrame,\n",
      "  1094                                                   pd.Series,\n",
      "  1095                                                   dict[str, pd.Index],\n",
      "  1096                                                   list[str],\n",
      "  1097                                                   list[str],\n",
      "  1098                                                   list[str],\n",
      "  1099                                                   list[str],\n",
      "  1100                                                   list[str],\n",
      "  1101                                                   dict[str, type],\n",
      "  1102                                                   dict[str, pd.Series],\n",
      "  1103                                               ]:\n",
      "  1104                                                   \"\"\"\n",
      "  1105                                                   Create training matrices from multiple time series and exogenous\n",
      "  1106                                                   variables. See Notes section for more details depending on the type of\n",
      "  1107                                                   `series` and `exog`.\n",
      "  1108                                                   \n",
      "  1109                                                   Parameters\n",
      "  1110                                                   ----------\n",
      "  1111                                                   series : pandas DataFrame, dict\n",
      "  1112                                                       Training time series.\n",
      "  1113                                                   exog : pandas Series, pandas DataFrame, dict, default None\n",
      "  1114                                                       Exogenous variable/s included as predictor/s.\n",
      "  1115                                                   store_last_window : bool, list, default True\n",
      "  1116                                                       Whether or not to store the last window (`last_window_`) of training data.\n",
      "  1117                                           \n",
      "  1118                                                       - If `True`, last window is stored for all series. \n",
      "  1119                                                       - If `list`, last window is stored for the series present in the list.\n",
      "  1120                                                       - If `False`, last window is not stored.\n",
      "  1121                                           \n",
      "  1122                                                   Returns\n",
      "  1123                                                   -------\n",
      "  1124                                                   X_train : pandas DataFrame\n",
      "  1125                                                       Training values (predictors).\n",
      "  1126                                                   y_train : pandas Series\n",
      "  1127                                                       Values of the time series related to each row of `X_train`.\n",
      "  1128                                                   series_indexes : dict\n",
      "  1129                                                       Dictionary with the index of each series.\n",
      "  1130                                                   series_names_in_ : list\n",
      "  1131                                                       Names of the series (levels) provided by the user during training.\n",
      "  1132                                                   X_train_series_names_in_ : list\n",
      "  1133                                                       Names of the series (levels) included in the matrix `X_train` created\n",
      "  1134                                                       internally for training. It can be different from `series_names_in_` if\n",
      "  1135                                                       some series are dropped during the training process because of NaNs or\n",
      "  1136                                                       because they are not present in the training period.\n",
      "  1137                                                   exog_names_in_ : list\n",
      "  1138                                                       Names of the exogenous variables used during training.\n",
      "  1139                                                   X_train_window_features_names_out_ : list\n",
      "  1140                                                       Names of the window features included in the matrix `X_train` created\n",
      "  1141                                                       internally for training.\n",
      "  1142                                                   X_train_exog_names_out_ : list\n",
      "  1143                                                       Names of the exogenous variables included in the matrix `X_train` created\n",
      "  1144                                                       internally for training. It can be different from `exog_names_in_` if\n",
      "  1145                                                       some exogenous variables are transformed during the training process.\n",
      "  1146                                                   exog_dtypes_in_ : dict\n",
      "  1147                                                       Type of each exogenous variable/s used in training. If `transformer_exog` \n",
      "  1148                                                       is used, the dtypes are calculated before the transformation.\n",
      "  1149                                                   last_window_ : dict\n",
      "  1150                                                       Last window of training data for each series. It stores the values \n",
      "  1151                                                       needed to predict the next `step` immediately after the training data.\n",
      "  1152                                           \n",
      "  1153                                                   Notes\n",
      "  1154                                                   -----\n",
      "  1155                                                   - If `series` is a pandas DataFrame and `exog` is a pandas Series or \n",
      "  1156                                                   DataFrame, each exog is duplicated for each series. Exog must have the\n",
      "  1157                                                   same index as `series` (type, length and frequency).\n",
      "  1158                                                   - If `series` is a pandas DataFrame and `exog` is a dict of pandas Series \n",
      "  1159                                                   or DataFrames. Each key in `exog` must be a column in `series` and the \n",
      "  1160                                                   values are the exog for each series. Exog must have the same index as \n",
      "  1161                                                   `series` (type, length and frequency).\n",
      "  1162                                                   - If `series` is a dict of pandas Series, `exog` must be a dict of pandas\n",
      "  1163                                                   Series or DataFrames. The keys in `series` and `exog` must be the same.\n",
      "  1164                                                   All series and exog must have a pandas DatetimeIndex with the same \n",
      "  1165                                                   frequency.\n",
      "  1166                                                   \n",
      "  1167                                                   \"\"\"\n",
      "  1168                                           \n",
      "  1169         1     201399.0 201399.0      2.9          series_dict, series_indexes = check_preprocess_series(series=series)\n",
      "  1170         1         26.0     26.0      0.0          input_series_is_dict = isinstance(series, dict)\n",
      "  1171         1         54.0     54.0      0.0          series_names_in_ = list(series_dict.keys())\n",
      "  1172                                           \n",
      "  1173         1         42.0     42.0      0.0          if self.is_fitted and not set(series_names_in_).issubset(set(self.series_names_in_)):\n",
      "  1174                                                       raise ValueError(\n",
      "  1175                                                           f\"Once the Forecaster has been trained, `series` must contain \"\n",
      "  1176                                                           f\"the same series names as those used during training:\\n\"\n",
      "  1177                                                           f\" Got      : {series_names_in_}\\n\"\n",
      "  1178                                                           f\" Expected : {self.series_names_in_}\"\n",
      "  1179                                                       )\n",
      "  1180                                           \n",
      "  1181         1        287.0    287.0      0.0          exog_dict = {serie: None for serie in series_names_in_}\n",
      "  1182         1          4.0      4.0      0.0          exog_names_in_ = None\n",
      "  1183         1          3.0      3.0      0.0          X_train_exog_names_out_ = None\n",
      "  1184         1          4.0      4.0      0.0          if exog is not None:\n",
      "  1185         2     464439.0 232219.5      6.6              exog_dict, exog_names_in_ = check_preprocess_exog_multiseries(\n",
      "  1186         1          2.0      2.0      0.0                                              input_series_is_dict = input_series_is_dict,\n",
      "  1187         1          3.0      3.0      0.0                                              series_indexes       = series_indexes,\n",
      "  1188         1          1.0      1.0      0.0                                              series_names_in_     = series_names_in_,\n",
      "  1189         1          1.0      1.0      0.0                                              exog                 = exog,\n",
      "  1190         1          2.0      2.0      0.0                                              exog_dict            = exog_dict\n",
      "  1191                                                                                   )\n",
      "  1192                                           \n",
      "  1193         1         21.0     21.0      0.0              if self.is_fitted:\n",
      "  1194                                                           if self.exog_names_in_ is None:\n",
      "  1195                                                               raise ValueError(\n",
      "  1196                                                                   \"Once the Forecaster has been trained, `exog` must be `None` \"\n",
      "  1197                                                                   \"because no exogenous variables were added during training.\"\n",
      "  1198                                                               )\n",
      "  1199                                                           else:\n",
      "  1200                                                               if not set(exog_names_in_) == set(self.exog_names_in_):\n",
      "  1201                                                                   raise ValueError(\n",
      "  1202                                                                       f\"Once the Forecaster has been trained, `exog` must contain \"\n",
      "  1203                                                                       f\"the same exogenous variables as those used during training:\\n\"\n",
      "  1204                                                                       f\" Got      : {exog_names_in_}\\n\"\n",
      "  1205                                                                       f\" Expected : {self.exog_names_in_}\"\n",
      "  1206                                                                   )\n",
      "  1207                                           \n",
      "  1208         1          4.0      4.0      0.0          if not self.is_fitted:\n",
      "  1209         2        503.0    251.5      0.0              self.transformer_series_ = initialize_transformer_series(\n",
      "  1210         1         13.0     13.0      0.0                                             forecaster_name    = type(self).__name__,\n",
      "  1211         1          2.0      2.0      0.0                                             series_names_in_   = series_names_in_,\n",
      "  1212         1         20.0     20.0      0.0                                             encoding           = self.encoding,\n",
      "  1213         1         15.0     15.0      0.0                                             transformer_series = self.transformer_series\n",
      "  1214                                                                                  )\n",
      "  1215                                                       \n",
      "  1216         2        317.0    158.5      0.0              self.differentiator_ = initialize_differentiator_multiseries(\n",
      "  1217         1          2.0      2.0      0.0                                         series_names_in_ = series_names_in_,\n",
      "  1218         1          6.0      6.0      0.0                                         differentiator   = self.differentiator\n",
      "  1219                                                                              )\n",
      "  1220                                           \n",
      "  1221         2    1288362.0 644181.0     18.4          series_dict, exog_dict = align_series_and_exog_multiseries(\n",
      "  1222         1         10.0     10.0      0.0                                       series_dict          = series_dict,\n",
      "  1223         1          3.0      3.0      0.0                                       input_series_is_dict = input_series_is_dict,\n",
      "  1224         1          3.0      3.0      0.0                                       exog_dict            = exog_dict\n",
      "  1225                                                                            )\n",
      "  1226                                                   \n",
      "  1227         1         28.0     28.0      0.0          if not self.is_fitted and self.transformer_series_['_unknown_level'] is not None:\n",
      "  1228                                                       self.transformer_series_['_unknown_level'].fit(\n",
      "  1229                                                           np.concatenate(list(series_dict.values())).reshape(-1, 1)\n",
      "  1230                                                       )\n",
      "  1231                                           \n",
      "  1232         1          6.0      6.0      0.0          ignore_exog = True if exog is None else False\n",
      "  1233         2       1088.0    544.0      0.0          input_matrices = [\n",
      "  1234                                                       [series_dict[k], exog_dict[k], ignore_exog]\n",
      "  1235         1          5.0      5.0      0.0               for k in series_dict.keys()\n",
      "  1236                                                   ]\n",
      "  1237                                           \n",
      "  1238         1          4.0      4.0      0.0          X_train_autoreg_buffer = []\n",
      "  1239         1          3.0      3.0      0.0          X_train_exog_buffer = []\n",
      "  1240         1          4.0      4.0      0.0          y_train_buffer = []\n",
      "  1241       100        686.0      6.9      0.0          for matrices in input_matrices:\n",
      "  1242                                           \n",
      "  1243        99        453.0      4.6      0.0              (\n",
      "  1244        99        342.0      3.5      0.0                  X_train_autoreg,\n",
      "  1245        99        201.0      2.0      0.0                  X_train_window_features_names_out_,\n",
      "  1246        99        241.0      2.4      0.0                  X_train_exog,\n",
      "  1247        99        243.0      2.5      0.0                  y_train\n",
      "  1248       198    1197187.0   6046.4     17.1              ) = self._create_train_X_y_single_series(\n",
      "  1249        99        637.0      6.4      0.0                  y           = matrices[0],\n",
      "  1250        99        548.0      5.5      0.0                  exog        = matrices[1],\n",
      "  1251        99        289.0      2.9      0.0                  ignore_exog = matrices[2],\n",
      "  1252                                                       )\n",
      "  1253                                           \n",
      "  1254        99        880.0      8.9      0.0              X_train_autoreg_buffer.append(X_train_autoreg)\n",
      "  1255        99        449.0      4.5      0.0              X_train_exog_buffer.append(X_train_exog)\n",
      "  1256        99        531.0      5.4      0.0              y_train_buffer.append(y_train)\n",
      "  1257                                           \n",
      "  1258         1     222665.0 222665.0      3.2          X_train = pd.concat(X_train_autoreg_buffer, axis=0)\n",
      "  1259         1      62816.0  62816.0      0.9          y_train = pd.concat(y_train_buffer, axis=0)\n",
      "  1260                                           \n",
      "  1261         1         24.0     24.0      0.0          if self.is_fitted:\n",
      "  1262                                                       encoded_values = self.encoder.transform(X_train[['_level_skforecast']])\n",
      "  1263                                                   else:\n",
      "  1264         1    1761034.0    2e+06     25.1              encoded_values = self.encoder.fit_transform(X_train[['_level_skforecast']])\n",
      "  1265       100       1308.0     13.1      0.0              for i, code in enumerate(self.encoder.categories_[0]):\n",
      "  1266        99        585.0      5.9      0.0                  self.encoding_mapping_[code] = i\n",
      "  1267                                           \n",
      "  1268         1         51.0     51.0      0.0          if self.encoding == 'onehot': \n",
      "  1269                                                       X_train = pd.concat([\n",
      "  1270                                                                     X_train.drop(columns='_level_skforecast'),\n",
      "  1271                                                                     encoded_values\n",
      "  1272                                                                 ], axis=1)\n",
      "  1273                                                       X_train.columns = X_train.columns.str.replace('_level_skforecast_', '')\n",
      "  1274                                                   else:\n",
      "  1275         1      38713.0  38713.0      0.6              X_train['_level_skforecast'] = encoded_values\n",
      "  1276                                           \n",
      "  1277         1         30.0     30.0      0.0          if self.encoding == 'ordinal_category':\n",
      "  1278                                                       X_train['_level_skforecast'] = (\n",
      "  1279                                                           X_train['_level_skforecast'].astype('category')\n",
      "  1280                                                       )\n",
      "  1281                                           \n",
      "  1282         1       2048.0   2048.0      0.0          del encoded_values\n",
      "  1283                                           \n",
      "  1284         1          6.0      6.0      0.0          exog_dtypes_in_ = None\n",
      "  1285         1          8.0      8.0      0.0          if exog is not None:\n",
      "  1286                                           \n",
      "  1287         1     165760.0 165760.0      2.4              X_train_exog = pd.concat(X_train_exog_buffer, axis=0)\n",
      "  1288         1        337.0    337.0      0.0              if '_dummy_exog_col_to_keep_shape' in X_train_exog.columns:\n",
      "  1289                                                           X_train_exog = (\n",
      "  1290                                                               X_train_exog.drop(columns=['_dummy_exog_col_to_keep_shape'])\n",
      "  1291                                                           )\n",
      "  1292                                           \n",
      "  1293         1        169.0    169.0      0.0              exog_names_in_ = X_train_exog.columns.to_list()\n",
      "  1294         1      10626.0  10626.0      0.2              exog_dtypes_in_ = get_exog_dtypes(exog=X_train_exog)\n",
      "  1295                                           \n",
      "  1296         1        136.0    136.0      0.0              fit_transformer = False if self.is_fitted else True\n",
      "  1297         2    1223639.0 611819.5     17.4              X_train_exog = transform_dataframe(\n",
      "  1298         1         14.0     14.0      0.0                                 df                = X_train_exog,\n",
      "  1299         1         23.0     23.0      0.0                                 transformer       = self.transformer_exog,\n",
      "  1300         1          9.0      9.0      0.0                                 fit               = fit_transformer,\n",
      "  1301         1          3.0      3.0      0.0                                 inverse_transform = False\n",
      "  1302                                                                      )\n",
      "  1303                                           \n",
      "  1304         1      10065.0  10065.0      0.1              check_exog_dtypes(X_train_exog, call_check_exog=False)\n",
      "  1305         1      13845.0  13845.0      0.2              if not (X_train_exog.index == X_train.index).all():\n",
      "  1306                                                           raise ValueError(\n",
      "  1307                                                               \"Different index for `series` and `exog` after transformation. \"\n",
      "  1308                                                               \"They must be equal to ensure the correct alignment of values.\"\n",
      "  1309                                                           )\n",
      "  1310                                           \n",
      "  1311         1         83.0     83.0      0.0              X_train_exog_names_out_ = X_train_exog.columns.to_list()\n",
      "  1312         1     122836.0 122836.0      1.8              X_train = pd.concat([X_train, X_train_exog], axis=1)\n",
      "  1313                                           \n",
      "  1314         1       3850.0   3850.0      0.1          if y_train.isna().to_numpy().any():\n",
      "  1315                                                       mask = y_train.notna().to_numpy()\n",
      "  1316                                                       y_train = y_train.iloc[mask]\n",
      "  1317                                                       X_train = X_train.iloc[mask,]\n",
      "  1318                                                       warnings.warn(\n",
      "  1319                                                           \"NaNs detected in `y_train`. They have been dropped because the \"\n",
      "  1320                                                           \"target variable cannot have NaN values. Same rows have been \"\n",
      "  1321                                                           \"dropped from `X_train` to maintain alignment. This is caused by \"\n",
      "  1322                                                           \"series with interspersed NaNs.\",\n",
      "  1323                                                           MissingValuesWarning\n",
      "  1324                                                       )\n",
      "  1325                                           \n",
      "  1326         1         53.0     53.0      0.0          if self.dropna_from_series:\n",
      "  1327                                                       if np.any(X_train.isnull().to_numpy()):\n",
      "  1328                                                           mask = X_train.notna().all(axis=1).to_numpy()\n",
      "  1329                                                           X_train = X_train.iloc[mask, ]\n",
      "  1330                                                           y_train = y_train.iloc[mask]\n",
      "  1331                                                           warnings.warn(\n",
      "  1332                                                               \"NaNs detected in `X_train`. They have been dropped. If \"\n",
      "  1333                                                               \"you want to keep them, set `forecaster.dropna_from_series = False`. \"\n",
      "  1334                                                               \"Same rows have been removed from `y_train` to maintain alignment. \"\n",
      "  1335                                                               \"This caused by series with interspersed NaNs.\",\n",
      "  1336                                                               MissingValuesWarning\n",
      "  1337                                                           )\n",
      "  1338                                                   else:\n",
      "  1339         1      62581.0  62581.0      0.9              if np.any(X_train.isnull().to_numpy()):\n",
      "  1340         2        204.0    102.0      0.0                  warnings.warn(\n",
      "  1341         1          7.0      7.0      0.0                      \"NaNs detected in `X_train`. Some regressors do not allow \"\n",
      "  1342                                                               \"NaN values during training. If you want to drop them, \"\n",
      "  1343                                                               \"set `forecaster.dropna_from_series = True`.\",\n",
      "  1344         1         10.0     10.0      0.0                      MissingValuesWarning\n",
      "  1345                                                           )\n",
      "  1346                                           \n",
      "  1347         1        315.0    315.0      0.0          if X_train.empty:\n",
      "  1348                                                       raise ValueError(\n",
      "  1349                                                           \"All samples have been removed due to NaNs. Set \"\n",
      "  1350                                                           \"`forecaster.dropna_from_series = False` or review `exog` values.\"\n",
      "  1351                                                       )\n",
      "  1352                                                   \n",
      "  1353         1         40.0     40.0      0.0          if self.encoding == 'onehot':\n",
      "  1354                                                       X_train_series_names_in_ = [\n",
      "  1355                                                           col for col in series_names_in_ if X_train[col].sum() > 0\n",
      "  1356                                                       ]\n",
      "  1357                                                   else:\n",
      "  1358         1      27389.0  27389.0      0.4              unique_levels = X_train['_level_skforecast'].unique()\n",
      "  1359         2       3537.0   1768.5      0.1              X_train_series_names_in_ = [\n",
      "  1360         1         18.0     18.0      0.0                  k for k, v in self.encoding_mapping_.items()\n",
      "  1361                                                           if v in unique_levels\n",
      "  1362                                                       ]\n",
      "  1363                                           \n",
      "  1364                                                   # The last time window of training data is stored so that lags needed as\n",
      "  1365                                                   # predictors in the first iteration of `predict()` can be calculated.\n",
      "  1366         1          5.0      5.0      0.0          last_window_ = None\n",
      "  1367         1          3.0      3.0      0.0          if store_last_window:\n",
      "  1368                                           \n",
      "  1369         1          2.0      2.0      0.0              series_to_store = (\n",
      "  1370         1          6.0      6.0      0.0                  X_train_series_names_in_ if store_last_window is True else store_last_window\n",
      "  1371                                                       )\n",
      "  1372                                           \n",
      "  1373         1        150.0    150.0      0.0              series_not_in_series_dict = set(series_to_store) - set(X_train_series_names_in_)\n",
      "  1374         1         10.0     10.0      0.0              if series_not_in_series_dict:\n",
      "  1375                                                           warnings.warn(\n",
      "  1376                                                               f\"Series {series_not_in_series_dict} are not present in \"\n",
      "  1377                                                               f\"`series`. No last window is stored for them.\",\n",
      "  1378                                                               IgnoredArgumentWarning\n",
      "  1379                                                           )\n",
      "  1380                                                           series_to_store = [\n",
      "  1381                                                               s for s in series_to_store \n",
      "  1382                                                               if s not in series_not_in_series_dict\n",
      "  1383                                                           ]\n",
      "  1384                                           \n",
      "  1385         1          5.0      5.0      0.0              if series_to_store:\n",
      "  1386         2     122692.0  61346.0      1.7                  last_window_ = {\n",
      "  1387                                                               k: v.iloc[-self.window_size:].copy()\n",
      "  1388         1          7.0      7.0      0.0                      for k, v in series_dict.items()\n",
      "  1389                                                               if k in series_to_store\n",
      "  1390                                                           }\n",
      "  1391                                           \n",
      "  1392         1          3.0      3.0      0.0          return (\n",
      "  1393         1          6.0      6.0      0.0              X_train,\n",
      "  1394         1          6.0      6.0      0.0              y_train,\n",
      "  1395         1          2.0      2.0      0.0              series_indexes,\n",
      "  1396         1          2.0      2.0      0.0              series_names_in_,\n",
      "  1397         1          1.0      1.0      0.0              X_train_series_names_in_,\n",
      "  1398         1          3.0      3.0      0.0              exog_names_in_,\n",
      "  1399         1          2.0      2.0      0.0              X_train_window_features_names_out_,\n",
      "  1400         1          5.0      5.0      0.0              X_train_exog_names_out_,\n",
      "  1401         1          1.0      1.0      0.0              exog_dtypes_in_,\n",
      "  1402         1          1.0      1.0      0.0              last_window_\n",
      "  1403                                                   )"
     ]
    }
   ],
   "source": [
    "def funt_to_profile(forecaster, series_dict, exog_dict):\n",
    "    _ = forecaster._create_train_X_y(\n",
    "                            series = series_dict,\n",
    "                            exog=exog_dict\n",
    "                        )\n",
    "\n",
    "%lprun -f forecaster._create_train_X_y funt_to_profile(forecaster, series_dict, exog_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.064929 s\n",
      "File: c:\\Users\\jaesc2\\GitHub\\skforecast\\skforecast\\utils\\utils.py\n",
      "Function: check_preprocess_series at line 2448\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  2448                                           def check_preprocess_series(\n",
      "  2449                                               series: pd.DataFrame,\n",
      "  2450                                           ) -> tuple[pd.DataFrame]:\n",
      "  2451                                               \"\"\"\n",
      "  2452                                               Check and preprocess `series` argument in `ForecasterRecursiveMultiSeries`\n",
      "  2453                                               class.\n",
      "  2454                                           \n",
      "  2455                                               Check if the indexes of the series are valid. If the temporal index of the\n",
      "  2456                                               series is not a pandas DatetimeIndex index with frequency, it is overwritten\n",
      "  2457                                               with a pandas RangeIndex.\n",
      "  2458                                               \n",
      "  2459                                               Parameters\n",
      "  2460                                               ----------\n",
      "  2461                                               series : pandas DataFrame\n",
      "  2462                                                   Training time series.\n",
      "  2463                                           \n",
      "  2464                                               Returns\n",
      "  2465                                               -------\n",
      "  2466                                               series : pandas DataFrame\n",
      "  2467                                                   Series used during training.\n",
      "  2468                                               \n",
      "  2469                                               \"\"\"\n",
      "  2470                                           \n",
      "  2471         1         31.0     31.0      0.0      if not isinstance(series, pd.DataFrame):\n",
      "  2472                                                   raise TypeError(\n",
      "  2473                                                       f\"`series` must be a pandas DataFrame with a single DatetimeIndex or \"\n",
      "  2474                                                       f\"a pandas DataFrame with a MultiIndex where the first level is the \"\n",
      "  2475                                                       f\"series ID and the second level is temporal index. \"\n",
      "  2476                                                       f\"Got {type(series)}.\"\n",
      "  2477                                                   )\n",
      "  2478                                           \n",
      "  2479                                               # TODO: deprecate in next release\n",
      "  2480         1         92.0     92.0      0.0      if not isinstance(series.index, pd.MultiIndex):\n",
      "  2481                                                   warnings.warn(\n",
      "  2482                                                       \"In future versions, 'series' must be a pandas Series with a MultiIndex where \"\n",
      "  2483                                                       \"the first level is the series ID and the second level is the temporal index.\",\n",
      "  2484                                                       DeprecationWarning,\n",
      "  2485                                                   )\n",
      "  2486                                           \n",
      "  2487                                                   freq = series.index.freq\n",
      "  2488                                                   series.index.name = 'datetime'\n",
      "  2489                                                   series = series.reset_index()\n",
      "  2490                                                   series = pd.melt(\n",
      "  2491                                                       series,\n",
      "  2492                                                       id_vars='datetime',\n",
      "  2493                                                       var_name='series_id',\n",
      "  2494                                                       value_name='value'\n",
      "  2495                                                   )\n",
      "  2496                                                   series = (\n",
      "  2497                                                       series\n",
      "  2498                                                       .groupby('series_id', sort=False)\n",
      "  2499                                                       .apply(lambda x: x.set_index('datetime').asfreq(freq), include_groups=False)\n",
      "  2500                                                   )\n",
      "  2501                                           \n",
      "  2502         1          7.0      7.0      0.0      if isinstance(series.index, pd.MultiIndex):\n",
      "  2503                                           \n",
      "  2504         1         65.0     65.0      0.0          if not series.index.nlevels == 2:\n",
      "  2505                                                       raise ValueError(\n",
      "  2506                                                           f\"`series` must be a pandas DataFrame with a MultiIndex, where \"\n",
      "  2507                                                           f\"the first level is the seris ID and the second level the temporal \"\n",
      "  2508                                                           f\"index. Found {series.index.names} levels.\"\n",
      "  2509                                                       )\n",
      "  2510                                               \n",
      "  2511                                                   # NOTE: if it is not a DatetimeIndex,or a RangeIndex, raise error instead of warning\n",
      "  2512         1        143.0    143.0      0.0          if not isinstance(series.index.levels[1], (pd.DatetimeIndex, pd.RangeIndex)):\n",
      "  2513                                                       raise TypeError(\n",
      "  2514                                                           f\"The second level of the MultiIndex in `series` must be a \"\n",
      "  2515                                                           f\"pandas DatetimeIndex or RangeIndex. Found {type(series.index.levels[1])}.\"\n",
      "  2516                                                       )\n",
      "  2517                                             \n",
      "  2518                                           \n",
      "  2519         1         19.0     19.0      0.0          if isinstance(series.index.levels[1], pd.DatetimeIndex):\n",
      "  2520         1         11.0     11.0      0.0              indexes_freq = set()\n",
      "  2521         1         18.0     18.0      0.0              unique_ids = series.index.levels[0]\n",
      "  2522       100       1542.0     15.4      0.2              for series_id in unique_ids:\n",
      "  2523        99     539425.0   5448.7     83.1                  series_i = series.loc[series_id]\n",
      "  2524                                                           # TODO: hacer esto solo si es datetime\n",
      "  2525        99      15287.0    154.4      2.4                  indexes_freq.add(series_i.index.freq)\n",
      "  2526        99      92603.0    935.4     14.3                  if series_i.isna().to_numpy().all():\n",
      "  2527                                                               raise ValueError(\n",
      "  2528                                                                   f\"All values of series '{series_id}' are NaN. Please, \",\n",
      "  2529                                                                   f\"remove series with all NaN values before training the forecaster.\"\n",
      "  2530                                                               )\n",
      "  2531                                           \n",
      "  2532         1         25.0     25.0      0.0              if not len(indexes_freq) == 1:\n",
      "  2533                                                           raise ValueError(\n",
      "  2534                                                               f\"When using a DatetimeIndex, all series must have the same \",\n",
      "  2535                                                               f\"frequency. Found frequencies: {indexes_freq}\"\n",
      "  2536                                                           )\n",
      "  2537         1         15.0     15.0      0.0              if indexes_freq == [None]:\n",
      "  2538                                                           raise TypeError(\n",
      "  2539                                                               \"Series have a pandas DatetimeIndex without frequancy. When \"\n",
      "  2540                                                               \"using a DatetimeIndex, all series must have the same frequency. \"\n",
      "  2541                                                               \"To avoid this error, set the frequency of the index using: \"\n",
      "  2542                                                               \"series.groupby('series_id').apply(lambda x: x.set_index('datetime').asfreq('D'),\"\n",
      "  2543                                                               \"include_groups=False)\"\n",
      "  2544                                                           )\n",
      "  2545                                                       \n",
      "  2546                                                           #TODO: remove if agree with the raise error above\n",
      "  2547                                                           # series_grouped = series.groupby(level=0, group_keys=False, sort=False)\n",
      "  2548                                                           # series = series_grouped.apply(\n",
      "  2549                                                           #     lambda g: g.set_index(\n",
      "  2550                                                           #         pd.MultiIndex.from_arrays(\n",
      "  2551                                                           #             [g.index.get_level_values(0), pd.RangeIndex(len(g))],\n",
      "  2552                                                           #             names=g.index.names\n",
      "  2553                                                           #         )\n",
      "  2554                                                           #     )\n",
      "  2555                                                           # )            \n",
      "  2556                                           \n",
      "  2557         1          7.0      7.0      0.0      return series"
     ]
    }
   ],
   "source": [
    "def funt_to_profile(series):\n",
    "    check_preprocess_series(series=series)\n",
    "\n",
    "%lprun -f check_preprocess_series funt_to_profile(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.0202911 s\n",
      "File: c:\\Users\\jaesc2\\Miniconda3\\envs\\skforecast_py11_2\\Lib\\site-packages\\skforecast\\utils\\utils.py\n",
      "Function: check_preprocess_series at line 2448\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "  2448                                           def check_preprocess_series(\n",
      "  2449                                               series: pd.DataFrame | dict[str, pd.Series | pd.DataFrame],\n",
      "  2450                                           ) -> tuple[dict[str, pd.Series], dict[str, pd.Index]]:\n",
      "  2451                                               \"\"\"\n",
      "  2452                                               Check and preprocess `series` argument in `ForecasterRecursiveMultiSeries` class.\n",
      "  2453                                           \n",
      "  2454                                               - If `series` is a pandas DataFrame, it is converted to a dict of pandas \n",
      "  2455                                               Series and index is overwritten according to the rules of preprocess_y.\n",
      "  2456                                               - If `series` is a dict, all values are converted to pandas Series. Checks\n",
      "  2457                                               if all index are pandas DatetimeIndex and, at least, one Series has a non-null\n",
      "  2458                                               frequency. No multiple frequency is allowed.\n",
      "  2459                                           \n",
      "  2460                                               Parameters\n",
      "  2461                                               ----------\n",
      "  2462                                               series : pandas DataFrame, dict\n",
      "  2463                                                   Training time series.\n",
      "  2464                                           \n",
      "  2465                                               Returns\n",
      "  2466                                               -------\n",
      "  2467                                               series_dict : dict\n",
      "  2468                                                   Dictionary with the series used during training.\n",
      "  2469                                               series_indexes : dict\n",
      "  2470                                                   Dictionary with the index of each series.\n",
      "  2471                                               \n",
      "  2472                                               \"\"\"\n",
      "  2473                                           \n",
      "  2474         1         41.0     41.0      0.0      if isinstance(series, pd.DataFrame):\n",
      "  2475                                           \n",
      "  2476                                                   _, series_index = preprocess_y(y=series, return_values=False)\n",
      "  2477                                                   series = series.copy()\n",
      "  2478                                                   series.index = series_index\n",
      "  2479                                                   series_dict = series.to_dict(\"series\")\n",
      "  2480                                           \n",
      "  2481         1          6.0      6.0      0.0      elif isinstance(series, dict):\n",
      "  2482                                           \n",
      "  2483         2       1029.0    514.5      0.5          not_valid_series = [\n",
      "  2484                                                       k \n",
      "  2485         1         14.0     14.0      0.0              for k, v in series.items()\n",
      "  2486                                                       if not isinstance(v, (pd.Series, pd.DataFrame))\n",
      "  2487                                                   ]\n",
      "  2488         1          4.0      4.0      0.0          if not_valid_series:\n",
      "  2489                                                       raise TypeError(\n",
      "  2490                                                           f\"If `series` is a dictionary, all series must be a named \"\n",
      "  2491                                                           f\"pandas Series or a pandas DataFrame with a single column. \"\n",
      "  2492                                                           f\"Review series: {not_valid_series}\"\n",
      "  2493                                                       )\n",
      "  2494                                           \n",
      "  2495         2      69205.0  34602.5     34.1          series_dict = {\n",
      "  2496                                                       k: v.copy()\n",
      "  2497         1          4.0      4.0      0.0              for k, v in series.items()\n",
      "  2498                                                   }\n",
      "  2499                                           \n",
      "  2500       100        395.0      4.0      0.2          for k, v in series_dict.items():\n",
      "  2501        99        471.0      4.8      0.2              if isinstance(v, pd.DataFrame):\n",
      "  2502                                                           if v.shape[1] != 1:\n",
      "  2503                                                               raise ValueError(\n",
      "  2504                                                                   f\"If `series` is a dictionary, all series must be a named \"\n",
      "  2505                                                                   f\"pandas Series or a pandas DataFrame with a single column. \"\n",
      "  2506                                                                   f\"Review series: '{k}'\"\n",
      "  2507                                                               )\n",
      "  2508                                                           series_dict[k] = v.iloc[:, 0]\n",
      "  2509                                           \n",
      "  2510        99       6525.0     65.9      3.2              series_dict[k].name = k\n",
      "  2511                                           \n",
      "  2512         2       1200.0    600.0      0.6          not_valid_index = [\n",
      "  2513                                                       k \n",
      "  2514         1         17.0     17.0      0.0              for k, v in series_dict.items()\n",
      "  2515                                                       if not isinstance(v.index, pd.DatetimeIndex)\n",
      "  2516                                                   ]\n",
      "  2517         1          7.0      7.0      0.0          if not_valid_index:\n",
      "  2518                                                       raise TypeError(\n",
      "  2519                                                           f\"If `series` is a dictionary, all series must have a Pandas \"\n",
      "  2520                                                           f\"DatetimeIndex as index with the same frequency. \"\n",
      "  2521                                                           f\"Review series: {not_valid_index}\"\n",
      "  2522                                                       )\n",
      "  2523                                           \n",
      "  2524         1       3040.0   3040.0      1.5          indexes_freq = [f\"{v.index.freq}\" for v in series_dict.values()]\n",
      "  2525         1        101.0    101.0      0.0          indexes_freq = sorted(set(indexes_freq))\n",
      "  2526         1          8.0      8.0      0.0          if not len(indexes_freq) == 1:\n",
      "  2527                                                       raise ValueError(\n",
      "  2528                                                           f\"If `series` is a dictionary, all series must have a Pandas \"\n",
      "  2529                                                           f\"DatetimeIndex as index with the same frequency. \"\n",
      "  2530                                                           f\"Found frequencies: {indexes_freq}\"\n",
      "  2531                                                       )\n",
      "  2532                                               else:\n",
      "  2533                                                   raise TypeError(\n",
      "  2534                                                       f\"`series` must be a pandas DataFrame or a dict of DataFrames or Series. \"\n",
      "  2535                                                       f\"Got {type(series)}.\"\n",
      "  2536                                                   )\n",
      "  2537                                           \n",
      "  2538       100        533.0      5.3      0.3      for k, v in series_dict.items():\n",
      "  2539        99     118845.0   1200.5     58.6          if v.isna().to_numpy().all():\n",
      "  2540                                                       raise ValueError(f\"All values of series '{k}' are NaN.\")\n",
      "  2541                                           \n",
      "  2542         2       1438.0    719.0      0.7      series_indexes = {\n",
      "  2543                                                   k: v.index\n",
      "  2544         1         18.0     18.0      0.0          for k, v in series_dict.items()\n",
      "  2545                                               }\n",
      "  2546                                           \n",
      "  2547         1         10.0     10.0      0.0      return series_dict, series_indexes"
     ]
    }
   ],
   "source": [
    "def funt_to_profile(series_dict):\n",
    "    check_preprocess_series(series=series_dict)\n",
    "\n",
    "%lprun -f check_preprocess_series funt_to_profile(series_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%pyinstrument\n",
    "# x_train, y_train = forecaster.create_train_X_y(\n",
    "#     series = series_dict,\n",
    "#     exog=exog_dict\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "n = 5000\n",
    "series = pd.DataFrame(\n",
    "    {i: np.random.randint(1, 100, n) for i in range(1, 100)\n",
    "    },\n",
    "    index=pd.date_range(start=\"2023-01-01\", periods=n, freq=\"h\"),\n",
    ")\n",
    "\n",
    "freq = series.index.freq\n",
    "series.index.name = \"datetime\"\n",
    "series = series.reset_index()\n",
    "series = pd.melt(series, id_vars=\"datetime\", var_name=\"series_id\", value_name=\"value\")\n",
    "series = series.groupby(\"series_id\").apply(\n",
    "    lambda x: x.set_index(\"datetime\").asfreq(\"D\"), include_groups=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract MultiIndex levels\n",
    "ids = series.index.get_level_values(0).to_numpy()\n",
    "dates = series.index.get_level_values(1).astype('datetime64[ns]').to_numpy()\n",
    "\n",
    "# Ensure sorting by (id, datetime)\n",
    "sort_idx = np.lexsort((dates, ids))\n",
    "ids = ids[sort_idx]\n",
    "dates_ns = dates[sort_idx].view('int64')\n",
    "\n",
    "@njit\n",
    "def most_common_deltas(ids, dates_ns, max_check=1000):\n",
    "    result_ids = []\n",
    "    result_deltas = []\n",
    "\n",
    "    start = 0\n",
    "    n = len(ids)\n",
    "\n",
    "    while start < n:\n",
    "        current_id = ids[start]\n",
    "        end = start + 1\n",
    "        while end < n and ids[end] == current_id:\n",
    "            end += 1\n",
    "\n",
    "        # Extract time series slice\n",
    "        series = dates_ns[start:end]\n",
    "        count = min(len(series) - 1, max_check)\n",
    "        \n",
    "        if count < 1:\n",
    "            result_ids.append(current_id)\n",
    "            result_deltas.append(-1)  # No data\n",
    "            start = end\n",
    "            continue\n",
    "\n",
    "        delta_counts = {}\n",
    "        for i in range(count):\n",
    "            delta = series[i + 1] - series[i]\n",
    "            if delta in delta_counts:\n",
    "                delta_counts[delta] += 1\n",
    "            else:\n",
    "                delta_counts[delta] = 1\n",
    "\n",
    "        # Find most common delta\n",
    "        max_delta = -1\n",
    "        max_count = -1\n",
    "        for delta, cnt in delta_counts.items():\n",
    "            if cnt > max_count:\n",
    "                max_delta = delta\n",
    "                max_count = cnt\n",
    "\n",
    "        result_ids.append(current_id)\n",
    "        result_deltas.append(max_delta)\n",
    "        start = end\n",
    "\n",
    "    return result_ids, result_deltas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_ids, deltas_ns = most_common_deltas(ids, dates_ns)\n",
    "\n",
    "# Convert to pandas timedelta64\n",
    "freqs = {}\n",
    "for uid, delta in zip(unique_ids, deltas_ns):\n",
    "    if delta == -1:\n",
    "        freqs[uid] = None  # Not enough data\n",
    "    else:\n",
    "        freqs[uid] = pd.Timedelta(delta, unit='ns')  # Convert to pandas Timedelta\n",
    "freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqstr_ = pd.date_range(start=\"2023-01-01\", periods=10, freq='ME').freqstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex([], dtype='datetime64[ns]', freq='ME')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range(start=\"2023-01-01\", end=\"2023-01-10\", freq=freqstr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cdb2994c-43d8-472b-859d-11d9f309d1f0",
       "rows": [
        [
         "2023-01-01 00:00:00",
         "0"
        ],
        [
         "2023-01-02 00:00:00",
         "1"
        ],
        [
         "2023-01-03 00:00:00",
         "2"
        ],
        [
         "2023-01-04 00:00:00",
         "3"
        ],
        [
         "2023-01-05 00:00:00",
         "4"
        ],
        [
         "2023-01-06 00:00:00",
         "5"
        ],
        [
         "2023-01-07 00:00:00",
         "6"
        ],
        [
         "2023-01-08 00:00:00",
         "7"
        ],
        [
         "2023-01-09 00:00:00",
         "8"
        ],
        [
         "2023-01-10 00:00:00",
         "9"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "2023-01-01    0\n",
       "2023-01-02    1\n",
       "2023-01-03    2\n",
       "2023-01-04    3\n",
       "2023-01-05    4\n",
       "2023-01-06    5\n",
       "2023-01-07    6\n",
       "2023-01-08    7\n",
       "2023-01-09    8\n",
       "2023-01-10    9\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series(np.arange(10), index=pd.date_range(start=\"2023-01-01\", periods=10, freq='D'))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2e9faa8f-4edb-4d46-aaf9-708b1f4f1869",
       "rows": [
        [
         "2023-01-01 00:00:00",
         "0"
        ],
        [
         "2023-01-02 00:00:00",
         "1"
        ],
        [
         "2023-01-03 00:00:00",
         "2"
        ],
        [
         "2023-01-04 00:00:00",
         "3"
        ],
        [
         "2023-01-05 00:00:00",
         "4"
        ],
        [
         "2023-01-06 00:00:00",
         "5"
        ],
        [
         "2023-01-07 00:00:00",
         "6"
        ],
        [
         "2023-01-08 00:00:00",
         "7"
        ],
        [
         "2023-01-09 00:00:00",
         "8"
        ],
        [
         "2023-01-10 00:00:00",
         "9"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 10
       }
      },
      "text/plain": [
       "2023-01-01    0\n",
       "2023-01-02    1\n",
       "2023-01-03    2\n",
       "2023-01-04    3\n",
       "2023-01-05    4\n",
       "2023-01-06    5\n",
       "2023-01-07    6\n",
       "2023-01-08    7\n",
       "2023-01-09    8\n",
       "2023-01-10    9\n",
       "Freq: D, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc['2021-01-01':'2024-01-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py11_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
