{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.recursive import ForecasterRecursive, ForecasterRecursiveMultiSeries\n",
    "from skforecast.direct import ForecasterDirect, ForecasterDirectMultiVariate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(123)\n",
    "y = pd.Series(rng.normal(size=10000), index=pd.date_range(\"2020-01-01\", periods=10000, freq=\"h\"))\n",
    "y_original = y.copy()\n",
    "forecaster = ForecasterRecursive(\n",
    "    regressor=LinearRegression(),\n",
    "    lags=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.9 ms ± 171 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "forecaster._create_lags(\n",
    "    y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = forecaster.create_train_X_y(y=y)\n",
    "x_train.iloc[1,1] = 10000\n",
    "pd.testing.assert_series_equal(y, y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 ms ± 39.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "forecaster.fit(y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">╭───────────────────────────── DataTransformationWarning ──────────────────────────────╮</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> When using a linear model, it is recommended to use a transformer_series to ensure   <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> all series are in the same scale. You can use, for example, a `StandardScaler` from  <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> sklearn.preprocessing.                                                               <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>                                                                                      <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Category : skforecast.exceptions.DataTransformationWarning                           <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Location :                                                                           <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> /home/joaquin/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/skfore <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> cast/recursive/_forecaster_recursive_multiseries.py:478                              <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Suppress : warnings.simplefilter('ignore', category=DataTransformationWarning)       <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">╰──────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;214m╭─\u001b[0m\u001b[38;5;214m────────────────────────────\u001b[0m\u001b[38;5;214m DataTransformationWarning \u001b[0m\u001b[38;5;214m─────────────────────────────\u001b[0m\u001b[38;5;214m─╮\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m When using a linear model, it is recommended to use a transformer_series to ensure   \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m all series are in the same scale. You can use, for example, a `StandardScaler` from  \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m sklearn.preprocessing.                                                               \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m                                                                                      \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Category : skforecast.exceptions.DataTransformationWarning                           \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Location :                                                                           \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m /home/joaquin/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/skfore \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m cast/recursive/_forecaster_recursive_multiseries.py:478                              \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Suppress : warnings.simplefilter('ignore', category=DataTransformationWarning)       \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m╰──────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = np.random.default_rng(123)\n",
    "series = {\n",
    "    f\"series_{i}\": pd.Series(\n",
    "        rng.normal(size=1000), index=pd.date_range(\"2020-01-01\", periods=1000)\n",
    "    )\n",
    "    for i in range(1000)\n",
    "}\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "    regressor=LinearRegression(),\n",
    "    lags=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 ms ± 6.55 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for y in series.values():\n",
    "    forecaster._create_lags(\n",
    "        y\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17 s ± 32.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "forecaster.fit(series=series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.direct import ForecasterDirect\n",
    "\n",
    "forecaster = ForecasterDirect(\n",
    "    regressor=LinearRegression(),\n",
    "    steps=24,\n",
    "    lags=50\n",
    ")\n",
    "rng = np.random.default_rng(123)\n",
    "y = pd.Series(rng.normal(size=1000), index=pd.date_range(\"2020-01-01\", periods=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.59 ms ± 78.2 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "forecaster._create_lags(\n",
    "    y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 ms ± 29.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "forecaster.fit(y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterDirectMultiVariate(\n",
    "    regressor=LinearRegression(),\n",
    "    steps=24,\n",
    "    lags=50,\n",
    "    level = \"series_1\"\n",
    ")\n",
    "rng = np.random.default_rng(123)\n",
    "series = {\n",
    "    f\"series_{i}\": pd.Series(\n",
    "        rng.normal(size=1000), index=pd.date_range(\"2020-01-01\", periods=1000)\n",
    "    )\n",
    "    for i in range(20)\n",
    "}\n",
    "series = pd.DataFrame(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8 ms ± 150 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "forecaster._create_train_X_y(\n",
    "    series = series,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtimeit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mforecaster.fit(series=series)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2547\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2545\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2546\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2547\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2550\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2551\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2552\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/IPython/core/magics/execution.py:1229\u001b[39m, in \u001b[36mExecutionMagics.timeit\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1226\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m time_number >= \u001b[32m0.2\u001b[39m:\n\u001b[32m   1227\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1229\u001b[39m all_runs = \u001b[43mtimer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1230\u001b[39m best = \u001b[38;5;28mmin\u001b[39m(all_runs) / number\n\u001b[32m   1231\u001b[39m worst = \u001b[38;5;28mmax\u001b[39m(all_runs) / number\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/timeit.py:208\u001b[39m, in \u001b[36mTimer.repeat\u001b[39m\u001b[34m(self, repeat, number)\u001b[39m\n\u001b[32m    206\u001b[39m r = []\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     t = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     r.append(t)\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/IPython/core/magics/execution.py:182\u001b[39m, in \u001b[36mTimer.timeit\u001b[39m\u001b[34m(self, number)\u001b[39m\n\u001b[32m    180\u001b[39m gc.disable()\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     timing = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<magic-timeit>:1\u001b[39m, in \u001b[36minner\u001b[39m\u001b[34m(_it, _timer)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/skforecast/direct/_forecaster_direct_multivariate.py:1546\u001b[39m, in \u001b[36mForecasterDirectMultiVariate.fit\u001b[39m\u001b[34m(self, series, exog, store_last_window, store_in_sample_residuals, random_state, suppress_warnings)\u001b[39m\n\u001b[32m   1541\u001b[39m         y_pred_step = regressor.predict(X_train_step)\n\u001b[32m   1543\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m step, regressor, y_true_step, y_pred_step\n\u001b[32m   1545\u001b[39m results_fit = (\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m     \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_forecaster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregressor\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregressor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1555\u001b[39m )\n\u001b[32m   1557\u001b[39m \u001b[38;5;28mself\u001b[39m.regressors_ = {step: regressor \u001b[38;5;28;01mfor\u001b[39;00m step, regressor, *_ \u001b[38;5;129;01min\u001b[39;00m results_fit}\n\u001b[32m   1559\u001b[39m \u001b[38;5;28mself\u001b[39m.in_sample_residuals_ = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/skforecast/direct/_forecaster_direct_multivariate.py:1530\u001b[39m, in \u001b[36mForecasterDirectMultiVariate.fit.<locals>.fit_forecaster\u001b[39m\u001b[34m(regressor, X_train, y_train, step)\u001b[39m\n\u001b[32m   1523\u001b[39m     regressor.fit(\n\u001b[32m   1524\u001b[39m         X             = X_train_step,\n\u001b[32m   1525\u001b[39m         y             = y_train_step,\n\u001b[32m   1526\u001b[39m         sample_weight = sample_weight,\n\u001b[32m   1527\u001b[39m         **\u001b[38;5;28mself\u001b[39m.fit_kwargs\n\u001b[32m   1528\u001b[39m     )\n\u001b[32m   1529\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1530\u001b[39m     \u001b[43mregressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1532\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1533\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_kwargs\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[38;5;66;03m# NOTE: This is done to save time during fit in functions such as backtesting()\u001b[39;00m\n\u001b[32m   1537\u001b[39m y_true_step = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/sklearn/linear_model/_base.py:701\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# cut-off ratio for small singular values\u001b[39;00m\n\u001b[32m    700\u001b[39m     cond = \u001b[38;5;28mmax\u001b[39m(X.shape) * np.finfo(X.dtype).eps\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m     \u001b[38;5;28mself\u001b[39m.coef_, _, \u001b[38;5;28mself\u001b[39m.rank_, \u001b[38;5;28mself\u001b[39m.singular_ = \u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m     \u001b[38;5;28mself\u001b[39m.coef_ = \u001b[38;5;28mself\u001b[39m.coef_.T\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/scipy/linalg/_basic.py:1470\u001b[39m, in \u001b[36mlstsq\u001b[39m\u001b[34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[39m\n\u001b[32m   1468\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m real_data:\n\u001b[32m   1469\u001b[39m     lwork, iwork = _compute_lwork(lapack_lwork, m, n, nrhs, cond)\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m     x, s, rank, info = \u001b[43mlapack_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43miwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# complex data\u001b[39;00m\n\u001b[32m   1473\u001b[39m     lwork, rwork, iwork = _compute_lwork(lapack_lwork, m, n,\n\u001b[32m   1474\u001b[39m                                          nrhs, cond)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "forecaster.fit(series=series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def is_view(obj1, obj2):\n",
    "    \"\"\"\n",
    "    Check if obj2 is a view of obj1.\n",
    "    Works for NumPy arrays, pandas Series, and pandas DataFrames.\n",
    "    \"\"\"\n",
    "    # Convert pandas objects to underlying NumPy arrays\n",
    "    if isinstance(obj1, (pd.Series, pd.DataFrame)):\n",
    "        arr1 = obj1.values\n",
    "    else:\n",
    "        arr1 = obj1\n",
    "\n",
    "    if isinstance(obj2, (pd.Series, pd.DataFrame)):\n",
    "        arr2 = obj2.values\n",
    "    else:\n",
    "        arr2 = obj2\n",
    "\n",
    "    # Use NumPy function to check shared memory\n",
    "    return np.shares_memory(arr1, arr2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_16_py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
