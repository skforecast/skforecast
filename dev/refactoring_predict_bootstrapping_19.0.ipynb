{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaesc2\\GitHub\\skforecast\n",
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skforecast\n",
    "\n",
    "print(skforecast.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skforecast\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skforecast.recursive import ForecasterRecursive, ForecasterRecursiveMultiSeries\n",
    "from skforecast.preprocessing import RollingFeatures\n",
    "import time\n",
    "import warnings\n",
    "from skforecast.exceptions import DataTransformationWarning\n",
    "\n",
    "warnings.simplefilter('ignore', category=DataTransformationWarning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with 1000 time series of 1000 observations each\n",
    "series = {f'series_{i}': pd.Series(np.random.randn(1000), \n",
    "                                 index=pd.date_range(start='2000-01-01', periods=1000, freq='D')) \n",
    "        for i in range(1000)}\n",
    "\n",
    "y = series['series_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.7000052479997976 seconds\n"
     ]
    }
   ],
   "source": [
    "forecaster = ForecasterRecursive(\n",
    "                    estimator = LinearRegression(),\n",
    "                    lags      = 48,\n",
    ")\n",
    "forecaster.fit(y=y, store_in_sample_residuals=True)\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "forecaster.predict_bootstrapping(steps=48, n_boot=500)\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f'Time taken: {end - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 4.429095293999126 seconds\n"
     ]
    }
   ],
   "source": [
    "window_features = RollingFeatures(\n",
    "                    window_sizes = 48,\n",
    "                    stats   = ['mean', 'std', 'min', 'max']\n",
    ")\n",
    "forecaster = ForecasterRecursive(\n",
    "                    estimator = LinearRegression(),\n",
    "                    lags      = 48,\n",
    "                    window_features = window_features\n",
    ")\n",
    "forecaster.fit(y=y, store_in_sample_residuals=True)\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "forecaster.predict_bootstrapping(steps=48, n_boot=500)\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f'Time taken: {end - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_features = RollingFeatures(\n",
    "                    window_sizes = 48,\n",
    "                    stats   = ['mean', 'std', 'min', 'max']\n",
    ")\n",
    "\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "                    estimator = LinearRegression(),\n",
    "                    lags      = 48,\n",
    "                    window_features = window_features\n",
    ")\n",
    "forecaster.fit(series=series, store_in_sample_residuals=True)\n",
    "\n",
    "steps = 24\n",
    "n_boot = 100\n",
    "use_in_sample_residuals = True\n",
    "use_binned_residuals = False\n",
    "\n",
    "(\n",
    "    last_window,\n",
    "    exog_values_dict,\n",
    "    levels,\n",
    "    prediction_index\n",
    ") = forecaster._create_predict_inputs(\n",
    "        steps                   = steps,\n",
    "        levels                  = None,\n",
    "        last_window             = None,\n",
    "        exog                    = None,\n",
    "        predict_probabilistic   = True,\n",
    "        use_in_sample_residuals = use_in_sample_residuals,\n",
    "        use_binned_residuals    = use_binned_residuals\n",
    "    )\n",
    "\n",
    "if use_in_sample_residuals:\n",
    "    residuals = forecaster.in_sample_residuals_\n",
    "    residuals_by_bin = forecaster.in_sample_residuals_by_bin_\n",
    "else:\n",
    "    residuals = forecaster.out_sample_residuals_\n",
    "    residuals_by_bin = forecaster.out_sample_residuals_by_bin_\n",
    "\n",
    "n_levels = len(levels)\n",
    "rng = np.random.default_rng(seed=123)\n",
    "\n",
    "if use_binned_residuals:\n",
    "    # Pre-allocate 4D array directly: (n_bins, steps, n_boot, n_levels)\n",
    "    # Loop order must match original to preserve RNG sequence for reproducibility\n",
    "    n_bins = forecaster.binner_kwargs['n_bins']\n",
    "    sampled_residuals = np.empty(\n",
    "        (n_bins, steps, n_boot, n_levels), order='C', dtype=float\n",
    "    )\n",
    "    for bin_idx in range(n_bins):\n",
    "        for i, level in enumerate(levels):\n",
    "            sampled_residuals[bin_idx, :, :, i] = rng.choice(\n",
    "                a       = residuals_by_bin.get(level, residuals_by_bin['_unknown_level'])[bin_idx],\n",
    "                size    = (steps, n_boot),\n",
    "                replace = True\n",
    "            )\n",
    "else:\n",
    "    sampled_residuals = np.full(\n",
    "        shape      = (steps, n_levels, n_boot),\n",
    "        fill_value = np.nan,\n",
    "        order      = 'C',\n",
    "        dtype      = float\n",
    "    )\n",
    "    for i, level in enumerate(levels):\n",
    "        sampled_residuals[:, i, :] = rng.choice(\n",
    "            a       = residuals.get(level, residuals['_unknown_level']),\n",
    "            size    = (steps, n_boot),\n",
    "            replace = True\n",
    "        )\n",
    "\n",
    "boot_columns = [f\"pred_boot_{i}\" for i in range(n_boot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.63 s ± 44.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\", \n",
    "        message=\"X does not have valid feature names\", \n",
    "        category=UserWarning\n",
    "    )\n",
    "    forecaster._recursive_predict_bootstrapping(\n",
    "                    steps                = steps,\n",
    "                    levels               = levels,\n",
    "                    last_window          = last_window,\n",
    "                    n_boot               = n_boot,\n",
    "                    sampled_residuals    = sampled_residuals,\n",
    "                    use_binned_residuals = use_binned_residuals,\n",
    "                    exog_values_dict     = exog_values_dict,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    def _recursive_predict_bootstrapping_new(\n",
    "        self,\n",
    "        steps: int,\n",
    "        levels: list,\n",
    "        last_window: pd.DataFrame,\n",
    "        n_boot: int,\n",
    "        sampled_residuals: np.ndarray,\n",
    "        use_binned_residuals: bool,\n",
    "        exog_values_dict: dict[str, np.ndarray] | None = None,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Vectorized bootstrap prediction with optimized memory layout.\n",
    "        \n",
    "        Uses layout `(window_size+steps, n_boot, n_levels)` for `last_window_boot`\n",
    "        which provides ~4x speedup compared to the original layout.\n",
    "        \"\"\"\n",
    "\n",
    "        original_device = set_cpu_gpu_device(estimator=self.estimator, device='cpu')\n",
    "\n",
    "        n_levels = len(levels)\n",
    "        n_lags = len(self.lags) if self.lags is not None else 0\n",
    "        n_window_features = (\n",
    "            len(self.X_train_window_features_names_out_)\n",
    "            if self.window_features is not None\n",
    "            else 0\n",
    "        )\n",
    "        n_autoreg = n_lags + n_window_features\n",
    "        n_exog = len(self.X_train_exog_names_out_) if exog_values_dict is not None else 0\n",
    "\n",
    "        n_samples = n_levels * n_boot\n",
    "\n",
    "        if self.encoding is not None:\n",
    "            if self.encoding == \"onehot\":\n",
    "                levels_encoded = np.zeros(\n",
    "                    (n_levels, len(self.X_train_series_names_in_)), dtype=float\n",
    "                )\n",
    "                for i, level in enumerate(levels):\n",
    "                    if level in self.X_train_series_names_in_:\n",
    "                        levels_encoded[i, self.X_train_series_names_in_.index(level)] = 1.\n",
    "            else:\n",
    "                levels_encoded = np.array(\n",
    "                    [self.encoding_mapping_.get(level, np.nan) for level in levels],\n",
    "                    dtype=\"float64\"\n",
    "                ).reshape(-1, 1)\n",
    "            levels_encoded_shape = levels_encoded.shape[1]\n",
    "            levels_encoded = np.tile(levels_encoded, (n_boot, 1))\n",
    "        else:\n",
    "            levels_encoded_shape = 0\n",
    "\n",
    "        features_shape = n_autoreg + levels_encoded_shape + n_exog\n",
    "        features = np.full(\n",
    "            shape=(n_samples, features_shape), fill_value=np.nan, order='C', dtype=float\n",
    "        )\n",
    "        if self.encoding is not None:\n",
    "            features[:, n_autoreg: n_autoreg + levels_encoded_shape] = levels_encoded\n",
    "\n",
    "        boot_predictions = np.full(\n",
    "            shape=(steps, n_levels, n_boot), fill_value=np.nan, order='C', dtype=float\n",
    "        )\n",
    "\n",
    "        # NEW LAYOUT: (window_size + steps, n_boot, n_levels)\n",
    "        last_window = last_window.to_numpy()\n",
    "        window_size = last_window.shape[0]\n",
    "        last_window_boot = np.empty(\n",
    "            (window_size + steps, n_boot, n_levels), dtype=float, order='C'\n",
    "        )\n",
    "        last_window_boot[:window_size, :, :] = last_window[:, np.newaxis, :]\n",
    "        last_window_boot[window_size:, :, :] = np.nan\n",
    "\n",
    "        for step in range(steps):\n",
    "\n",
    "            if self.lags is not None:\n",
    "                lags_indices = window_size + step - self.lags\n",
    "                # lagged_values shape: (n_lags, n_boot, n_levels)\n",
    "                lagged_values = last_window_boot[lags_indices, :, :]\n",
    "                # NEW: transpose(1, 2, 0) instead of (2, 1, 0)\n",
    "                features[:, :n_lags] = lagged_values.transpose(1, 2, 0).reshape(n_samples, n_lags)\n",
    "\n",
    "            if self.window_features is not None:\n",
    "                wf_col_offset = n_lags\n",
    "                for wf in self.window_features:\n",
    "                    wf_in = last_window_boot[:window_size + step, :, :]\n",
    "                    # NEW: No transpose needed - direct reshape\n",
    "                    wf_in = wf_in.reshape(window_size + step, n_samples)\n",
    "                    wf_out = wf.transform(wf_in)\n",
    "                    n_wf_cols = wf_out.shape[1]\n",
    "                    features[:, wf_col_offset:wf_col_offset + n_wf_cols] = wf_out\n",
    "                    wf_col_offset += n_wf_cols\n",
    "\n",
    "            if exog_values_dict is not None:\n",
    "                features[:, -n_exog:] = np.tile(exog_values_dict[step + 1], (n_boot, 1))\n",
    "\n",
    "            pred = self.estimator.predict(features)\n",
    "            pred = pred.reshape(n_boot, n_levels).T\n",
    "            \n",
    "            if not features.flags.writeable:\n",
    "                features.flags.writeable = True\n",
    "\n",
    "            if use_binned_residuals:\n",
    "                boot_indices = np.arange(n_boot)\n",
    "                for j, level in enumerate(levels):\n",
    "                    binner = self.binner.get(level, self.binner['_unknown_level'])\n",
    "                    predicted_bins = binner.transform(pred[j, :]).astype(int)\n",
    "                    pred[j, :] += sampled_residuals[predicted_bins, step, boot_indices, j]\n",
    "            else:\n",
    "                pred += sampled_residuals[step, :, :]\n",
    "\n",
    "            boot_predictions[step, :, :] = pred\n",
    "\n",
    "            # NEW: Need transpose for (n_boot, n_levels) layout\n",
    "            last_window_boot[window_size + step, :, :] = pred.T\n",
    "\n",
    "        set_cpu_gpu_device(estimator=self.estimator, device=original_device)\n",
    "\n",
    "        return boot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        original_device = set_cpu_gpu_device(estimator=self.estimator, device='cpu')\n",
    "\n",
    "        n_levels = len(levels)\n",
    "        n_lags = len(self.lags) if self.lags is not None else 0\n",
    "        n_window_features = (\n",
    "            len(self.X_train_window_features_names_out_)\n",
    "            if self.window_features is not None\n",
    "            else 0\n",
    "        )\n",
    "        n_autoreg = n_lags + n_window_features\n",
    "        n_exog = len(self.X_train_exog_names_out_) if exog_values_dict is not None else 0\n",
    "\n",
    "        # Total samples per step: n_boot × n_levels\n",
    "        # Row ordering: [level0_boot0, level1_boot0, ..., levelN_boot0, level0_boot1, ...]\n",
    "        n_samples = n_levels * n_boot\n",
    "\n",
    "        # Build level encoding (repeated for all bootstrap samples)\n",
    "        if self.encoding is not None:\n",
    "            if self.encoding == \"onehot\":\n",
    "                levels_encoded = np.zeros(\n",
    "                    (n_levels, len(self.X_train_series_names_in_)), dtype=float\n",
    "                )\n",
    "                for i, level in enumerate(levels):\n",
    "                    if level in self.X_train_series_names_in_:\n",
    "                        levels_encoded[i, self.X_train_series_names_in_.index(level)] = 1.\n",
    "            else:\n",
    "                levels_encoded = np.array(\n",
    "                    [self.encoding_mapping_.get(level, np.nan) for level in levels],\n",
    "                    dtype=\"float64\"\n",
    "                ).reshape(-1, 1)\n",
    "            levels_encoded_shape = levels_encoded.shape[1]\n",
    "            # Tile to (n_boot × n_levels, encoded_shape): pattern repeats n_boot times\n",
    "            levels_encoded = np.tile(levels_encoded, (n_boot, 1))\n",
    "        else:\n",
    "            levels_encoded_shape = 0\n",
    "\n",
    "        features_shape = n_autoreg + levels_encoded_shape + n_exog\n",
    "        features = np.full(\n",
    "            shape=(n_samples, features_shape), fill_value=np.nan, order='C', dtype=float\n",
    "        )\n",
    "        if self.encoding is not None:\n",
    "            features[:, n_autoreg: n_autoreg + levels_encoded_shape] = levels_encoded\n",
    "\n",
    "        boot_predictions = np.full(\n",
    "            shape=(steps, n_levels, n_boot), fill_value=np.nan, order='C', dtype=float\n",
    "        )\n",
    "\n",
    "        # Expand last_window to 3D: (window_size + steps, n_levels, n_boot)\n",
    "        # All bootstrap samples start with identical last_window values\n",
    "        last_window = last_window.to_numpy()\n",
    "        window_size = last_window.shape[0]\n",
    "        last_window_boot = np.empty(\n",
    "            (window_size + steps, n_levels, n_boot), dtype=float, order='C'\n",
    "        )\n",
    "        last_window_boot[:window_size, :, :] = last_window[:, :, np.newaxis]\n",
    "        last_window_boot[window_size:, :, :] = np.nan\n",
    "\n",
    "        for step in range(steps):\n",
    "\n",
    "            if self.lags is not None:\n",
    "                lags_indices = window_size + step - self.lags\n",
    "                # lagged_values shape: (n_lags, n_levels, n_boot)\n",
    "                lagged_values = last_window_boot[lags_indices, :, :]\n",
    "                # Reshape to (n_boot x n_levels, n_lags) with correct row ordering\n",
    "                features[:, :n_lags] = lagged_values.transpose(2, 1, 0).reshape(n_samples, n_lags)\n",
    "\n",
    "            if self.window_features is not None:\n",
    "                wf_col_offset = n_lags\n",
    "                for wf in self.window_features:\n",
    "                    wf_in = last_window_boot[:window_size + step, :, :]\n",
    "                    # Reshape to (window_length, n_samples) with correct column ordering\n",
    "                    wf_in = wf_in.transpose(0, 2, 1).reshape(window_size + step, n_samples)\n",
    "                    wf_out = wf.transform(wf_in)\n",
    "                    n_wf_cols = wf_out.shape[1]\n",
    "                    features[:, wf_col_offset:wf_col_offset + n_wf_cols] = wf_out\n",
    "                    wf_col_offset += n_wf_cols\n",
    "\n",
    "            if exog_values_dict is not None:\n",
    "                # Reshape (n_levels, n_exog) to (n_boot × n_levels, n_exog)\n",
    "                features[:, -n_exog:] = np.tile(exog_values_dict[step + 1], (n_boot, 1))\n",
    "\n",
    "            pred = self.estimator.predict(features)\n",
    "            # Reshape from (n_boot × n_levels,) to (n_levels, n_boot)\n",
    "            pred = pred.reshape(n_boot, n_levels).T\n",
    "            \n",
    "            # NOTE: CatBoost makes the input array read-only.\n",
    "            if not features.flags.writeable:\n",
    "                features.flags.writeable = True\n",
    "\n",
    "            if use_binned_residuals:\n",
    "                boot_indices = np.arange(n_boot)\n",
    "                # Vectorized residual lookup for all levels and boots\n",
    "                # sampled_residuals shape: (n_bins, steps, n_boot, n_levels)\n",
    "                for j, level in enumerate(levels):\n",
    "                    binner = self.binner.get(level, self.binner['_unknown_level'])\n",
    "                    # Transform all predictions for this level at once (n_boot predictions)\n",
    "                    predicted_bins = binner.transform(pred[j, :]).astype(int)\n",
    "                    # Vectorized lookup: sampled_residuals[predicted_bins, step, boot_indices, j]\n",
    "                    pred[j, :] += sampled_residuals[predicted_bins, step, boot_indices, j]\n",
    "            else:\n",
    "                # sampled_residuals shape: (steps, n_levels, n_boot)\n",
    "                pred += sampled_residuals[step, :, :]\n",
    "\n",
    "            boot_predictions[step, :, :] = pred\n",
    "\n",
    "            # Update last_window_boot with new predictions for next step\n",
    "            last_window_boot[window_size + step, :, :] = pred\n",
    "\n",
    "        set_cpu_gpu_device(estimator=self.estimator, device=original_device)\n",
    "\n",
    "        return boot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.84 s ± 98.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\", \n",
    "        message=\"X does not have valid feature names\", \n",
    "        category=UserWarning\n",
    "    )\n",
    "\n",
    "    forecaster._recursive_predict_bootstrapping_new(\n",
    "                    steps                = steps,\n",
    "                    levels               = levels,\n",
    "                    last_window          = last_window,\n",
    "                    n_boot               = n_boot,\n",
    "                    sampled_residuals    = sampled_residuals,\n",
    "                    use_binned_residuals = use_binned_residuals,\n",
    "                    exog_values_dict     = exog_values_dict,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 28.04260306800097 seconds\n"
     ]
    }
   ],
   "source": [
    "window_features = RollingFeatures(\n",
    "                    window_sizes = 48,\n",
    "                    stats   = ['mean', 'std', 'min', 'max']\n",
    ")\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "                    estimator = LinearRegression(),\n",
    "                    lags      = 48,\n",
    "                    window_features = window_features\n",
    ")\n",
    "forecaster.fit(series=series, store_in_sample_residuals=True)\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "forecaster.predict_bootstrapping(steps=10, n_boot=100)\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(f'Time taken: {end - start} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
