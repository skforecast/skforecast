{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joaquín Amat\\Documents\\GitHub\\skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skforecast.recursive import ForecasterRecursiveMultiSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_weights(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return 0 if index is between '2022-01-08' and '2022-01-10', 1 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-08\") & (index <= \"2022-01-10\"), 0, 1)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def custom_weights_2(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return 2 if index is between '2022-01-11' and '2022-01-13', 3 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-11\") & (index <= \"2022-01-13\"), 2, 3)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def custom_weights_nan(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return np.nan if index is between '2022-01-08' and '2022-01-10', 1 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-08\") & (index <= \"2022-01-10\"), np.nan, 1)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "def custom_weights_negative(index):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Return -1 if index is between '2022-01-08' and '2022-01-10', 1 otherwise.\n",
    "    \"\"\"\n",
    "    weights = np.where((index >= \"2022-01-08\") & (index <= \"2022-01-10\"), -1, 1)\n",
    "\n",
    "    return weights\n",
    "\n",
    "\n",
    "series = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.12362923, 0.51328688],\n",
    "            [0.65138268, 0.11599708],\n",
    "            [0.58142898, 0.72350895],\n",
    "            [0.72969992, 0.10305721],\n",
    "            [0.97790567, 0.20581485],\n",
    "            [0.56924731, 0.41262027],\n",
    "            [0.85369084, 0.82107767],\n",
    "            [0.75425194, 0.0107816],\n",
    "            [0.08167939, 0.94951918],\n",
    "            [0.00249297, 0.55583355],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"series_1\", \"series_2\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-04\",\n",
    "            \"2022-01-05\",\n",
    "            \"2022-01-06\",\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=\"D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_onehot = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 1.0, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 1.0, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 1.0, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 1.0, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 1.0, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 1.0, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 1.0, 0.0],\n",
    "            [0.72350895, 0.11599708, 0.51328688, 0.0, 1.0],\n",
    "            [0.10305721, 0.72350895, 0.11599708, 0.0, 1.0],\n",
    "            [0.20581485, 0.10305721, 0.72350895, 0.0, 1.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 0.0, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 0.0, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 0.0, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 0.0, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"series_1\", \"series_2\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 0.0],\n",
    "            [0.72350895, 0.11599708, 0.51328688, 1.0],\n",
    "            [0.10305721, 0.72350895, 0.11599708, 1.0],\n",
    "            [0.20581485, 0.10305721, 0.72350895, 1.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"_level_skforecast\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal_category = X_train_ordinal.copy()\n",
    "X_train_ordinal_category[\"_level_skforecast\"] = X_train_ordinal_category[\n",
    "    \"_level_skforecast\"\n",
    "].astype(\"category\")\n",
    "\n",
    "X_train_onehot_diferent_length = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 1.0, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 1.0, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 1.0, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 1.0, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 1.0, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 1.0, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 1.0, 0.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 0.0, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 0.0, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 0.0, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 0.0, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"series_1\", \"series_2\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal_diferent_length = pd.DataFrame(\n",
    "    data=np.array(\n",
    "        [\n",
    "            [0.58142898, 0.65138268, 0.12362923, 0.0],\n",
    "            [0.72969992, 0.58142898, 0.65138268, 0.0],\n",
    "            [0.97790567, 0.72969992, 0.58142898, 0.0],\n",
    "            [0.56924731, 0.97790567, 0.72969992, 0.0],\n",
    "            [0.85369084, 0.56924731, 0.97790567, 0.0],\n",
    "            [0.75425194, 0.85369084, 0.56924731, 0.0],\n",
    "            [0.08167939, 0.75425194, 0.85369084, 0.0],\n",
    "            [0.41262027, 0.20581485, 0.10305721, 1.0],\n",
    "            [0.82107767, 0.41262027, 0.20581485, 1.0],\n",
    "            [0.0107816, 0.82107767, 0.41262027, 1.0],\n",
    "            [0.94951918, 0.0107816, 0.82107767, 1.0],\n",
    "        ]\n",
    "    ),\n",
    "    columns=[\"lag_1\", \"lag_2\", \"lag_3\", \"_level_skforecast\"],\n",
    "    index=pd.DatetimeIndex(\n",
    "        [\n",
    "            \"2022-01-07\",\n",
    "            \"2022-01-08\",\n",
    "            \"2022-01-09\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "            \"2022-01-10\",\n",
    "            \"2022-01-11\",\n",
    "            \"2022-01-12\",\n",
    "            \"2022-01-13\",\n",
    "        ],\n",
    "        dtype=\"datetime64[ns]\",\n",
    "        freq=None,\n",
    "    ),\n",
    ")\n",
    "\n",
    "X_train_ordinal_category_diferent_length = X_train_ordinal_diferent_length.copy()\n",
    "X_train_ordinal_category_diferent_length[\"_level_skforecast\"] = (\n",
    "    X_train_ordinal_category_diferent_length[\"_level_skforecast\"].astype(\"category\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\n",
    "    \"weight_func, expected\",\n",
    "    [\n",
    "        (\n",
    "            {\"series_1\": custom_weights},\n",
    "            np.array(\n",
    "                [\n",
    "                    1.0,\n",
    "                    0.0,\n",
    "                    0.0,\n",
    "                    0.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                    1.0,\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            {\"series_2\": custom_weights_2},\n",
    "            np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0]),\n",
    "        ),\n",
    "        (\n",
    "            {\"series_1\": custom_weights, \"series_2\": custom_weights_2},\n",
    "            np.array([1, 0, 0, 0, 1, 1, 1, 3, 2, 2, 2]),\n",
    "        ),\n",
    "    ],\n",
    "    ids=lambda values: f\"levels: {values}\",\n",
    ")\n",
    "def test_create_sample_weights_output_using_weight_func_dict_different_series_lengths(\n",
    "    weight_func, expected\n",
    "):\n",
    "    \"\"\"\n",
    "    Test `sample_weights` creation using `weight_func` with series of different lengths.\n",
    "    \"\"\"\n",
    "    forecaster = ForecasterRecursiveMultiSeries(\n",
    "                     regressor          = LinearRegression(),\n",
    "                     lags               = 3,\n",
    "                     encoding           = \"ordinal\",\n",
    "                     transformer_series = StandardScaler(),\n",
    "                     weight_func        = weight_func\n",
    "                 )\n",
    "    forecaster.encoding_mapping_ = {\"series_1\": 0, \"series_2\": 1}\n",
    "    results = forecaster.create_sample_weights(\n",
    "        series_names_in_=[\"series_1\", \"series_2\"],\n",
    "        X_train=X_train_ordinal_diferent_length,\n",
    "    )\n",
    "\n",
    "    assert np.array_equal(results, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.DataFrame({'l1': pd.Series(np.arange(10)), \n",
    "                       'l2': pd.Series(np.arange(10))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joaquín Amat\\Documents\\GitHub\\skforecast\\skforecast\\recursive\\_forecaster_recursive_multiseries.py:3204: UnknownLevelWarning: As `encoding` is set to `None`, no distinction between levels is made. All residuals are stored in the '_unknown_level' key. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=UnknownLevelWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m\n\u001b[0;32m     26\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m ForecasterRecursiveMultiSeries(\n\u001b[0;32m     27\u001b[0m                     regressor          \u001b[38;5;241m=\u001b[39m LinearRegression(),\n\u001b[0;32m     28\u001b[0m                     lags               \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     32\u001b[0m                 )\n\u001b[0;32m     33\u001b[0m forecaster\u001b[38;5;241m.\u001b[39mfit(series\u001b[38;5;241m=\u001b[39mseries_train)\n\u001b[1;32m---> 34\u001b[0m \u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_out_sample_residuals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unknown_level\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m], y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     40\u001b[0m y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m forecaster\u001b[38;5;241m.\u001b[39mtransformer_series_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(y_true[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\Joaquín Amat\\Documents\\GitHub\\skforecast\\skforecast\\recursive\\_forecaster_recursive_multiseries.py:3210\u001b[0m, in \u001b[0;36mForecasterRecursiveMultiSeries.set_out_sample_residuals\u001b[1;34m(self, y_true, y_pred, append, random_state)\u001b[0m\n\u001b[0;32m   3203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(y_true\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m!=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unknown_level\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m   3204\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   3205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAs `encoding` is set to `None`, no distinction between levels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis made. All residuals are stored in the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unknown_level\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3207\u001b[0m         UnknownLevelWarning\n\u001b[0;32m   3208\u001b[0m     )\n\u001b[1;32m-> 3210\u001b[0m residuals_all_levels \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_sample_residuals_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(residuals_all_levels) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10_000\u001b[39m:\n\u001b[0;32m   3212\u001b[0m     rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(seed\u001b[38;5;241m=\u001b[39mrandom_state)\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "series_train = {\n",
    "    'l1': pd.Series(\n",
    "        np.array([-1.42382504,  1.26372846, -0.87066174, -0.25917323, -0.07534331,\n",
    "                    -0.74088465, -1.3677927 ,  0.6488928 ,  0.36105811, -1.95286306,\n",
    "                    2.34740965,  0.96849691, -0.75938718,  0.90219827, -0.46695317,\n",
    "                    -0.06068952,  0.78884434, -1.25666813,  0.57585751,  1.39897899]),\n",
    "        index = pd.date_range(start='1-1-2018', periods=20, freq='D')\n",
    "    ),\n",
    "    'l2': pd.Series(\n",
    "        np.array([1.32229806, -0.29969852,  0.90291934, -1.62158273, -0.15818926,\n",
    "                    0.44948393, -1.34360107, -0.08168759,  1.72473993,  2.61815943,\n",
    "                    0.77736134,  0.8286332 , -0.95898831, -1.20938829, -1.41229201,\n",
    "                    0.54154683,  0.7519394 , -0.65876032, -1.22867499,  0.25755777]),\n",
    "        index = pd.date_range(start='1-1-2018', periods=20, freq='D')\n",
    "    )\n",
    "}\n",
    "y_true  = {\n",
    "    'l1': np.array([ 0.31290292, -0.13081169,  1.26998312, -0.09296246, -0.06615089]),\n",
    "    'l2': np.array([-1.10821447,  0.13595685,  1.34707776,  0.06114402,  0.0709146 ])\n",
    "}\n",
    "y_pred = {\n",
    "    'l1': np.array([0.43365454, 0.27748366, 0.53025239, 0.53672097, 0.61835001]),\n",
    "    'l2': np.array([-0.79501746,  0.30003095, -1.60270159,  0.26679883, -1.26162378])\n",
    "}\n",
    "\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "                    regressor          = LinearRegression(),\n",
    "                    lags               = 5,\n",
    "                    transformer_series = StandardScaler(),\n",
    "                    differentiation    = 1,\n",
    "                    encoding=None\n",
    "                )\n",
    "forecaster.fit(series=series_train)\n",
    "forecaster.set_out_sample_residuals(\n",
    "    y_true = y_true,\n",
    "    y_pred = y_pred\n",
    ")\n",
    "\n",
    "y_true['_unknown_level'] = np.concatenate([y_true['l2'], y_true['l1']])\n",
    "y_true['l1'] = forecaster.transformer_series_['l1'].transform(y_true['l1'].reshape(-1, 1)).flatten()\n",
    "y_true['l2'] = forecaster.transformer_series_['l2'].transform(y_true['l2'].reshape(-1, 1)).flatten()\n",
    "y_pred['l1'] = forecaster.transformer_series_['l1'].transform(y_pred['l1'].reshape(-1, 1)).flatten()\n",
    "y_pred['l2'] = forecaster.transformer_series_['l2'].transform(y_pred['l2'].reshape(-1, 1)).flatten()\n",
    "y_true['_unknown_level'] = forecaster.transformer_series_['_unknown_level'].transform(y_true['_unknown_level'].reshape(-1, 1)).flatten()\n",
    "y_true['l1'] = forecaster.differentiator_['l1'].transform(y_true['l1'])[forecaster.differentiation_max:]\n",
    "y_true['l2'] = forecaster.differentiator_['l2'].transform(y_true['l2'])[forecaster.differentiation_max:]\n",
    "y_pred['l1'] = forecaster.differentiator_['l1'].transform(y_pred['l1'])[forecaster.differentiation_max:]\n",
    "y_pred['l2'] = forecaster.differentiator_['l2'].transform(y_pred['l2'])[forecaster.differentiation_max:]\n",
    "y_true['_unknown_level'] = forecaster.differentiator_['_unknown_level'].transform(y_true['_unknown_level'])[forecaster.differentiation_max:]\n",
    "residuals = {}\n",
    "residuals['l1'] = y_true['l1'] - y_pred['l1']\n",
    "residuals['l2'] = y_true['l2'] - y_pred['l2']\n",
    "residuals['_unknown_level'] = y_true['_unknown_level'] - np.concatenate([y_pred['l2'], y_pred['l1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: l1\n",
      "key: l2\n"
     ]
    }
   ],
   "source": [
    "for key in residuals.keys():\n",
    "    print(f\"key: {key}\")\n",
    "    np.testing.assert_array_almost_equal(residuals[key], forecaster.out_sample_residuals_[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6845009 , -0.62968343, -0.40829535, -0.31319701, -0.20565481,\n",
       "       -0.1640741 , -0.12075162,  0.73973073,  1.33253838,  2.94977935])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.concatenate([(y_true['l2'] - y_pred['l2']), (y_true['l1'] - y_pred['l1'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12075162, -0.40829535,  0.73973073, -0.62968343, -0.6845009 ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true['l1'] - y_pred['l1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31319701, -0.1640741 ,  2.94977935, -0.20565481,  1.33253838])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true['l2'] - y_pred['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31319701, -0.1640741 ,  2.94977935, -0.20565481,  1.33253838,\n",
       "       -0.12075162, -0.40829535,  0.73973073, -0.62968343, -0.6845009 ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residuals['_unknown_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joaquín Amat\\Documents\\GitHub\\skforecast\\skforecast\\recursive\\_forecaster_recursive_multiseries.py:3204: UnknownLevelWarning: As `encoding` is set to `None`, no distinction between levels is made. All residuals are stored in the '_unknown_level' key. \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=UnknownLevelWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 34\u001b[0m\n\u001b[0;32m     26\u001b[0m forecaster \u001b[38;5;241m=\u001b[39m ForecasterRecursiveMultiSeries(\n\u001b[0;32m     27\u001b[0m                     regressor          \u001b[38;5;241m=\u001b[39m LinearRegression(),\n\u001b[0;32m     28\u001b[0m                     lags               \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     32\u001b[0m                 )\n\u001b[0;32m     33\u001b[0m forecaster\u001b[38;5;241m.\u001b[39mfit(series\u001b[38;5;241m=\u001b[39mseries_train)\n\u001b[1;32m---> 34\u001b[0m \u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_out_sample_residuals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m forecaster\u001b[38;5;241m.\u001b[39mout_sample_residuals_\n",
      "File \u001b[1;32mc:\\Users\\Joaquín Amat\\Documents\\GitHub\\skforecast\\skforecast\\recursive\\_forecaster_recursive_multiseries.py:3210\u001b[0m, in \u001b[0;36mForecasterRecursiveMultiSeries.set_out_sample_residuals\u001b[1;34m(self, y_true, y_pred, append, random_state)\u001b[0m\n\u001b[0;32m   3203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(y_true\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m!=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unknown_level\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m   3204\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   3205\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAs `encoding` is set to `None`, no distinction between levels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3206\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis made. All residuals are stored in the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unknown_level\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m key.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3207\u001b[0m             UnknownLevelWarning\n\u001b[0;32m   3208\u001b[0m         )\n\u001b[1;32m-> 3210\u001b[0m     residuals_all_levels \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_sample_residuals_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3211\u001b[0m     \u001b[38;5;66;03m# if len(residuals_all_levels) > 10_000:\u001b[39;00m\n\u001b[0;32m   3212\u001b[0m     \u001b[38;5;66;03m#     rng = np.random.default_rng(seed=random_state)\u001b[39;00m\n\u001b[0;32m   3213\u001b[0m     \u001b[38;5;66;03m#     residuals_all_levels = rng.choice(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3225\u001b[0m     \u001b[38;5;66;03m#     }\u001b[39;00m\n\u001b[0;32m   3226\u001b[0m     \u001b[38;5;66;03m# }          \u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unknown_level\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m series_to_update:\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "series_train = {\n",
    "    'l1': pd.Series(\n",
    "        np.array([-1.42382504,  1.26372846, -0.87066174, -0.25917323, -0.07534331,\n",
    "                    -0.74088465, -1.3677927 ,  0.6488928 ,  0.36105811, -1.95286306,\n",
    "                    2.34740965,  0.96849691, -0.75938718,  0.90219827, -0.46695317,\n",
    "                    -0.06068952,  0.78884434, -1.25666813,  0.57585751,  1.39897899]),\n",
    "        index = pd.date_range(start='1-1-2018', periods=20, freq='D')\n",
    "    ),\n",
    "    'l2': pd.Series(\n",
    "        np.array([1.32229806, -0.29969852,  0.90291934, -1.62158273, -0.15818926,\n",
    "                    0.44948393, -1.34360107, -0.08168759,  1.72473993,  2.61815943,\n",
    "                    0.77736134,  0.8286332 , -0.95898831, -1.20938829, -1.41229201,\n",
    "                    0.54154683,  0.7519394 , -0.65876032, -1.22867499,  0.25755777]),\n",
    "        index = pd.date_range(start='1-1-2018', periods=20, freq='D')\n",
    "    )\n",
    "}\n",
    "y_true  = {\n",
    "    'l1': np.array([ 0.31290292, -0.13081169,  1.26998312, -0.09296246, -0.06615089]),\n",
    "    'l2': np.array([-1.10821447,  0.13595685,  1.34707776,  0.06114402,  0.0709146 ])\n",
    "}\n",
    "y_pred = {\n",
    "    'l1': np.array([0.43365454, 0.27748366, 0.53025239, 0.53672097, 0.61835001]),\n",
    "    'l2': np.array([-0.79501746,  0.30003095, -1.60270159,  0.26679883, -1.26162378])\n",
    "}\n",
    "\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "                    regressor          = LinearRegression(),\n",
    "                    lags               = 5,\n",
    "                    transformer_series = StandardScaler(),\n",
    "                    differentiation    = 1,\n",
    "                    encoding=None\n",
    "                )\n",
    "forecaster.fit(series=series_train)\n",
    "forecaster.set_out_sample_residuals(\n",
    "    y_true = y_true,\n",
    "    y_pred = y_pred\n",
    ")\n",
    "\n",
    "forecaster.out_sample_residuals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_unknown_level': <skforecast.preprocessing.preprocessing.QuantileBinner at 0x1aa35ae5790>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.binner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': TimeSeriesDifferentiator(order=1, window_size=6),\n",
       " 'l2': TimeSeriesDifferentiator(order=1, window_size=6),\n",
       " '_unknown_level': TimeSeriesDifferentiator(order=1, window_size=6)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.differentiator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_unknown_level': StandardScaler()}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.transformer_series_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l1', 'l2']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.series_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.25863534,  1.03260854, -1.23173923, -0.04930636,  0.33397462,\n",
       "        0.13413074,  2.8008002 , -2.83820057,  1.38354995,  0.13413074,\n",
       "        2.8008002 , -2.83820057,  1.38354995, -0.25863534,  1.03260854,\n",
       "       -1.23173923, -0.04930636])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self = forecaster\n",
    "np.concatenate(list(self.out_sample_residuals_.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_14_p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
