{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/home/joaquin/Documents/GitHub/skforecast\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "path = str(Path.cwd().parent)\n",
    "print(path)\n",
    "sys.path.insert(1, path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Optional\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "class DriftDetector:\n",
    "    \"\"\"\n",
    "    Univariate drift detector per feature using training histograms only (no raw data kept).\n",
    "\n",
    "    fit():\n",
    "      - Builds per-feature histograms (equal-width, bins=int) on numeric columns.\n",
    "      - Precomputes per-bin lookup tables for:\n",
    "        ks, jsd, kl, psi, p_bin and a fast Wasserstein-by-center approximation.\n",
    "\n",
    "    predict(df: single-row DataFrame):\n",
    "      - Bins each value, then returns metrics by simple array indexing.\n",
    "      - Columns: ks, wasserstein, jsd, kl, psi, p_bin.\n",
    "\n",
    "    Notes\n",
    "    - Only numeric columns are used for fitting. Same set must exist at predict time.\n",
    "    - Non-finite values in the new observation yield NaN metrics for those features.\n",
    "    - PSI uses the standard definition: sum((actual - expected) * ln(actual/expected)).\n",
    "    - Wasserstein default is a fast per-bin-center approximation (no raw values).\n",
    "      Set wd_mode='exact' to compute E[|X - x0|] against centers at predict-time\n",
    "      (still histogram-based; cost O(bins) per feature).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bins: int = 20, eps: float = 1e-12, wd_mode: str = \"center\"):\n",
    "        if not isinstance(bins, int) or bins <= 0:\n",
    "            raise ValueError(\"bins must be a positive integer\")\n",
    "        if wd_mode not in (\"center\", \"exact\"):\n",
    "            raise ValueError(\"wd_mode must be 'center' or 'exact'\")\n",
    "        self.bins = bins\n",
    "        self.eps = eps\n",
    "        self.wd_mode = wd_mode\n",
    "\n",
    "        # Learned state\n",
    "        self.features: Optional[List[str]] = None\n",
    "        self.hist_array: Optional[np.ndarray] = None           # (n_feat, B)\n",
    "        self.bin_edges_array: Optional[List[np.ndarray]] = None# list length n_feat, each (B+1,)\n",
    "        self.bin_centers_array: Optional[np.ndarray] = None    # (n_feat, B)\n",
    "        self.cdf_array: Optional[np.ndarray] = None            # (n_feat, B)\n",
    "\n",
    "        # Lookups for O(1) predict (by bin index)\n",
    "        self.ks_lookup: Optional[np.ndarray] = None            # (n_feat, B)\n",
    "        self.jsd_lookup: Optional[np.ndarray] = None           # (n_feat, B)\n",
    "        self.kl_lookup: Optional[np.ndarray] = None            # (n_feat, B)\n",
    "        self.psi_lookup: Optional[np.ndarray] = None           # (n_feat, B)\n",
    "        self.wd_lookup: Optional[np.ndarray] = None            # (n_feat, B) Wasserstein-by-center\n",
    "        # p_bin is just hist_array\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        \"\"\"Fit per-feature histograms on numeric columns and precompute lookups.\"\"\"\n",
    "        num_features = df.select_dtypes(include=[np.number]).columns\n",
    "        self.features = list(num_features)\n",
    "        B = self.bins\n",
    "\n",
    "        hists, edges, centers, cdfs = [], [], [], []\n",
    "        for col in self.features:\n",
    "            values = df[col].dropna().values\n",
    "            if values.size == 0:\n",
    "                # Mark invalid feature with NaNs so predict returns NaNs\n",
    "                hist = np.full(B, np.nan, dtype=float)\n",
    "                bin_edges = np.linspace(0.0, 1.0, B + 1)\n",
    "                bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "                cdf = np.full(B, np.nan, dtype=float)\n",
    "            else:\n",
    "                hist, bin_edges = np.histogram(values, bins=B)\n",
    "                hist = hist.astype(float)\n",
    "                hist = hist / (hist.sum() + self.eps)\n",
    "                bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "                cdf = np.cumsum(hist)\n",
    "\n",
    "            hists.append(hist)\n",
    "            edges.append(bin_edges)\n",
    "            centers.append(bin_centers)\n",
    "            cdfs.append(cdf)\n",
    "\n",
    "        self.hist_array = np.stack(hists, axis=0)                          # (F, B)\n",
    "        self.bin_edges_array = edges\n",
    "        self.bin_centers_array = np.stack(centers, axis=0)                 # (F, B)\n",
    "        self.cdf_array = np.stack(cdfs, axis=0)                            # (F, B)\n",
    "\n",
    "        # Precompute KS per bin: max(CDF[k-1], 1 - CDF[k])\n",
    "        F = self.hist_array.shape[0]\n",
    "        cdf = self.cdf_array\n",
    "        left = np.concatenate([np.zeros((F, 1)), cdf[:, :-1]], axis=1)     # CDF before step\n",
    "        right_gap = 1.0 - cdf\n",
    "        self.ks_lookup = np.maximum(left, right_gap)\n",
    "\n",
    "        # Smoothing for q (one-hot with epsilon)\n",
    "        denom = 1.0 + (B - 1) * self.eps\n",
    "        q_k_val = 1.0 / denom\n",
    "        q_other_val = self.eps / denom\n",
    "\n",
    "        p = np.clip(self.hist_array, self.eps, None)                       # avoid zeros\n",
    "        log_p = np.log(p)\n",
    "\n",
    "        # KL(p || q_k) vectorized using constants\n",
    "        log_q_k = np.log(q_k_val)\n",
    "        log_q_other = np.log(q_other_val)\n",
    "        sum_p_logp = np.nansum(p * log_p, axis=1, keepdims=True)           # (F,1)\n",
    "        p_k = p                                                             # alias\n",
    "        # kl[:, k] = sum p log p - [(1 - p_k)*log_q_other + p_k*log_q_k]\n",
    "        self.kl_lookup = sum_p_logp - ((1.0 - p_k) * log_q_other + p_k * log_q_k)\n",
    "\n",
    "        # PSI(actual=q, expected=p): sum (q - p) * ln(q/p)\n",
    "        # For each k: q_i = q_other_val (i!=k); q_k = q_k_val\n",
    "        # Do it with a small loop over bins, vectorized across features\n",
    "        psi = np.empty_like(self.kl_lookup)\n",
    "        jsd = np.empty_like(self.kl_lookup)\n",
    "\n",
    "        # Precompute Wasserstein-by-center lookup (fast mode): wd[k] = sum_j |c_j - c_k| p_j\n",
    "        wd = np.empty_like(self.kl_lookup)\n",
    "        for i in range(F):\n",
    "            ci = self.bin_centers_array[i]\n",
    "            pi = p[i]\n",
    "            if not np.isfinite(pi).all():\n",
    "                wd[i, :] = np.nan\n",
    "                continue\n",
    "            diff = np.abs(ci[:, None] - ci[None, :])  # (B,B) where [j,k] = |c_j - c_k|\n",
    "            # wd[i, k] = sum_j p_j * |c_j - c_k|\n",
    "            wd[i, :] = pi @ diff\n",
    "        self.wd_lookup = wd\n",
    "\n",
    "        # Precompute JSD and PSI lookups; JSD via SciPy (fit-time only, predict stays O(1))\n",
    "        for k in range(B):\n",
    "            q = np.full_like(p, q_other_val)  # (F,B)\n",
    "            q[:, k] = q_k_val\n",
    "            log_q = np.log(q)\n",
    "\n",
    "            # PSI\n",
    "            psi[:, k] = np.nansum((q - p) * (log_q - log_p), axis=1)\n",
    "\n",
    "            # JSD distance (sqrt(JS, base 2)) using SciPy for correctness\n",
    "            jsd[:, k] = np.array([jensenshannon(p[i], q[i]) for i in range(F)])\n",
    "\n",
    "        self.psi_lookup = psi\n",
    "        self.jsd_lookup = jsd\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Compute drift metrics for a single-row DataFrame using O(1) lookups per feature.\"\"\"\n",
    "        if self.hist_array is None:\n",
    "            raise RuntimeError(\"DriftDetector is not fitted. Call fit() first.\")\n",
    "        if len(df) != 1:\n",
    "            raise ValueError(\"Only single-row dataframes are supported.\")\n",
    "        if self.features is None:\n",
    "            raise RuntimeError(\"Missing fitted features state.\")\n",
    "\n",
    "        missing = set(self.features) - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required features: {sorted(missing)}\")\n",
    "\n",
    "        row = df[self.features].iloc[0].astype(float).values  # (F,)\n",
    "        F, B = self.hist_array.shape\n",
    "\n",
    "        # Init outputs\n",
    "        ks = np.full(F, np.nan, dtype=float)\n",
    "        wd = np.full(F, np.nan, dtype=float)\n",
    "        jsd = np.full(F, np.nan, dtype=float)\n",
    "        kl = np.full(F, np.nan, dtype=float)\n",
    "        psi = np.full(F, np.nan, dtype=float)\n",
    "        p_bin = np.full(F, np.nan, dtype=float)\n",
    "\n",
    "        valid_idx = np.where(np.isfinite(row))[0]\n",
    "        if valid_idx.size == 0:\n",
    "            return pd.DataFrame(\n",
    "                {\"ks\": ks, \"wasserstein\": wd, \"jsd\": jsd, \"kl\": kl, \"psi\": psi, \"p_bin\": p_bin},\n",
    "                index=self.features,\n",
    "            )\n",
    "\n",
    "        # Compute bin index with searchsorted; clip to [0, B-1]\n",
    "        bin_idx = np.array([\n",
    "            np.searchsorted(self.bin_edges_array[i], row[i], side=\"right\") - 1\n",
    "            for i in valid_idx\n",
    "        ])\n",
    "        bin_idx = np.clip(bin_idx, 0, B - 1)\n",
    "\n",
    "        # Gather from lookups\n",
    "        ks[valid_idx] = self.ks_lookup[valid_idx, bin_idx]\n",
    "        jsd[valid_idx] = self.jsd_lookup[valid_idx, bin_idx]\n",
    "        kl[valid_idx] = self.kl_lookup[valid_idx, bin_idx]\n",
    "        psi[valid_idx] = self.psi_lookup[valid_idx, bin_idx]\n",
    "        p_bin[valid_idx] = self.hist_array[valid_idx, bin_idx]\n",
    "\n",
    "        # Wasserstein\n",
    "        if self.wd_mode == \"center\":\n",
    "            wd[valid_idx] = self.wd_lookup[valid_idx, bin_idx]\n",
    "        else:\n",
    "            # exact against x0 using centers and training p (still histogram-based)\n",
    "            centers_valid = self.bin_centers_array[valid_idx]\n",
    "            hist_valid = self.hist_array[valid_idx]\n",
    "            wd[valid_idx] = np.sum(np.abs(centers_valid - row[valid_idx, None]) * hist_valid, axis=1)\n",
    "\n",
    "        return pd.DataFrame(\n",
    "            {\"ks\": ks, \"wasserstein\": wd, \"jsd\": jsd, \"kl\": kl, \"psi\": psi, \"p_bin\": p_bin},\n",
    "            index=self.features,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ks   wasserstein       jsd         kl        psi   p_bin\n",
      "age     0.6803      9.543505  0.701133  21.724580  23.765570  0.1299\n",
      "income  0.5405  10059.659374  0.688611  21.194249  23.115662  0.1464\n",
      "score   0.5368     41.190276  0.687045  21.138187  23.045357  0.1485\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    \"age\": np.random.normal(40, 10, 10000),\n",
    "    \"income\": np.random.normal(50000, 12000, 10000),\n",
    "    \"score\": np.random.normal(700, 50, 10000)\n",
    "})\n",
    "\n",
    "new_df = pd.DataFrame({\n",
    "    \"age\": [45],\n",
    "    \"income\": [52000],\n",
    "    \"score\": [720]\n",
    "})\n",
    "\n",
    "detector = DriftDetector(bins=20).fit(train_df)\n",
    "metrics = detector.predict(new_df)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_16_py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
