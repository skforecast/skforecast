{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8bfe72e",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning and lags selection\n",
    "\n",
    "Hyperparameter tuning is a key step in building accurate and robust machine learning models. Hyperparameters are configuration values that cannot be learned directly from data and must be defined by the user before training. These values can significantly affect model performance, and carefully tuning them helps improve both accuracy and generalization.\n",
    "\n",
    "In forecasting models, the selection of **lags** (past time steps used as predictors) is considered an additional hyperparameter, as it directly influences the model's input structure and learning capacity.\n",
    "\n",
    "Hyperparameter tuning consists of systematically evaluating combinations of hyperparameters (including lags) to find the configuration that yields the best predictive performance. The **skforecast** library supports several tuning strategies: **grid search**, **random search**, and **Bayesian search**. These strategies can be used with either [backtesting](../user_guides/backtesting.html) or [one-step-ahead validation](../user_guides/hyperparameter-tuning-and-lags-selection.html#one-step-ahead-validation) to determine the optimal parameter set for a given forecasting task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bd6f81b",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4; border-color: #00b8d4; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b style=\"color: #00b8d4;\">&#9998 Note</b>\n",
    "</p>\n",
    "\n",
    "All <b>backtesting</b> and <b>hyperparameter search</b> functions in the <code>model_selection</code> module include the <code>n_jobs</code> argument, enabling <b>multi-process parallelization</b> to improve computational performance.\n",
    "\n",
    "Its effectiveness depends on factors like the regressor type, the number of model fits to perform, and the volume of data. When <code>n_jobs</code> is set to <code>'auto'</code>, the level of parallelization is automatically determined using heuristic rules designed to select the most efficient configuration for each scenario.\n",
    "\n",
    "For more information, see the guide <a href=\"../faq/parallelization-skforecast.html\">Parallelization in skforecast</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a589bf",
   "metadata": {},
   "source": [
    "## Validation strategies\n",
    "\n",
    "Hyperparameter and lag tuning involves systematically testing different values or combinations of hyperparameters (and/or lags) to find the optimal configuration that gives the best performance. The **skforecast** library provides two different methods to evaluate each candidate configuration:\n",
    "\n",
    "+ **Backtesting**: Simulates a real deployment scenario by generating multi-step forecasts in repeated iterations, using the defined forecast horizon and retraining frequency. This approach provides a realistic estimate of performance over time. Use the <code>[TimeSeriesFold](../api/model_selection.html#skforecast.model_selection._split.TimeSeriesFold)</code> class for this validation strategy. [More information](../user_guides/backtesting.html).\n",
    "\n",
    "+ **One-Step-Ahead**: Evaluates model performance using only one-step-ahead forecasts ($t+1$). This method is faster, as it requires fewer iterations, but it only tests the model's performance in the immediate next time step. Use the <code>[OneStepAheadFold](../api/model_selection.html#skforecast.model_selection._split.OneStepAheadFold)</code> class for the one-step-ahead strategy. [More information](../user_guides/hyperparameter-tuning-and-lags-selection.html#one-step-ahead-validation).\n",
    "\n",
    "Although the two methods may produce different results, they tend to converge on similar hyperparameter selections over time. The one-step-ahead method is faster than backtesting because it requires fewer iterations; however, it only tests the model's performance in the next immediate time step. For a more accurate multi-step performance estimate, it is recommended to backtest the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76193903",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4; border-color: #00b8d4; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b style=\"color: #00b8d4;\">&#9998 Note</b>\n",
    "</p>\n",
    "\n",
    "For a more detailed comparison of the results (**execution time** and **metric**) obtained with each strategy, visit <a href=\"../faq/parameters-search-backtesting-vs-one-step-ahead.html\">Hyperparameters and lags search: backtesting vs one-step-ahead</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc006084",
   "metadata": {},
   "source": [
    "## Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902da042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.recursive import ForecasterRecursive\n",
    "from skforecast.plot import set_dark_theme\n",
    "from skforecast.model_selection import (\n",
    "    TimeSeriesFold,\n",
    "    OneStepAheadFold,\n",
    "    grid_search_forecaster,\n",
    "    random_search_forecaster,\n",
    "    bayesian_search_forecaster\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ad54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2o\n",
      "---\n",
      "Monthly expenditure ($AUD) on corticosteroid drugs that the Australian health\n",
      "system had between 1991 and 2008.\n",
      "Hyndman R (2023). fpp3: Data for Forecasting: Principles and Practice(3rd\n",
      "Edition). http://pkg.robjhyndman.com/fpp3package/,https://github.com/robjhyndman\n",
      "/fpp3package, http://OTexts.com/fpp3.\n",
      "Shape of the dataset: (204, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-07-01</th>\n",
       "      <td>0.429795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-08-01</th>\n",
       "      <td>0.400906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-09-01</th>\n",
       "      <td>0.432159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   y\n",
       "datetime            \n",
       "1991-07-01  0.429795\n",
       "1991-08-01  0.400906\n",
       "1991-09-01  0.432159"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0}\n",
    ")\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data[['y']]\n",
    "data = data.sort_index()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f18cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates      : 1991-07-01 00:00:00 --- 2001-01-01 00:00:00  (n=115)\n",
      "Validation dates : 2001-02-01 00:00:00 --- 2006-01-01 00:00:00  (n=60)\n",
      "Test dates       : 2006-02-01 00:00:00 --- 2008-06-01 00:00:00 (n=29)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train-val-test dates\n",
    "# ==============================================================================\n",
    "end_train = '2001-01-01 23:59:00'\n",
    "end_val = '2006-01-01 23:59:00'\n",
    "\n",
    "print(\n",
    "    f\"Train dates      : {data.index.min()} --- {data.loc[:end_train].index.max()}\"\n",
    "    f\"  (n={len(data.loc[:end_train])})\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation dates : {data.loc[end_train:].index.min()} --- {data.loc[:end_val].index.max()}\"\n",
    "    f\"  (n={len(data.loc[end_train:end_val])})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates       : {data.loc[end_val:].index.min()} --- {data.index.max()}\"\n",
    "    f\" (n={len(data.loc[end_val:])})\"\n",
    ")\n",
    "print(\"\")\n",
    "\n",
    "# Plot\n",
    "# ==============================================================================\n",
    "set_dark_theme()\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "data.loc[:end_train, 'y'].plot(ax=ax, label='train')\n",
    "data.loc[end_train:end_val, 'y'].plot(ax=ax, label='validation')\n",
    "data.loc[end_val:, 'y'].plot(ax=ax, label='test')\n",
    "ax.legend()\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bfc04a8",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "Grid search is a popular hyperparameter tuning technique that evaluate an exaustive list of combinations of hyperparameters and lags to find the optimal configuration for a forecasting model. To perform a grid search with the **skforecast** library, two grids are needed: one with different lags (`lags_grid`) and another with the hyperparameters (`param_grid`).\n",
    "\n",
    "The grid search process involves the following steps:\n",
    "\n",
    "1. `grid_search_forecaster` replaces the `lags` argument with the first option appearing in `lags_grid`.\n",
    "\n",
    "2. The function validates all combinations of hyperparameters presented in `param_grid` using [backtesting](../user_guides/backtesting.html) or [one-step-ahead validation](../user_guides/hyperparameter-tuning-and-lags-selection.html#one-step-ahead-validation) validation.\n",
    "\n",
    "3. The function repeats these two steps until it has evaluated all possible combinations of lags and hyperparameters.\n",
    "\n",
    "4. If `return_best = True`, the original forecaster is trained with the best lags and hyperparameters configuration found during the grid search process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748732ed",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "When using <b>backtesting</b> as the validation strategy, the computational cost of the tuning largely depends on the strategy used to evaluate each hyperparameter combination. In general, the more re-trainings required, the longer the tuning process will take.\n",
    "\n",
    "To speed up the prototyping phase, a two-step approach is recommended. First, run the search with <code>refit=False</code> to explore a broad range of values quickly. Then, refine the search within the most promising region using a tailored backtesting strategy aligned with the specific needs of the use case.\n",
    "\n",
    "For more guidance, refer to the following resource: <a href=\"../user_guides/backtesting.html#which-strategy-should-i-use\">Which backtesting strategy should I use?</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10187b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d26dd0adf04b2e977bf0a414949ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2155febf1842cb92a4c837ed78eafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.04387531272712768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               lags lags_label  \\\n",
       "0                         [1, 2, 3]     lags_1   \n",
       "1                         [1, 2, 3]     lags_1   \n",
       "2                         [1, 2, 3]     lags_1   \n",
       "3                     [1, 2, 3, 20]     lags_3   \n",
       "4                     [1, 2, 3, 20]     lags_3   \n",
       "5                     [1, 2, 3, 20]     lags_3   \n",
       "6                         [1, 2, 3]     lags_1   \n",
       "7                         [1, 2, 3]     lags_1   \n",
       "8                         [1, 2, 3]     lags_1   \n",
       "9                     [1, 2, 3, 20]     lags_3   \n",
       "10                    [1, 2, 3, 20]     lags_3   \n",
       "11                    [1, 2, 3, 20]     lags_3   \n",
       "12  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "13  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "14  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "15  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "16  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "17  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "\n",
       "                                    params  mean_squared_error  max_depth  \\\n",
       "0    {'max_depth': 5, 'n_estimators': 100}            0.043875          5   \n",
       "1   {'max_depth': 10, 'n_estimators': 100}            0.043875         10   \n",
       "2   {'max_depth': 15, 'n_estimators': 100}            0.043875         15   \n",
       "3   {'max_depth': 10, 'n_estimators': 100}            0.044074         10   \n",
       "4    {'max_depth': 5, 'n_estimators': 100}            0.044074          5   \n",
       "5   {'max_depth': 15, 'n_estimators': 100}            0.044074         15   \n",
       "6    {'max_depth': 10, 'n_estimators': 50}            0.045423         10   \n",
       "7    {'max_depth': 15, 'n_estimators': 50}            0.045423         15   \n",
       "8     {'max_depth': 5, 'n_estimators': 50}            0.045423          5   \n",
       "9    {'max_depth': 10, 'n_estimators': 50}            0.046221         10   \n",
       "10   {'max_depth': 15, 'n_estimators': 50}            0.046221         15   \n",
       "11    {'max_depth': 5, 'n_estimators': 50}            0.046221          5   \n",
       "12  {'max_depth': 10, 'n_estimators': 100}            0.047896         10   \n",
       "13   {'max_depth': 5, 'n_estimators': 100}            0.047896          5   \n",
       "14  {'max_depth': 15, 'n_estimators': 100}            0.047896         15   \n",
       "15    {'max_depth': 5, 'n_estimators': 50}            0.051399          5   \n",
       "16   {'max_depth': 10, 'n_estimators': 50}            0.051399         10   \n",
       "17   {'max_depth': 15, 'n_estimators': 50}            0.051399         15   \n",
       "\n",
       "    n_estimators  \n",
       "0            100  \n",
       "1            100  \n",
       "2            100  \n",
       "3            100  \n",
       "4            100  \n",
       "5            100  \n",
       "6             50  \n",
       "7             50  \n",
       "8             50  \n",
       "9             50  \n",
       "10            50  \n",
       "11            50  \n",
       "12           100  \n",
       "13           100  \n",
       "14           100  \n",
       "15            50  \n",
       "16            50  \n",
       "17            50  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = {\n",
    "    'lags_1': 3,\n",
    "    'lags_2': 10,\n",
    "    'lags_3': [1, 2, 3, 20]\n",
    "}\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = '2001-01-01 23:59:00',  # Same as len(data.loc[:end_train])\n",
    "         refit              = False\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              cv            = cv,\n",
    "              metric        = 'mean_squared_error',\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True\n",
    "          )\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2b2f2e0",
   "metadata": {},
   "source": [
    "Since `return_best = True`, the forecaster object is updated with the best configuration found and trained with the whole data set. This means that the final model obtained from grid search will have the best combination of lags and hyperparameters that resulted in the highest performance metric. This final model can then be used for future predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a718228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd {\n",
       "            font-family: 'Arial', sans-serif;\n",
       "            font-size: 0.9em;\n",
       "            color: #333333;\n",
       "            border: 1px solid #ddd;\n",
       "            background-color: #f0f8ff;\n",
       "            padding: 5px 15px;\n",
       "            border-radius: 8px;\n",
       "            max-width: 600px;\n",
       "            #margin: auto;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd h2 {\n",
       "            font-size: 1.5em;\n",
       "            color: #222222;\n",
       "            border-bottom: 2px solid #ddd;\n",
       "            padding-bottom: 5px;\n",
       "            margin-bottom: 15px;\n",
       "            margin-top: 5px;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd details {\n",
       "            margin: 10px 0;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd summary {\n",
       "            font-weight: bold;\n",
       "            font-size: 1.1em;\n",
       "            color: #000000;\n",
       "            cursor: pointer;\n",
       "            margin-bottom: 5px;\n",
       "            background-color: #b3dbfd;\n",
       "            padding: 5px;\n",
       "            border-radius: 5px;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd summary:hover {\n",
       "            color: #000000;\n",
       "            background-color: #e0e0e0;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd ul {\n",
       "            font-family: 'Courier New', monospace;\n",
       "            list-style-type: none;\n",
       "            padding-left: 20px;\n",
       "            margin: 10px 0;\n",
       "            line-height: normal;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd li {\n",
       "            margin: 5px 0;\n",
       "            font-family: 'Courier New', monospace;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd li strong {\n",
       "            font-weight: bold;\n",
       "            color: #444444;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd li::before {\n",
       "            content: \"- \";\n",
       "            color: #666666;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd a {\n",
       "            color: #001633;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd a:hover {\n",
       "            color: #359ccb; \n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "        <div class=\"container-1e5f6207e6504585b7c7e9072ae2cbcd\">\n",
       "            <h2>ForecasterRecursive</h2>\n",
       "            <details open>\n",
       "                <summary>General Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Regressor:</strong> LGBMRegressor</li>\n",
       "                    <li><strong>Lags:</strong> [1 2 3]</li>\n",
       "                    <li><strong>Window features:</strong> None</li>\n",
       "                    <li><strong>Window size:</strong> 3</li>\n",
       "                    <li><strong>Series name:</strong> y</li>\n",
       "                    <li><strong>Exogenous included:</strong> False</li>\n",
       "                    <li><strong>Weight function included:</strong> False</li>\n",
       "                    <li><strong>Differentiation order:</strong> None</li>\n",
       "                    <li><strong>Creation date:</strong> 2025-05-01 12:24:24</li>\n",
       "                    <li><strong>Last fit date:</strong> 2025-05-01 12:24:25</li>\n",
       "                    <li><strong>Skforecast version:</strong> 0.16.0</li>\n",
       "                    <li><strong>Python version:</strong> 3.12.9</li>\n",
       "                    <li><strong>Forecaster id:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Exogenous Variables</summary>\n",
       "                <ul>\n",
       "                    None\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Data Transformations</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Transformer for y:</strong> None</li>\n",
       "                    <li><strong>Transformer for exog:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Training Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Training range:</strong> [Timestamp('1991-07-01 00:00:00'), Timestamp('2006-01-01 00:00:00')]</li>\n",
       "                    <li><strong>Training index type:</strong> DatetimeIndex</li>\n",
       "                    <li><strong>Training index frequency:</strong> MS</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Regressor Parameters</summary>\n",
       "                <ul>\n",
       "                    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 5, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Fit Kwargs</summary>\n",
       "                <ul>\n",
       "                    {}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <p>\n",
       "                <a href=\"https://skforecast.org/0.16.0/api/forecasterrecursive.html\">&#128712 <strong>API Reference</strong></a>\n",
       "                &nbsp;&nbsp;\n",
       "                <a href=\"https://skforecast.org/0.16.0/user_guides/autoregresive-forecaster.html\">&#128462 <strong>User Guide</strong></a>\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "=================== \n",
       "ForecasterRecursive \n",
       "=================== \n",
       "Regressor: LGBMRegressor \n",
       "Lags: [1 2 3] \n",
       "Window features: None \n",
       "Window size: 3 \n",
       "Series name: y \n",
       "Exogenous included: False \n",
       "Exogenous names: None \n",
       "Transformer for y: None \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Differentiation order: None \n",
       "Training range: [Timestamp('1991-07-01 00:00:00'), Timestamp('2006-01-01 00:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: MS \n",
       "Regressor parameters: \n",
       "    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0,\n",
       "    'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 5,\n",
       "    'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0,\n",
       "    'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None,\n",
       "    'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0,\n",
       "    'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2025-05-01 12:24:24 \n",
       "Last fit date: 2025-05-01 12:24:25 \n",
       "Skforecast version: 0.16.0 \n",
       "Python version: 3.12.9 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ab71330",
   "metadata": {},
   "source": [
    "## Random search\n",
    "\n",
    "Random search is another hyperparameter tuning strategy available in the **skforecast** library. In contrast to grid search, which tries out all possible combinations of hyperparameters and lags, randomized search samples a fixed number of values from the specified possibilities. The number of combinations that are evaluated is given by `n_iter`.\n",
    "\n",
    "It is important to note that random sampling is only applied to the model hyperparameters, but not to the lags. All lags specified by the user are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395d1e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939c8da6fd0542cbb5c7c6d65b399806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aace4bf06d34b4bb1d96596b58e5991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5] \n",
      "  Parameters: {'n_estimators': np.int64(96), 'max_depth': np.int64(19)}\n",
      "  Backtesting metric: 0.04313147793349785\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 96, 'max_depth': 19}</td>\n",
       "      <td>0.043131</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 94, 'max_depth': 28}</td>\n",
       "      <td>0.043171</td>\n",
       "      <td>94</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 77, 'max_depth': 17}</td>\n",
       "      <td>0.043663</td>\n",
       "      <td>77</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 96, 'max_depth': 19}</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags       lags_label                                 params  \\\n",
       "0  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'n_estimators': 96, 'max_depth': 19}   \n",
       "1  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'n_estimators': 94, 'max_depth': 28}   \n",
       "2  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'n_estimators': 77, 'max_depth': 17}   \n",
       "3        [1, 2, 3]        [1, 2, 3]  {'n_estimators': 96, 'max_depth': 19}   \n",
       "\n",
       "   mean_squared_error  n_estimators  max_depth  \n",
       "0            0.043131            96         19  \n",
       "1            0.043171            94         28  \n",
       "2            0.043663            77         17  \n",
       "3            0.043868            96         19  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': np.arange(start=10, stop=100, step=1, dtype=int),\n",
    "    'max_depth': np.arange(start=5, stop=30, step=1, dtype=int)\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results = random_search_forecaster(\n",
    "              forecaster          = forecaster,\n",
    "              y                   = data.loc[:end_val, 'y'],\n",
    "              lags_grid           = lags_grid,\n",
    "              param_distributions = param_distributions,\n",
    "              cv                  = cv,\n",
    "              n_iter              = 5,\n",
    "              metric              = 'mean_squared_error',\n",
    "              return_best         = True,\n",
    "              random_state        = 123,\n",
    "              n_jobs              = 'auto',\n",
    "              verbose             = False,\n",
    "              show_progress       = True\n",
    "          )\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df764b2d",
   "metadata": {},
   "source": [
    "## Bayesian search\n",
    "\n",
    "Grid and random search can yield good results, especially when the search space is well-defined. However, these methods do not consider past results, which limits their ability to focus on the most promising regions and avoid uninformative ones.\n",
    "\n",
    "A more efficient alternative is **Bayesian optimization**, which builds a probabilistic model of the objective function, typically the validation metric (e.g. RMSE, AUC, accuracy). Based on the results observed so far, the algorithm iteratively refines the search, concentrating on regions with the highest potential. This approach reduces the number of evaluations needed by prioritizing the most relevant hyperparameter combinations. It is especially useful when the search space is large or model training is computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8011b4d",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(255,145,0,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #ff9100; border-color: #ff9100; padding-left: 10px; padding-right: 10px\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#ff9100; border-color: #ff1744;\"></i>\n",
    "    <b style=\"color: #ff9100;\"> <span style=\"color: #ff9100;\">&#9888;</span> Warning</b>\n",
    "</p>\n",
    "\n",
    "The <code>lags_grid</code> argument is not required when using <code>bayesian_search_forecaster</code>. Instead, the <code>lags</code> can be included directly in the <code>search_space</code>, allowing them to be optimized jointly with the other regressor hyperparameters during the search.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40bdbc55",
   "metadata": {},
   "source": [
    "In **skforecast**, Bayesian optimization is implemented using **Optuna** and its [`Study object`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study). The goal of the optimization is to **minimize the metric** returned by the validation strategy (either backtesting or one-step-ahead).\n",
    "\n",
    "You can customize the optimization process by passing additional arguments through the `kwargs_create_study` and `kwargs_study_optimize` parameters. These are forwarded to Optuna’s [`create_study`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.create_study.html) and [`optimize method`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study.optimize), respectively.\n",
    "\n",
    "To define the **hyperparameter search space**, the `search_space` argument must be a function that takes an Optuna [Trial object](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial) and returns a dictionary of parameters to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762a37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a16b8a19fd4e2798ca0a62ea3ea7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.126995</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.153278</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.160396</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 5, 'm...</td>\n",
       "      <td>0.172366</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags                                             params  \\\n",
       "0  [1, 2, 3, 4, 5]  {'n_estimators': 19, 'min_samples_leaf': 3, 'm...   \n",
       "1        [1, 2, 3]  {'n_estimators': 15, 'min_samples_leaf': 4, 'm...   \n",
       "2        [1, 2, 3]  {'n_estimators': 13, 'min_samples_leaf': 3, 'm...   \n",
       "3  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 5, 'm...   \n",
       "\n",
       "   mean_absolute_error  n_estimators  min_samples_leaf max_features  \n",
       "0             0.126995            19                 3         sqrt  \n",
       "1             0.153278            15                 4         sqrt  \n",
       "2             0.160396            13                 3         sqrt  \n",
       "3             0.172366            14                 5         log2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags with Optuna\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "\n",
    "# Search space\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'lags'            : trial.suggest_categorical('lags', [3, 5]),\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),  # Can use a date: '2001-01-01 23:59:00'\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data.loc[:end_val, 'y'],\n",
    "                          search_space          = search_space,\n",
    "                          cv                    = cv,\n",
    "                          metric                = 'mean_absolute_error',\n",
    "                          n_trials              = 10,\n",
    "                          random_state          = 123,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True,\n",
    "                          kwargs_create_study   = {},\n",
    "                          kwargs_study_optimize = {}\n",
    "                      )\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0a970a3",
   "metadata": {},
   "source": [
    "The `best_trial` return contains the details of the trial that achieved the best result during optimization. For more information, refer to the [Study class](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400b4ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=7, state=1, values=[0.1269945910624239], datetime_start=datetime.datetime(2025, 5, 1, 12, 24, 26, 777944), datetime_complete=datetime.datetime(2025, 5, 1, 12, 24, 26, 824529), params={'lags': 5, 'n_estimators': 19, 'min_samples_leaf': 3, 'max_features': 'sqrt'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'lags': CategoricalDistribution(choices=(3, 5)), 'n_estimators': IntDistribution(high=20, log=False, low=10, step=1), 'min_samples_leaf': IntDistribution(high=10, log=False, low=1, step=1), 'max_features': CategoricalDistribution(choices=('log2', 'sqrt'))}, trial_id=7, value=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optuna best trial in the study\n",
    "# ==============================================================================\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ee978",
   "metadata": {},
   "source": [
    "## One-step-ahead validation\n",
    "\n",
    "**One-Step-Ahead** evaluates model performance using only one-step-ahead forecasts ($t+1$). This method is faster, as it requires fewer iterations, but it only tests the model's performance in the immediate next time step. Use the <code>[OneStepAheadFold](../api/model_selection.html#skforecast.model_selection._split.OneStepAheadFold)</code> class for the one-step-ahead strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2237c2bf",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "For a more detailed comparison of the results (**execution time** and **metric**) obtained with each strategy, visit <a href=\"../faq/parameters-search-backtesting-vs-one-step-ahead.html\">Hyperparameters and lags search: backtesting vs one-step-ahead</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3cb60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">╭─────────────────────────── OneStepAheadValidationWarning ────────────────────────────╮</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> One-step-ahead predictions are used for faster model comparison, but they may not    <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> fully represent multi-step prediction performance. It is recommended to backtest the <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> final model for a more accurate multi-step performance estimate.                     <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>                                                                                      <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Category : OneStepAheadValidationWarning                                             <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Location :                                                                           <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> /home/joaquin/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/skfore <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> cast/model_selection/_utils.py:693                                                   <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Suppress : warnings.simplefilter('ignore', category=OneStepAheadValidationWarning)   <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">╰──────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;214m╭─\u001b[0m\u001b[38;5;214m──────────────────────────\u001b[0m\u001b[38;5;214m OneStepAheadValidationWarning \u001b[0m\u001b[38;5;214m───────────────────────────\u001b[0m\u001b[38;5;214m─╮\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m One-step-ahead predictions are used for faster model comparison, but they may not    \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m fully represent multi-step prediction performance. It is recommended to backtest the \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m final model for a more accurate multi-step performance estimate.                     \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m                                                                                      \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Category : OneStepAheadValidationWarning                                             \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Location :                                                                           \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m /home/joaquin/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/skfore \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m cast/model_selection/_utils.py:693                                                   \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Suppress : warnings.simplefilter('ignore', category=OneStepAheadValidationWarning)   \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m╰──────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ee4ee03717451abd5a9148dfc4bf74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 6, 'm...</td>\n",
       "      <td>0.180137</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 5, 'm...</td>\n",
       "      <td>0.180815</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 9, 'm...</td>\n",
       "      <td>0.187584</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 7, 'm...</td>\n",
       "      <td>0.188359</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags                                             params  \\\n",
       "0  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 6, 'm...   \n",
       "1  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 5, 'm...   \n",
       "2  [1, 2, 3, 4, 5]  {'n_estimators': 16, 'min_samples_leaf': 9, 'm...   \n",
       "3        [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 7, 'm...   \n",
       "\n",
       "   mean_absolute_error  n_estimators  min_samples_leaf max_features  \n",
       "0             0.180137            20                 6         log2  \n",
       "1             0.180815            14                 5         log2  \n",
       "2             0.187584            16                 9         log2  \n",
       "3             0.188359            14                 7         log2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search with OneStepAheadFold\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "\n",
    "# Search space\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'lags'            : trial.suggest_categorical('lags', [3, 5]),\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "\n",
    "# Folds\n",
    "cv = OneStepAheadFold(\n",
    "    initial_train_size = len(data.loc[:end_train])  # Can use a date: '2001-01-01 23:59:00'\n",
    ")\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data.loc[:end_val, 'y'],\n",
    "                          search_space          = search_space,\n",
    "                          cv                    = cv,\n",
    "                          metric                = 'mean_absolute_error',\n",
    "                          n_trials              = 10,\n",
    "                          random_state          = 123,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True,\n",
    "                          kwargs_create_study   = {},\n",
    "                          kwargs_study_optimize = {}\n",
    "                      )\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8279bda4",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with custom metric\n",
    "\n",
    "In addition to standard metrics such as `mean_squared_error` or `mean_absolute_error`, users can define **custom metric functions**, provided they accept the arguments `y_true` (true values), `y_pred` (predicted values) and optionally `y_train` (train values), and return a numeric value (`float` or `int`).\n",
    "\n",
    "This flexibility allows evaluating model performance under specific conditions, for example, focusing only on certain months, days, non-holiday periods, or the last step of the forecast horizon.\n",
    "\n",
    "To illustrate this, consider a scenario where a 12-month forecast is generated, but only the last three months of each year are relevant for evaluation. This can be handled by defining a custom metric function that filters the desired months before computing the error, and then passing that function to the backtesting or hyperparameter tuning process.\n",
    "\n",
    "The example below shows how to optimize model parameters using a custom metric focused on the last three months of each forecasted year.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf534ac",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "More information about <b>time series forecasting metrics</b> can be found in the <a href=\"../user_guides/metrics.html\">Metrics</a> guide.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b0fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric\n",
    "# ==============================================================================\n",
    "def custom_metric(y_true, y_pred, y_train=None):\n",
    "    \"\"\"\n",
    "    Calculate the mean squared error using only the predicted values of the last\n",
    "    3 months of the year.\n",
    "    \"\"\"\n",
    "    mask = y_true.index.month.isin([10, 11, 12])\n",
    "    metric = mean_squared_error(y_true[mask], y_pred[mask])\n",
    "    \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251660d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47214af392eb4d6cbc1e0e3c5e1d12f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d870bf2461348e4a9de2d4288058c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3 20] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.0681822427249296\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>custom_metric</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lags     lags_label                                  params  \\\n",
       "0  [1, 2, 3, 20]  [1, 2, 3, 20]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "1  [1, 2, 3, 20]  [1, 2, 3, 20]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "2  [1, 2, 3, 20]  [1, 2, 3, 20]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "3      [1, 2, 3]      [1, 2, 3]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "\n",
       "   custom_metric  max_depth  n_estimators  \n",
       "0       0.068182          5           100  \n",
       "1       0.068182         10           100  \n",
       "2       0.068182         15           100  \n",
       "3       0.070472          5           100  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameter and lags with custom metric\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              cv            = cv,\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              metric        = custom_metric,\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True\n",
    "          )\n",
    "\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f185ba5",
   "metadata": {},
   "source": [
    "## Compare multiple metrics\n",
    "\n",
    "The functions `grid_search_forecaster`, `random_search_forecaster`, and `bayesian_search_forecaster` support the evaluation of **multiple metrics** for each forecaster configuration by passing a `list` of metric functions. This list can include both built-in metrics (e.g. `mean_squared_error`, `mean_absolute_error`) and custom-defined ones.\n",
    "\n",
    "When multiple metrics are provided, the **first metric in the list** is used to select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53bd6f4",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "More information about <b>time series forecasting metrics</b> can be found in the <a href=\"../user_guides/metrics.html\">Metrics</a> guide.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d58707a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d142aa18c54135ad66f845d86b9e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909ab0cedb4447159d6626b8e0444f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.18359367014650177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>custom_metric</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.184901</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lags     lags_label                                  params  \\\n",
       "0      [1, 2, 3]      [1, 2, 3]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "1      [1, 2, 3]      [1, 2, 3]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "2      [1, 2, 3]      [1, 2, 3]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "3  [1, 2, 3, 20]  [1, 2, 3, 20]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "\n",
       "   mean_absolute_error  mean_squared_error  custom_metric  max_depth  \\\n",
       "0             0.183594            0.043875       0.070472          5   \n",
       "1             0.183594            0.043875       0.070472         10   \n",
       "2             0.183594            0.043875       0.070472         15   \n",
       "3             0.184901            0.044074       0.068182         10   \n",
       "\n",
       "   n_estimators  \n",
       "0           100  \n",
       "1           100  \n",
       "2           100  \n",
       "3           100  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameter and lags with multiple metrics\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              cv            = cv,\n",
    "              metric        = ['mean_absolute_error', mean_squared_error, custom_metric],\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True\n",
    "          )\n",
    "\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d21a6eba",
   "metadata": {},
   "source": [
    "## Compare multiple regressors\n",
    "\n",
    "The search process can be easily extended to compare several machine learning models. This can be achieved by using a simple for loop that iterates over each regressor and applying the desired function (for example, `grid_search_forecaster`). This approach allows for a more thorough exploration and can help you select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf210dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: RandomForestRegressor(random_state=123)\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa5606b0a1941c3ae039d62720213f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439e00de4016499e8296ef386861aea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaquin/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=13937) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: LGBMRegressor(random_state=123, verbose=-1)\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e133fb925ed4be281a37b34513dba6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bc3bf3da8a4dceb1889433768a169c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: Ridge(random_state=123)\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0565594dde4a2f888b2ed69e125848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bb444cdc6a4cc3866a042391ba97b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>model</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.050180</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.050180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.050907</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.050907</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 20}</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.057542</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 20}</td>\n",
       "      <td>0.057542</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.060078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags       lags_label                                 params  \\\n",
       "1  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]   {'max_depth': 5, 'n_estimators': 50}   \n",
       "0  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'max_depth': 10, 'n_estimators': 50}   \n",
       "3        [1, 2, 3]        [1, 2, 3]  {'max_depth': 10, 'n_estimators': 50}   \n",
       "2        [1, 2, 3]        [1, 2, 3]   {'max_depth': 5, 'n_estimators': 50}   \n",
       "5        [1, 2, 3]        [1, 2, 3]   {'max_depth': 5, 'n_estimators': 20}   \n",
       "4        [1, 2, 3]        [1, 2, 3]  {'max_depth': 10, 'n_estimators': 20}   \n",
       "7  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'max_depth': 10, 'n_estimators': 20}   \n",
       "6  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]   {'max_depth': 5, 'n_estimators': 20}   \n",
       "0        [1, 2, 3]        [1, 2, 3]                        {'alpha': 0.01}   \n",
       "1        [1, 2, 3]        [1, 2, 3]                         {'alpha': 0.1}   \n",
       "\n",
       "   mean_squared_error  max_depth  n_estimators          model  alpha  \n",
       "1            0.050180        5.0          50.0  LGBMRegressor    NaN  \n",
       "0            0.050180       10.0          50.0  LGBMRegressor    NaN  \n",
       "3            0.050907       10.0          50.0  LGBMRegressor    NaN  \n",
       "2            0.050907        5.0          50.0  LGBMRegressor    NaN  \n",
       "5            0.056990        5.0          20.0  LGBMRegressor    NaN  \n",
       "4            0.056990       10.0          20.0  LGBMRegressor    NaN  \n",
       "7            0.057542       10.0          20.0  LGBMRegressor    NaN  \n",
       "6            0.057542        5.0          20.0  LGBMRegressor    NaN  \n",
       "0            0.059814        NaN           NaN          Ridge   0.01  \n",
       "1            0.060078        NaN           NaN          Ridge   0.10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models to compare\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "models = [\n",
    "    RandomForestRegressor(random_state=123), \n",
    "    LGBMRegressor(random_state=123, verbose=-1),\n",
    "    Ridge(random_state=123)\n",
    "]\n",
    "\n",
    "# Hyperparameter to search for each model\n",
    "param_grids = {\n",
    "    'RandomForestRegressor': {'n_estimators': [50, 100], 'max_depth': [5, 15]},\n",
    "    'LGBMRegressor': {'n_estimators': [20, 50], 'max_depth': [5, 10]},\n",
    "    'Ridge': {'alpha': [0.01, 0.1, 1]}\n",
    "}\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 3,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "for i, model in enumerate(models):\n",
    "\n",
    "    print(f\"Grid search for regressor: {model}\")\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "    forecaster = ForecasterRecursive(\n",
    "                     regressor = model,\n",
    "                     lags      = 3\n",
    "                 )\n",
    "\n",
    "    # Regressor hyperparameters\n",
    "    param_grid = param_grids[list(param_grids)[i]]\n",
    "\n",
    "    results = grid_search_forecaster(\n",
    "                  forecaster    = forecaster,\n",
    "                  y             = data.loc[:end_val, 'y'],\n",
    "                  param_grid    = param_grid,\n",
    "                  lags_grid     = lags_grid,\n",
    "                  cv            = cv,\n",
    "                  metric        = 'mean_squared_error',\n",
    "                  return_best   = False,\n",
    "                  n_jobs        = 'auto',\n",
    "                  verbose       = False,\n",
    "                  show_progress = True\n",
    "              )\n",
    "    \n",
    "    # Create a column with model name\n",
    "    results['model'] = list(param_grids)[i]\n",
    "    \n",
    "    df_results = pd.concat([df_results, results])\n",
    "\n",
    "df_results = df_results.sort_values(by='mean_squared_error')\n",
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f77c791",
   "metadata": {},
   "source": [
    "## Saving results to file\n",
    "\n",
    "The results of the hyperparameter search process can be saved to a file by setting the `output_file` argument to the desired path. The results will be saved in a tab-separated values (TSV) format containing the hyperparameters, lags, and metrics of each configuration evaluated during the search. \n",
    "\n",
    "The saving process occurs after each hyperparameter evaluation, which means that if the optimization is stopped in the middle of the process, the logs of the first part of the evaluation have already been stored in the file. This can be useful for further analysis or to keep a record of the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7125be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b2b6ed5f8a4b06bb8e39e34ff1530f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908256c06e1a4590ac6e282bfd2c51f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.04387531272712768\n"
     ]
    }
   ],
   "source": [
    "# Save results to file\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              cv            = cv,\n",
    "              metric        = 'mean_squared_error',\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True,\n",
    "              output_file   = \"results_grid_search.txt\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3f34b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               lags                       lags_label  \\\n",
       "0                           [1 2 3]                          [1 2 3]   \n",
       "1                           [1 2 3]                          [1 2 3]   \n",
       "2                           [1 2 3]                          [1 2 3]   \n",
       "3                           [1 2 3]                          [1 2 3]   \n",
       "4                           [1 2 3]                          [1 2 3]   \n",
       "5                           [1 2 3]                          [1 2 3]   \n",
       "6   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "7   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "8   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "9   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "10  [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "11  [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "12                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "13                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "14                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "15                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "16                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "17                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "\n",
       "                                    params  mean_squared_error  max_depth  \\\n",
       "0     {'max_depth': 5, 'n_estimators': 50}            0.045423          5   \n",
       "1    {'max_depth': 5, 'n_estimators': 100}            0.043875          5   \n",
       "2    {'max_depth': 10, 'n_estimators': 50}            0.045423         10   \n",
       "3   {'max_depth': 10, 'n_estimators': 100}            0.043875         10   \n",
       "4    {'max_depth': 15, 'n_estimators': 50}            0.045423         15   \n",
       "5   {'max_depth': 15, 'n_estimators': 100}            0.043875         15   \n",
       "6     {'max_depth': 5, 'n_estimators': 50}            0.051399          5   \n",
       "7    {'max_depth': 5, 'n_estimators': 100}            0.047896          5   \n",
       "8    {'max_depth': 10, 'n_estimators': 50}            0.051399         10   \n",
       "9   {'max_depth': 10, 'n_estimators': 100}            0.047896         10   \n",
       "10   {'max_depth': 15, 'n_estimators': 50}            0.051399         15   \n",
       "11  {'max_depth': 15, 'n_estimators': 100}            0.047896         15   \n",
       "12    {'max_depth': 5, 'n_estimators': 50}            0.046221          5   \n",
       "13   {'max_depth': 5, 'n_estimators': 100}            0.044074          5   \n",
       "14   {'max_depth': 10, 'n_estimators': 50}            0.046221         10   \n",
       "15  {'max_depth': 10, 'n_estimators': 100}            0.044074         10   \n",
       "16   {'max_depth': 15, 'n_estimators': 50}            0.046221         15   \n",
       "17  {'max_depth': 15, 'n_estimators': 100}            0.044074         15   \n",
       "\n",
       "    n_estimators  \n",
       "0             50  \n",
       "1            100  \n",
       "2             50  \n",
       "3            100  \n",
       "4             50  \n",
       "5            100  \n",
       "6             50  \n",
       "7            100  \n",
       "8             50  \n",
       "9            100  \n",
       "10            50  \n",
       "11           100  \n",
       "12            50  \n",
       "13           100  \n",
       "14            50  \n",
       "15           100  \n",
       "16            50  \n",
       "17           100  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read results file\n",
    "# ==============================================================================\n",
    "pd.read_csv(\"results_grid_search.txt\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py11_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
