{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8bfe72e",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning and lags selection\n",
    "\n",
    "Hyperparameter tuning is a key step in building accurate and robust machine learning models. Hyperparameters are configuration values that cannot be learned directly from data and must be defined by the user before training. These values can significantly affect model performance, and carefully tuning them helps improve both accuracy and generalization.\n",
    "\n",
    "In forecasting models, the selection of **lags** (past time steps used as predictors) is considered an additional hyperparameter, as it directly influences the model's input structure and learning capacity.\n",
    "\n",
    "Hyperparameter tuning consists of systematically evaluating combinations of hyperparameters (including lags) to find the configuration that yields the best predictive performance. The **skforecast** library supports several tuning strategies: **grid search**, **random search**, and **Bayesian search**. These strategies can be used with either [backtesting](../user_guides/backtesting.html) or [one-step-ahead validation](../user_guides/hyperparameter-tuning-and-lags-selection.html#one-step-ahead-validation) to determine the optimal parameter set for a given forecasting task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bd6f81b",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4; border-color: #00b8d4; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b style=\"color: #00b8d4;\">&#9998 Note</b>\n",
    "</p>\n",
    "\n",
    "All <b>backtesting</b> and <b>hyperparameter search</b> functions in the <code>model_selection</code> module include the <code>n_jobs</code> argument, enabling <b>multi-process parallelization</b> to improve computational performance.\n",
    "\n",
    "Its effectiveness depends on factors like the regressor type, the number of model fits to perform, and the volume of data. When <code>n_jobs</code> is set to <code>'auto'</code>, the level of parallelization is automatically determined using heuristic rules designed to select the most efficient configuration for each scenario.\n",
    "\n",
    "For more information, see the guide <a href=\"../faq/parallelization-skforecast.html\">Parallelization in skforecast</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a589bf",
   "metadata": {},
   "source": [
    "## Validation strategies\n",
    "\n",
    "Hyperparameter and lag tuning involves systematically testing different values or combinations of hyperparameters (and/or lags) to find the optimal configuration that gives the best performance. The **skforecast** library provides two different methods to evaluate each candidate configuration:\n",
    "\n",
    "+ **Backtesting**: Simulates a real deployment scenario by generating multi-step forecasts in repeated iterations, using the defined forecast horizon and retraining frequency. This approach provides a realistic estimate of performance over time. Use the <code>[TimeSeriesFold](../api/model_selection.html#skforecast.model_selection._split.TimeSeriesFold)</code> class for this validation strategy. [More information](../user_guides/backtesting.html).\n",
    "\n",
    "+ **One-Step-Ahead**: Evaluates model performance using only one-step-ahead forecasts ($t+1$). This method is faster, as it requires fewer iterations, but it only tests the model's performance in the immediate next time step. Use the <code>[OneStepAheadFold](../api/model_selection.html#skforecast.model_selection._split.OneStepAheadFold)</code> class for the one-step-ahead strategy. [More information](../user_guides/hyperparameter-tuning-and-lags-selection.html#one-step-ahead-validation).\n",
    "\n",
    "Although the two methods may produce different results, they tend to converge on similar hyperparameter selections over time. The one-step-ahead method is faster than backtesting because it requires fewer iterations; however, it only tests the model's performance in the next immediate time step. For a more accurate multi-step performance estimate, it is recommended to backtest the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76193903",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4; border-color: #00b8d4; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b style=\"color: #00b8d4;\">&#9998 Note</b>\n",
    "</p>\n",
    "\n",
    "For a more detailed comparison of the results (**execution time** and **metric**) obtained with each strategy, visit <a href=\"../faq/parameters-search-backtesting-vs-one-step-ahead.html\">Hyperparameters and lags search: backtesting vs one-step-ahead</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc006084",
   "metadata": {},
   "source": [
    "## Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902da042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.recursive import ForecasterRecursive\n",
    "from skforecast.plot import set_dark_theme\n",
    "from skforecast.model_selection import (\n",
    "    TimeSeriesFold,\n",
    "    OneStepAheadFold,\n",
    "    grid_search_forecaster,\n",
    "    random_search_forecaster,\n",
    "    bayesian_search_forecaster\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ad54d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2o\n",
      "---\n",
      "Monthly expenditure ($AUD) on corticosteroid drugs that the Australian health\n",
      "system had between 1991 and 2008.\n",
      "Hyndman R (2023). fpp3: Data for Forecasting: Principles and Practice(3rd\n",
      "Edition). http://pkg.robjhyndman.com/fpp3package/,https://github.com/robjhyndman\n",
      "/fpp3package, http://OTexts.com/fpp3.\n",
      "Shape of the dataset: (204, 2)\n",
      "Train dates      : 1991-07-01 00:00:00 --- 2001-01-01 00:00:00  (n=115)\n",
      "Validation dates : 2001-02-01 00:00:00 --- 2006-01-01 00:00:00  (n=60)\n",
      "Test dates       : 2006-02-01 00:00:00 --- 2008-06-01 00:00:00 (n=29)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0}\n",
    ")\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data[['y']]\n",
    "data = data.sort_index()\n",
    "\n",
    "# Train-val-test dates\n",
    "# ==============================================================================\n",
    "end_train = '2001-01-01 23:59:00'\n",
    "end_val = '2006-01-01 23:59:00'\n",
    "\n",
    "print(\n",
    "    f\"Train dates      : {data.index.min()} --- {data.loc[:end_train].index.max()}\"\n",
    "    f\"  (n={len(data.loc[:end_train])})\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation dates : {data.loc[end_train:].index.min()} --- {data.loc[:end_val].index.max()}\"\n",
    "    f\"  (n={len(data.loc[end_train:end_val])})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates       : {data.loc[end_val:].index.min()} --- {data.index.max()}\"\n",
    "    f\" (n={len(data.loc[end_val:])})\"\n",
    ")\n",
    "\n",
    "# Plot\n",
    "# ==============================================================================\n",
    "set_dark_theme()\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "data.loc[:end_train].plot(ax=ax, label='train')\n",
    "data.loc[end_train:end_val].plot(ax=ax, label='validation')\n",
    "data.loc[end_val:].plot(ax=ax, label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bfc04a8",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "Grid search is a popular hyperparameter tuning technique that evaluate an exaustive list of combinations of hyperparameters and lags to find the optimal configuration for a forecasting model. To perform a grid search with the **skforecast** library, two grids are needed: one with different lags (`lags_grid`) and another with the hyperparameters (`param_grid`).\n",
    "\n",
    "The grid search process involves the following steps:\n",
    "\n",
    "1. `grid_search_forecaster` replaces the `lags` argument with the first option appearing in `lags_grid`.\n",
    "\n",
    "2. The function validates all combinations of hyperparameters presented in `param_grid` using [backtesting](../user_guides/backtesting.html) or [one-step-ahead validation](../user_guides/hyperparameter-tuning-and-lags-selection.html#one-step-ahead-validation) validation.\n",
    "\n",
    "3. The function repeats these two steps until it has evaluated all possible combinations of lags and hyperparameters.\n",
    "\n",
    "4. If `return_best = True`, the original forecaster is trained with the best lags and hyperparameters configuration found during the grid search process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748732ed",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "When using <b>backtesting</b> as the validation strategy, the computational cost of the tuning largely depends on the strategy used to evaluate each hyperparameter combination. In general, the more re-trainings required, the longer the tuning process will take.\n",
    "\n",
    "To speed up the prototyping phase, a two-step approach is recommended. First, run the search with <code>refit=False</code> to explore a broad range of values quickly. Then, refine the search within the most promising region using a tailored backtesting strategy aligned with the specific needs of the use case.\n",
    "\n",
    "For more guidance, refer to the following resource: <a href=\"../user_guides/backtesting.html#which-strategy-should-i-use\">Which backtesting strategy should I use?</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10187b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d26dd0adf04b2e977bf0a414949ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2155febf1842cb92a4c837ed78eafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.04387531272712768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               lags lags_label  \\\n",
       "0                         [1, 2, 3]     lags_1   \n",
       "1                         [1, 2, 3]     lags_1   \n",
       "2                         [1, 2, 3]     lags_1   \n",
       "3                     [1, 2, 3, 20]     lags_3   \n",
       "4                     [1, 2, 3, 20]     lags_3   \n",
       "5                     [1, 2, 3, 20]     lags_3   \n",
       "6                         [1, 2, 3]     lags_1   \n",
       "7                         [1, 2, 3]     lags_1   \n",
       "8                         [1, 2, 3]     lags_1   \n",
       "9                     [1, 2, 3, 20]     lags_3   \n",
       "10                    [1, 2, 3, 20]     lags_3   \n",
       "11                    [1, 2, 3, 20]     lags_3   \n",
       "12  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "13  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "14  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "15  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "16  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "17  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "\n",
       "                                    params  mean_squared_error  max_depth  \\\n",
       "0    {'max_depth': 5, 'n_estimators': 100}            0.043875          5   \n",
       "1   {'max_depth': 10, 'n_estimators': 100}            0.043875         10   \n",
       "2   {'max_depth': 15, 'n_estimators': 100}            0.043875         15   \n",
       "3   {'max_depth': 10, 'n_estimators': 100}            0.044074         10   \n",
       "4    {'max_depth': 5, 'n_estimators': 100}            0.044074          5   \n",
       "5   {'max_depth': 15, 'n_estimators': 100}            0.044074         15   \n",
       "6    {'max_depth': 10, 'n_estimators': 50}            0.045423         10   \n",
       "7    {'max_depth': 15, 'n_estimators': 50}            0.045423         15   \n",
       "8     {'max_depth': 5, 'n_estimators': 50}            0.045423          5   \n",
       "9    {'max_depth': 10, 'n_estimators': 50}            0.046221         10   \n",
       "10   {'max_depth': 15, 'n_estimators': 50}            0.046221         15   \n",
       "11    {'max_depth': 5, 'n_estimators': 50}            0.046221          5   \n",
       "12  {'max_depth': 10, 'n_estimators': 100}            0.047896         10   \n",
       "13   {'max_depth': 5, 'n_estimators': 100}            0.047896          5   \n",
       "14  {'max_depth': 15, 'n_estimators': 100}            0.047896         15   \n",
       "15    {'max_depth': 5, 'n_estimators': 50}            0.051399          5   \n",
       "16   {'max_depth': 10, 'n_estimators': 50}            0.051399         10   \n",
       "17   {'max_depth': 15, 'n_estimators': 50}            0.051399         15   \n",
       "\n",
       "    n_estimators  \n",
       "0            100  \n",
       "1            100  \n",
       "2            100  \n",
       "3            100  \n",
       "4            100  \n",
       "5            100  \n",
       "6             50  \n",
       "7             50  \n",
       "8             50  \n",
       "9             50  \n",
       "10            50  \n",
       "11            50  \n",
       "12           100  \n",
       "13           100  \n",
       "14           100  \n",
       "15            50  \n",
       "16            50  \n",
       "17            50  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = {\n",
    "    'lags_1': 3,\n",
    "    'lags_2': 10,\n",
    "    'lags_3': [1, 2, 3, 20]\n",
    "}\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = '2001-01-01 23:59:00',  # Same as len(data.loc[:end_train])\n",
    "         refit              = False\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              cv            = cv,\n",
    "              metric        = 'mean_squared_error',\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True\n",
    "          )\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2b2f2e0",
   "metadata": {},
   "source": [
    "Since `return_best = True`, the forecaster object is updated with the best configuration found and trained with the whole data set. This means that the final model obtained from grid search will have the best combination of lags and hyperparameters that resulted in the highest performance metric. This final model can then be used for future predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a718228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd {\n",
       "            font-family: 'Arial', sans-serif;\n",
       "            font-size: 0.9em;\n",
       "            color: #333333;\n",
       "            border: 1px solid #ddd;\n",
       "            background-color: #f0f8ff;\n",
       "            padding: 5px 15px;\n",
       "            border-radius: 8px;\n",
       "            max-width: 600px;\n",
       "            #margin: auto;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd h2 {\n",
       "            font-size: 1.5em;\n",
       "            color: #222222;\n",
       "            border-bottom: 2px solid #ddd;\n",
       "            padding-bottom: 5px;\n",
       "            margin-bottom: 15px;\n",
       "            margin-top: 5px;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd details {\n",
       "            margin: 10px 0;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd summary {\n",
       "            font-weight: bold;\n",
       "            font-size: 1.1em;\n",
       "            color: #000000;\n",
       "            cursor: pointer;\n",
       "            margin-bottom: 5px;\n",
       "            background-color: #b3dbfd;\n",
       "            padding: 5px;\n",
       "            border-radius: 5px;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd summary:hover {\n",
       "            color: #000000;\n",
       "            background-color: #e0e0e0;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd ul {\n",
       "            font-family: 'Courier New', monospace;\n",
       "            list-style-type: none;\n",
       "            padding-left: 20px;\n",
       "            margin: 10px 0;\n",
       "            line-height: normal;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd li {\n",
       "            margin: 5px 0;\n",
       "            font-family: 'Courier New', monospace;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd li strong {\n",
       "            font-weight: bold;\n",
       "            color: #444444;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd li::before {\n",
       "            content: \"- \";\n",
       "            color: #666666;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd a {\n",
       "            color: #001633;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "        .container-1e5f6207e6504585b7c7e9072ae2cbcd a:hover {\n",
       "            color: #359ccb; \n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "        <div class=\"container-1e5f6207e6504585b7c7e9072ae2cbcd\">\n",
       "            <h2>ForecasterRecursive</h2>\n",
       "            <details open>\n",
       "                <summary>General Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Regressor:</strong> LGBMRegressor</li>\n",
       "                    <li><strong>Lags:</strong> [1 2 3]</li>\n",
       "                    <li><strong>Window features:</strong> None</li>\n",
       "                    <li><strong>Window size:</strong> 3</li>\n",
       "                    <li><strong>Series name:</strong> y</li>\n",
       "                    <li><strong>Exogenous included:</strong> False</li>\n",
       "                    <li><strong>Weight function included:</strong> False</li>\n",
       "                    <li><strong>Differentiation order:</strong> None</li>\n",
       "                    <li><strong>Creation date:</strong> 2025-05-01 12:24:24</li>\n",
       "                    <li><strong>Last fit date:</strong> 2025-05-01 12:24:25</li>\n",
       "                    <li><strong>Skforecast version:</strong> 0.16.0</li>\n",
       "                    <li><strong>Python version:</strong> 3.12.9</li>\n",
       "                    <li><strong>Forecaster id:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Exogenous Variables</summary>\n",
       "                <ul>\n",
       "                    None\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Data Transformations</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Transformer for y:</strong> None</li>\n",
       "                    <li><strong>Transformer for exog:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Training Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Training range:</strong> [Timestamp('1991-07-01 00:00:00'), Timestamp('2006-01-01 00:00:00')]</li>\n",
       "                    <li><strong>Training index type:</strong> DatetimeIndex</li>\n",
       "                    <li><strong>Training index frequency:</strong> MS</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Regressor Parameters</summary>\n",
       "                <ul>\n",
       "                    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 5, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Fit Kwargs</summary>\n",
       "                <ul>\n",
       "                    {}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <p>\n",
       "                <a href=\"https://skforecast.org/0.16.0/api/forecasterrecursive.html\">&#128712 <strong>API Reference</strong></a>\n",
       "                &nbsp;&nbsp;\n",
       "                <a href=\"https://skforecast.org/0.16.0/user_guides/autoregresive-forecaster.html\">&#128462 <strong>User Guide</strong></a>\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "=================== \n",
       "ForecasterRecursive \n",
       "=================== \n",
       "Regressor: LGBMRegressor \n",
       "Lags: [1 2 3] \n",
       "Window features: None \n",
       "Window size: 3 \n",
       "Series name: y \n",
       "Exogenous included: False \n",
       "Exogenous names: None \n",
       "Transformer for y: None \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Differentiation order: None \n",
       "Training range: [Timestamp('1991-07-01 00:00:00'), Timestamp('2006-01-01 00:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: MS \n",
       "Regressor parameters: \n",
       "    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0,\n",
       "    'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 5,\n",
       "    'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0,\n",
       "    'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None,\n",
       "    'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0,\n",
       "    'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2025-05-01 12:24:24 \n",
       "Last fit date: 2025-05-01 12:24:25 \n",
       "Skforecast version: 0.16.0 \n",
       "Python version: 3.12.9 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ab71330",
   "metadata": {},
   "source": [
    "## Random search\n",
    "\n",
    "Random search is another hyperparameter tuning strategy available in the **skforecast** library. In contrast to grid search, which tries out all possible combinations of hyperparameters and lags, randomized search samples a fixed number of values from the specified possibilities. The number of combinations that are evaluated is given by `n_iter`.\n",
    "\n",
    "It is important to note that random sampling is only applied to the model hyperparameters, but not to the lags. All lags specified by the user are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395d1e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939c8da6fd0542cbb5c7c6d65b399806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aace4bf06d34b4bb1d96596b58e5991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5] \n",
      "  Parameters: {'n_estimators': np.int64(96), 'max_depth': np.int64(19)}\n",
      "  Backtesting metric: 0.04313147793349785\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 96, 'max_depth': 19}</td>\n",
       "      <td>0.043131</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 94, 'max_depth': 28}</td>\n",
       "      <td>0.043171</td>\n",
       "      <td>94</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 77, 'max_depth': 17}</td>\n",
       "      <td>0.043663</td>\n",
       "      <td>77</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 96, 'max_depth': 19}</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags       lags_label                                 params  \\\n",
       "0  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'n_estimators': 96, 'max_depth': 19}   \n",
       "1  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'n_estimators': 94, 'max_depth': 28}   \n",
       "2  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'n_estimators': 77, 'max_depth': 17}   \n",
       "3        [1, 2, 3]        [1, 2, 3]  {'n_estimators': 96, 'max_depth': 19}   \n",
       "\n",
       "   mean_squared_error  n_estimators  max_depth  \n",
       "0            0.043131            96         19  \n",
       "1            0.043171            94         28  \n",
       "2            0.043663            77         17  \n",
       "3            0.043868            96         19  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': np.arange(start=10, stop=100, step=1, dtype=int),\n",
    "    'max_depth': np.arange(start=5, stop=30, step=1, dtype=int)\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results = random_search_forecaster(\n",
    "              forecaster          = forecaster,\n",
    "              y                   = data.loc[:end_val, 'y'],\n",
    "              lags_grid           = lags_grid,\n",
    "              param_distributions = param_distributions,\n",
    "              cv                  = cv,\n",
    "              n_iter              = 5,\n",
    "              metric              = 'mean_squared_error',\n",
    "              return_best         = True,\n",
    "              random_state        = 123,\n",
    "              n_jobs              = 'auto',\n",
    "              verbose             = False,\n",
    "              show_progress       = True\n",
    "          )\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df764b2d",
   "metadata": {},
   "source": [
    "## Bayesian search\n",
    "\n",
    "Grid and random search can yield good results, especially when the search space is well-defined. However, these methods do not consider past results, which limits their ability to focus on the most promising regions and avoid uninformative ones.\n",
    "\n",
    "A more efficient alternative is **Bayesian optimization**, which builds a probabilistic model of the objective function, typically the validation metric (e.g. RMSE, AUC, accuracy). Based on the results observed so far, the algorithm iteratively refines the search, concentrating on regions with the highest potential. This approach reduces the number of evaluations needed by prioritizing the most relevant hyperparameter combinations. It is especially useful when the search space is large or model training is computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8011b4d",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(255,145,0,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #ff9100; border-color: #ff9100; padding-left: 10px; padding-right: 10px\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#ff9100; border-color: #ff1744;\"></i>\n",
    "    <b style=\"color: #ff9100;\"> <span style=\"color: #ff9100;\">&#9888;</span> Warning</b>\n",
    "</p>\n",
    "\n",
    "The <code>lags_grid</code> argument is not required when using <code>bayesian_search_forecaster</code>. Instead, the <code>lags</code> can be included directly in the <code>search_space</code>, allowing them to be optimized jointly with the other regressor hyperparameters during the search.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40bdbc55",
   "metadata": {},
   "source": [
    "In **skforecast**, Bayesian optimization is implemented using **Optuna** and its [`Study object`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study). The goal of the optimization is to **minimize the metric** returned by the validation strategy (either backtesting or one-step-ahead).\n",
    "\n",
    "You can customize the optimization process by passing additional arguments through the `kwargs_create_study` and `kwargs_study_optimize` parameters. These are forwarded to Optuna’s [`create_study`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.create_study.html) and [`optimize method`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study.optimize), respectively.\n",
    "\n",
    "To define the **hyperparameter search space**, the `search_space` argument must be a function that takes an Optuna [Trial object](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial) and returns a dictionary of parameters to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762a37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a16b8a19fd4e2798ca0a62ea3ea7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.126995</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.153278</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.160396</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 5, 'm...</td>\n",
       "      <td>0.172366</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags                                             params  \\\n",
       "0  [1, 2, 3, 4, 5]  {'n_estimators': 19, 'min_samples_leaf': 3, 'm...   \n",
       "1        [1, 2, 3]  {'n_estimators': 15, 'min_samples_leaf': 4, 'm...   \n",
       "2        [1, 2, 3]  {'n_estimators': 13, 'min_samples_leaf': 3, 'm...   \n",
       "3  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 5, 'm...   \n",
       "\n",
       "   mean_absolute_error  n_estimators  min_samples_leaf max_features  \n",
       "0             0.126995            19                 3         sqrt  \n",
       "1             0.153278            15                 4         sqrt  \n",
       "2             0.160396            13                 3         sqrt  \n",
       "3             0.172366            14                 5         log2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags with Optuna\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "\n",
    "# Search space\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'lags'            : trial.suggest_categorical('lags', [3, 5]),\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),  # Can use a date: '2001-01-01 23:59:00'\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data.loc[:end_val, 'y'],\n",
    "                          search_space          = search_space,\n",
    "                          cv                    = cv,\n",
    "                          metric                = 'mean_absolute_error',\n",
    "                          n_trials              = 10,\n",
    "                          random_state          = 123,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True,\n",
    "                          kwargs_create_study   = {},\n",
    "                          kwargs_study_optimize = {}\n",
    "                      )\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0a970a3",
   "metadata": {},
   "source": [
    "The `best_trial` return contains the details of the trial that achieved the best result during optimization. For more information, refer to the [Study class](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400b4ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=7, state=1, values=[0.1269945910624239], datetime_start=datetime.datetime(2025, 5, 1, 12, 24, 26, 777944), datetime_complete=datetime.datetime(2025, 5, 1, 12, 24, 26, 824529), params={'lags': 5, 'n_estimators': 19, 'min_samples_leaf': 3, 'max_features': 'sqrt'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'lags': CategoricalDistribution(choices=(3, 5)), 'n_estimators': IntDistribution(high=20, log=False, low=10, step=1), 'min_samples_leaf': IntDistribution(high=10, log=False, low=1, step=1), 'max_features': CategoricalDistribution(choices=('log2', 'sqrt'))}, trial_id=7, value=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optuna best trial in the study\n",
    "# ==============================================================================\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ee978",
   "metadata": {},
   "source": [
    "## One-step-ahead validation\n",
    "\n",
    "**One-Step-Ahead** evaluates model performance using only one-step-ahead forecasts ($t+1$). This method is faster, as it requires fewer iterations, but it only tests the model's performance in the immediate next time step. Use the <code>[OneStepAheadFold](../api/model_selection.html#skforecast.model_selection._split.OneStepAheadFold)</code> class for the one-step-ahead strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2237c2bf",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "For a more detailed comparison of the results (**execution time** and **metric**) obtained with each strategy, visit <a href=\"../faq/parameters-search-backtesting-vs-one-step-ahead.html\">Hyperparameters and lags search: backtesting vs one-step-ahead</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3cb60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">╭─────────────────────────── OneStepAheadValidationWarning ────────────────────────────╮</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> One-step-ahead predictions are used for faster model comparison, but they may not    <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> fully represent multi-step prediction performance. It is recommended to backtest the <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> final model for a more accurate multi-step performance estimate.                     <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>                                                                                      <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Category : OneStepAheadValidationWarning                                             <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Location :                                                                           <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> /home/joaquin/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/skfore <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> cast/model_selection/_utils.py:693                                                   <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span> Suppress : warnings.simplefilter('ignore', category=OneStepAheadValidationWarning)   <span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">│</span>\n",
       "<span style=\"color: #ffaf00; text-decoration-color: #ffaf00\">╰──────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;214m╭─\u001b[0m\u001b[38;5;214m──────────────────────────\u001b[0m\u001b[38;5;214m OneStepAheadValidationWarning \u001b[0m\u001b[38;5;214m───────────────────────────\u001b[0m\u001b[38;5;214m─╮\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m One-step-ahead predictions are used for faster model comparison, but they may not    \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m fully represent multi-step prediction performance. It is recommended to backtest the \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m final model for a more accurate multi-step performance estimate.                     \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m                                                                                      \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Category : OneStepAheadValidationWarning                                             \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Location :                                                                           \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m /home/joaquin/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/skfore \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m cast/model_selection/_utils.py:693                                                   \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m│\u001b[0m Suppress : warnings.simplefilter('ignore', category=OneStepAheadValidationWarning)   \u001b[38;5;214m│\u001b[0m\n",
       "\u001b[38;5;214m╰──────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ee4ee03717451abd5a9148dfc4bf74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 6, 'm...</td>\n",
       "      <td>0.180137</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 5, 'm...</td>\n",
       "      <td>0.180815</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 9, 'm...</td>\n",
       "      <td>0.187584</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 7, 'm...</td>\n",
       "      <td>0.188359</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags                                             params  \\\n",
       "0  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 6, 'm...   \n",
       "1  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 5, 'm...   \n",
       "2  [1, 2, 3, 4, 5]  {'n_estimators': 16, 'min_samples_leaf': 9, 'm...   \n",
       "3        [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 7, 'm...   \n",
       "\n",
       "   mean_absolute_error  n_estimators  min_samples_leaf max_features  \n",
       "0             0.180137            20                 6         log2  \n",
       "1             0.180815            14                 5         log2  \n",
       "2             0.187584            16                 9         log2  \n",
       "3             0.188359            14                 7         log2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search with OneStepAheadFold\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "\n",
    "# Search space\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'lags'            : trial.suggest_categorical('lags', [3, 5]),\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "\n",
    "# Folds\n",
    "cv = OneStepAheadFold(\n",
    "    initial_train_size = len(data.loc[:end_train])  # Can use a date: '2001-01-01 23:59:00'\n",
    ")\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data.loc[:end_val, 'y'],\n",
    "                          search_space          = search_space,\n",
    "                          cv                    = cv,\n",
    "                          metric                = 'mean_absolute_error',\n",
    "                          n_trials              = 10,\n",
    "                          random_state          = 123,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True,\n",
    "                          kwargs_create_study   = {},\n",
    "                          kwargs_study_optimize = {}\n",
    "                      )\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8279bda4",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with custom metric\n",
    "\n",
    "In addition to standard metrics such as `mean_squared_error` or `mean_absolute_error`, users can define **custom metric functions**, provided they accept the arguments `y_true` (true values), `y_pred` (predicted values) and optionally `y_train` (train values), and return a numeric value (`float` or `int`).\n",
    "\n",
    "This flexibility allows evaluating model performance under specific conditions, for example, focusing only on certain months, days, non-holiday periods, or the last step of the forecast horizon.\n",
    "\n",
    "To illustrate this, consider a scenario where a 12-month forecast is generated, but only the last three months of each year are relevant for evaluation. This can be handled by defining a custom metric function that filters the desired months before computing the error, and then passing that function to the backtesting or hyperparameter tuning process.\n",
    "\n",
    "The example below shows how to optimize model parameters using a custom metric focused on the last three months of each forecasted year.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf534ac",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "More information about <b>time series forecasting metrics</b> can be found in the <a href=\"../user_guides/metrics.html\">Metrics</a> guide.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b0fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric\n",
    "# ==============================================================================\n",
    "def custom_metric(y_true, y_pred, y_train=None):\n",
    "    \"\"\"\n",
    "    Calculate the mean squared error using only the predicted values of the last\n",
    "    3 months of the year.\n",
    "    \"\"\"\n",
    "    mask = y_true.index.month.isin([10, 11, 12])\n",
    "    metric = mean_squared_error(y_true[mask], y_pred[mask])\n",
    "    \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251660d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47214af392eb4d6cbc1e0e3c5e1d12f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d870bf2461348e4a9de2d4288058c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3 20] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.0681822427249296\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>custom_metric</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lags     lags_label                                  params  \\\n",
       "0  [1, 2, 3, 20]  [1, 2, 3, 20]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "1  [1, 2, 3, 20]  [1, 2, 3, 20]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "2  [1, 2, 3, 20]  [1, 2, 3, 20]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "3      [1, 2, 3]      [1, 2, 3]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "\n",
       "   custom_metric  max_depth  n_estimators  \n",
       "0       0.068182          5           100  \n",
       "1       0.068182         10           100  \n",
       "2       0.068182         15           100  \n",
       "3       0.070472          5           100  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameter and lags with custom metric\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              cv            = cv,\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              metric        = custom_metric,\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True\n",
    "          )\n",
    "\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f185ba5",
   "metadata": {},
   "source": [
    "## Compare multiple metrics\n",
    "\n",
    "The functions `grid_search_forecaster`, `random_search_forecaster`, and `bayesian_search_forecaster` support the evaluation of **multiple metrics** for each forecaster configuration by passing a `list` of metric functions. This list can include both built-in metrics (e.g. `mean_squared_error`, `mean_absolute_error`) and custom-defined ones.\n",
    "\n",
    "When multiple metrics are provided, the **first metric in the list** is used to select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53bd6f4",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "More information about <b>time series forecasting metrics</b> can be found in the <a href=\"../user_guides/metrics.html\">Metrics</a> guide.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d58707a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d142aa18c54135ad66f845d86b9e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909ab0cedb4447159d6626b8e0444f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.18359367014650177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>custom_metric</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.184901</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lags     lags_label                                  params  \\\n",
       "0      [1, 2, 3]      [1, 2, 3]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "1      [1, 2, 3]      [1, 2, 3]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "2      [1, 2, 3]      [1, 2, 3]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "3  [1, 2, 3, 20]  [1, 2, 3, 20]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "\n",
       "   mean_absolute_error  mean_squared_error  custom_metric  max_depth  \\\n",
       "0             0.183594            0.043875       0.070472          5   \n",
       "1             0.183594            0.043875       0.070472         10   \n",
       "2             0.183594            0.043875       0.070472         15   \n",
       "3             0.184901            0.044074       0.068182         10   \n",
       "\n",
       "   n_estimators  \n",
       "0           100  \n",
       "1           100  \n",
       "2           100  \n",
       "3           100  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameter and lags with multiple metrics\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              cv            = cv,\n",
    "              metric        = ['mean_absolute_error', mean_squared_error, custom_metric],\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True\n",
    "          )\n",
    "\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d21a6eba",
   "metadata": {},
   "source": [
    "## Compare multiple regressors\n",
    "\n",
    "The search process can be easily extended to compare several machine learning models. This can be achieved by using a simple for loop that iterates over each regressor and applying the desired function (for example, `grid_search_forecaster`). This approach allows for a more thorough exploration and can help you select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf210dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: RandomForestRegressor(random_state=123)\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa5606b0a1941c3ae039d62720213f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439e00de4016499e8296ef386861aea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaquin/miniconda3/envs/skforecast_16_py12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=13937) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: LGBMRegressor(random_state=123, verbose=-1)\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e133fb925ed4be281a37b34513dba6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bc3bf3da8a4dceb1889433768a169c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: Ridge(random_state=123)\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0565594dde4a2f888b2ed69e125848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bb444cdc6a4cc3866a042391ba97b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>model</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.050180</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.050180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.050907</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.050907</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 20}</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.057542</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 20}</td>\n",
       "      <td>0.057542</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.060078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags       lags_label                                 params  \\\n",
       "1  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]   {'max_depth': 5, 'n_estimators': 50}   \n",
       "0  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'max_depth': 10, 'n_estimators': 50}   \n",
       "3        [1, 2, 3]        [1, 2, 3]  {'max_depth': 10, 'n_estimators': 50}   \n",
       "2        [1, 2, 3]        [1, 2, 3]   {'max_depth': 5, 'n_estimators': 50}   \n",
       "5        [1, 2, 3]        [1, 2, 3]   {'max_depth': 5, 'n_estimators': 20}   \n",
       "4        [1, 2, 3]        [1, 2, 3]  {'max_depth': 10, 'n_estimators': 20}   \n",
       "7  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'max_depth': 10, 'n_estimators': 20}   \n",
       "6  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]   {'max_depth': 5, 'n_estimators': 20}   \n",
       "0        [1, 2, 3]        [1, 2, 3]                        {'alpha': 0.01}   \n",
       "1        [1, 2, 3]        [1, 2, 3]                         {'alpha': 0.1}   \n",
       "\n",
       "   mean_squared_error  max_depth  n_estimators          model  alpha  \n",
       "1            0.050180        5.0          50.0  LGBMRegressor    NaN  \n",
       "0            0.050180       10.0          50.0  LGBMRegressor    NaN  \n",
       "3            0.050907       10.0          50.0  LGBMRegressor    NaN  \n",
       "2            0.050907        5.0          50.0  LGBMRegressor    NaN  \n",
       "5            0.056990        5.0          20.0  LGBMRegressor    NaN  \n",
       "4            0.056990       10.0          20.0  LGBMRegressor    NaN  \n",
       "7            0.057542       10.0          20.0  LGBMRegressor    NaN  \n",
       "6            0.057542        5.0          20.0  LGBMRegressor    NaN  \n",
       "0            0.059814        NaN           NaN          Ridge   0.01  \n",
       "1            0.060078        NaN           NaN          Ridge   0.10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models to compare\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "models = [\n",
    "    RandomForestRegressor(random_state=123), \n",
    "    LGBMRegressor(random_state=123, verbose=-1),\n",
    "    Ridge(random_state=123)\n",
    "]\n",
    "\n",
    "# Hyperparameter to search for each model\n",
    "param_grids = {\n",
    "    'RandomForestRegressor': {'n_estimators': [50, 100], 'max_depth': [5, 15]},\n",
    "    'LGBMRegressor': {'n_estimators': [20, 50], 'max_depth': [5, 10]},\n",
    "    'Ridge': {'alpha': [0.01, 0.1, 1]}\n",
    "}\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 3,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "for i, model in enumerate(models):\n",
    "\n",
    "    print(f\"Grid search for regressor: {model}\")\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "    forecaster = ForecasterRecursive(\n",
    "                     regressor = model,\n",
    "                     lags      = 3\n",
    "                 )\n",
    "\n",
    "    # Regressor hyperparameters\n",
    "    param_grid = param_grids[list(param_grids)[i]]\n",
    "\n",
    "    results = grid_search_forecaster(\n",
    "                  forecaster    = forecaster,\n",
    "                  y             = data.loc[:end_val, 'y'],\n",
    "                  param_grid    = param_grid,\n",
    "                  lags_grid     = lags_grid,\n",
    "                  cv            = cv,\n",
    "                  metric        = 'mean_squared_error',\n",
    "                  return_best   = False,\n",
    "                  n_jobs        = 'auto',\n",
    "                  verbose       = False,\n",
    "                  show_progress = True\n",
    "              )\n",
    "    \n",
    "    # Create a column with model name\n",
    "    results['model'] = list(param_grids)[i]\n",
    "    \n",
    "    df_results = pd.concat([df_results, results])\n",
    "\n",
    "df_results = df_results.sort_values(by='mean_squared_error')\n",
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f77c791",
   "metadata": {},
   "source": [
    "## Saving results to file\n",
    "\n",
    "The results of the hyperparameter search process can be saved to a file by setting the `output_file` argument to the desired path. The results will be saved in a tab-separated values (TSV) format containing the hyperparameters, lags, and metrics of each configuration evaluated during the search. \n",
    "\n",
    "The saving process occurs after each hyperparameter evaluation, which means that if the optimization is stopped in the middle of the process, the logs of the first part of the evaluation have already been stored in the file. This can be useful for further analysis or to keep a record of the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7125be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b2b6ed5f8a4b06bb8e39e34ff1530f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908256c06e1a4590ac6e282bfd2c51f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.04387531272712768\n"
     ]
    }
   ],
   "source": [
    "# Save results to file\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              cv            = cv,\n",
    "              metric        = 'mean_squared_error',\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True,\n",
    "              output_file   = \"results_grid_search.txt\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3f34b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               lags                       lags_label  \\\n",
       "0                           [1 2 3]                          [1 2 3]   \n",
       "1                           [1 2 3]                          [1 2 3]   \n",
       "2                           [1 2 3]                          [1 2 3]   \n",
       "3                           [1 2 3]                          [1 2 3]   \n",
       "4                           [1 2 3]                          [1 2 3]   \n",
       "5                           [1 2 3]                          [1 2 3]   \n",
       "6   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "7   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "8   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "9   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "10  [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "11  [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "12                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "13                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "14                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "15                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "16                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "17                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "\n",
       "                                    params  mean_squared_error  max_depth  \\\n",
       "0     {'max_depth': 5, 'n_estimators': 50}            0.045423          5   \n",
       "1    {'max_depth': 5, 'n_estimators': 100}            0.043875          5   \n",
       "2    {'max_depth': 10, 'n_estimators': 50}            0.045423         10   \n",
       "3   {'max_depth': 10, 'n_estimators': 100}            0.043875         10   \n",
       "4    {'max_depth': 15, 'n_estimators': 50}            0.045423         15   \n",
       "5   {'max_depth': 15, 'n_estimators': 100}            0.043875         15   \n",
       "6     {'max_depth': 5, 'n_estimators': 50}            0.051399          5   \n",
       "7    {'max_depth': 5, 'n_estimators': 100}            0.047896          5   \n",
       "8    {'max_depth': 10, 'n_estimators': 50}            0.051399         10   \n",
       "9   {'max_depth': 10, 'n_estimators': 100}            0.047896         10   \n",
       "10   {'max_depth': 15, 'n_estimators': 50}            0.051399         15   \n",
       "11  {'max_depth': 15, 'n_estimators': 100}            0.047896         15   \n",
       "12    {'max_depth': 5, 'n_estimators': 50}            0.046221          5   \n",
       "13   {'max_depth': 5, 'n_estimators': 100}            0.044074          5   \n",
       "14   {'max_depth': 10, 'n_estimators': 50}            0.046221         10   \n",
       "15  {'max_depth': 10, 'n_estimators': 100}            0.044074         10   \n",
       "16   {'max_depth': 15, 'n_estimators': 50}            0.046221         15   \n",
       "17  {'max_depth': 15, 'n_estimators': 100}            0.044074         15   \n",
       "\n",
       "    n_estimators  \n",
       "0             50  \n",
       "1            100  \n",
       "2             50  \n",
       "3            100  \n",
       "4             50  \n",
       "5            100  \n",
       "6             50  \n",
       "7            100  \n",
       "8             50  \n",
       "9            100  \n",
       "10            50  \n",
       "11           100  \n",
       "12            50  \n",
       "13           100  \n",
       "14            50  \n",
       "15           100  \n",
       "16            50  \n",
       "17           100  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read results file\n",
    "# ==============================================================================\n",
    "pd.read_csv(\"results_grid_search.txt\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py11_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
