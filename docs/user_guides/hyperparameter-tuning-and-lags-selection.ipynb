{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8bfe72e",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning and lags selection\n",
    "\n",
    "Hyperparameter tuning is a key step in building accurate and robust machine learning models. Hyperparameters are configuration values that cannot be learned directly from data and must be defined by the user before training. These values can significantly affect model performance, and carefully tuning them helps improve both accuracy and generalization.\n",
    "\n",
    "In forecasting models, the selection of **lags** (past time steps used as predictors) is considered an additional hyperparameter, as it directly influences the model's input structure and learning capacity.\n",
    "\n",
    "Hyperparameter tuning consists of systematically evaluating combinations of hyperparameters (including lags) to find the configuration that yields the best predictive performance. The **skforecast** library supports several tuning strategies: **grid search**, **random search**, and **Bayesian search**. These strategies can be used with either [backtesting](../user_guides/backtesting.html) or [one-step-ahead validation](../user_guides/hyperparameter-tuning-and-lags-selection.html#one-step-ahead-validation) to determine the optimal parameter set for a given forecasting task."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bd6f81b",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4; border-color: #00b8d4; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b style=\"color: #00b8d4;\">&#9998 Note</b>\n",
    "</p>\n",
    "\n",
    "All <b>backtesting</b> and <b>hyperparameter search</b> functions in the <code>model_selection</code> module include the <code>n_jobs</code> argument, enabling <b>multi-process parallelization</b> to improve computational performance.\n",
    "\n",
    "Its effectiveness depends on factors like the regressor type, the number of model fits to perform, and the volume of data. When <code>n_jobs</code> is set to <code>'auto'</code>, the level of parallelization is automatically determined using heuristic rules designed to select the most efficient configuration for each scenario.\n",
    "\n",
    "For more information, see the guide <a href=\"../faq/parallelization-skforecast.html\">Parallelization in skforecast</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a589bf",
   "metadata": {},
   "source": [
    "## Validation strategies\n",
    "\n",
    "Hyperparameter and lag tuning involves systematically testing different values or combinations of hyperparameters (and/or lags) to find the optimal configuration that gives the best performance. The **skforecast** library provides two different methods to evaluate each candidate configuration:\n",
    "\n",
    "+ **Backtesting**: Simulates a real deployment scenario by generating multi-step forecasts in repeated iterations, using the defined forecast horizon and retraining frequency. This approach provides a realistic estimate of performance over time. Use the <code>[TimeSeriesFold](../api/model_selection.html#skforecast.model_selection._split.TimeSeriesFold)</code> class for this validation strategy. [More information](../user_guides/backtesting.html).\n",
    "\n",
    "+ **One-Step-Ahead**: Evaluates model performance using only one-step-ahead forecasts ($t+1$). This method is faster, as it requires fewer iterations, but it only tests the model's performance in the immediate next time step. Use the <code>[OneStepAheadFold](../api/model_selection.html#skforecast.model_selection._split.OneStepAheadFold)</code> class for the one-step-ahead strategy. [More information](../user_guides/hyperparameter-tuning-and-lags-selection.html#one-step-ahead-validation).\n",
    "\n",
    "Although the two methods may produce different results, they tend to converge on similar hyperparameter selections over time. The one-step-ahead method is faster than backtesting because it requires fewer iterations; however, it only tests the model's performance in the next immediate time step. For a more accurate multi-step performance estimate, it is recommended to backtest the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76193903",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4; border-color: #00b8d4; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b style=\"color: #00b8d4;\">&#9998 Note</b>\n",
    "</p>\n",
    "\n",
    "For a more detailed comparison of the results (**execution time** and **metric**) obtained with each strategy, visit <a href=\"../faq/parameters-search-backtesting-vs-one-step-ahead.html\">Hyperparameters and lags search: backtesting vs one-step-ahead</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc006084",
   "metadata": {},
   "source": [
    "## Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902da042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skforecast.datasets import fetch_dataset\n",
    "from skforecast.recursive import ForecasterRecursive\n",
    "from skforecast.plot import set_dark_theme\n",
    "from skforecast.model_selection import (\n",
    "    TimeSeriesFold,\n",
    "    OneStepAheadFold,\n",
    "    grid_search_forecaster,\n",
    "    random_search_forecaster,\n",
    "    bayesian_search_forecaster\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ad54d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭────────────────────────────────────── <span style=\"font-weight: bold\">h2o</span> ───────────────────────────────────────╮\n",
       "│ <span style=\"font-weight: bold\">Description:</span>                                                                     │\n",
       "│ Monthly expenditure ($AUD) on corticosteroid drugs that the Australian health    │\n",
       "│ system had between 1991 and 2008.                                                │\n",
       "│                                                                                  │\n",
       "│ <span style=\"font-weight: bold\">Source:</span>                                                                          │\n",
       "│ Hyndman R (2023). fpp3: Data for Forecasting: Principles and Practice(3rd        │\n",
       "│ Edition). http://pkg.robjhyndman.com/fpp3package/,https://github.com/robjhyndman │\n",
       "│ /fpp3package, http://OTexts.com/fpp3.                                            │\n",
       "│                                                                                  │\n",
       "│ <span style=\"font-weight: bold\">URL:</span>                                                                             │\n",
       "│ https://raw.githubusercontent.com/skforecast/skforecast-                         │\n",
       "│ datasets/main/data/h2o.csv                                                       │\n",
       "│                                                                                  │\n",
       "│ <span style=\"font-weight: bold\">Shape:</span> 204 rows x 2 columns                                                      │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭────────────────────────────────────── \u001b[1mh2o\u001b[0m ───────────────────────────────────────╮\n",
       "│ \u001b[1mDescription:\u001b[0m                                                                     │\n",
       "│ Monthly expenditure ($AUD) on corticosteroid drugs that the Australian health    │\n",
       "│ system had between 1991 and 2008.                                                │\n",
       "│                                                                                  │\n",
       "│ \u001b[1mSource:\u001b[0m                                                                          │\n",
       "│ Hyndman R (2023). fpp3: Data for Forecasting: Principles and Practice(3rd        │\n",
       "│ Edition). http://pkg.robjhyndman.com/fpp3package/,https://github.com/robjhyndman │\n",
       "│ /fpp3package, http://OTexts.com/fpp3.                                            │\n",
       "│                                                                                  │\n",
       "│ \u001b[1mURL:\u001b[0m                                                                             │\n",
       "│ https://raw.githubusercontent.com/skforecast/skforecast-                         │\n",
       "│ datasets/main/data/h2o.csv                                                       │\n",
       "│                                                                                  │\n",
       "│ \u001b[1mShape:\u001b[0m 204 rows x 2 columns                                                      │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-07-01</th>\n",
       "      <td>0.429795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-08-01</th>\n",
       "      <td>0.400906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-09-01</th>\n",
       "      <td>0.432159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   y\n",
       "datetime            \n",
       "1991-07-01  0.429795\n",
       "1991-08-01  0.400906\n",
       "1991-09-01  0.432159"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download data\n",
    "# ==============================================================================\n",
    "data = fetch_dataset(\n",
    "    name=\"h2o\", raw=True, kwargs_read_csv={\"names\": [\"y\", \"datetime\"], \"header\": 0}\n",
    ")\n",
    "\n",
    "# Data preprocessing\n",
    "# ==============================================================================\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data[['y']]\n",
    "data = data.sort_index()\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f18cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates      : 1991-07-01 00:00:00 --- 2001-01-01 00:00:00  (n=115)\n",
      "Validation dates : 2001-02-01 00:00:00 --- 2006-01-01 00:00:00  (n=60)\n",
      "Test dates       : 2006-02-01 00:00:00 --- 2008-06-01 00:00:00 (n=29)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train-val-test dates\n",
    "# ==============================================================================\n",
    "end_train = '2001-01-01 23:59:00'\n",
    "end_val = '2006-01-01 23:59:00'\n",
    "\n",
    "print(\n",
    "    f\"Train dates      : {data.index.min()} --- {data.loc[:end_train].index.max()}\"\n",
    "    f\"  (n={len(data.loc[:end_train])})\"\n",
    ")\n",
    "print(\n",
    "    f\"Validation dates : {data.loc[end_train:].index.min()} --- {data.loc[:end_val].index.max()}\"\n",
    "    f\"  (n={len(data.loc[end_train:end_val])})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates       : {data.loc[end_val:].index.min()} --- {data.index.max()}\"\n",
    "    f\" (n={len(data.loc[end_val:])})\"\n",
    ")\n",
    "print(\"\")\n",
    "\n",
    "# Plot\n",
    "# ==============================================================================\n",
    "set_dark_theme()\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "data.loc[:end_train, 'y'].plot(ax=ax, label='train')\n",
    "data.loc[end_train:end_val, 'y'].plot(ax=ax, label='validation')\n",
    "data.loc[end_val:, 'y'].plot(ax=ax, label='test')\n",
    "ax.legend()\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bfc04a8",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "Grid search is a popular hyperparameter tuning technique that evaluate an exaustive list of combinations of hyperparameters and lags to find the optimal configuration for a forecasting model. To perform a grid search with the **skforecast** library, two grids are needed: one with different lags (`lags_grid`) and another with the hyperparameters (`param_grid`).\n",
    "\n",
    "The grid search process involves the following steps:\n",
    "\n",
    "1. `grid_search_forecaster` replaces the `lags` argument with the first option appearing in `lags_grid`.\n",
    "\n",
    "2. The function validates all combinations of hyperparameters presented in `param_grid` using [backtesting](../user_guides/backtesting.html) or [one-step-ahead validation](../user_guides/hyperparameter-tuning-and-lags-selection.html#one-step-ahead-validation) validation.\n",
    "\n",
    "3. The function repeats these two steps until it has evaluated all possible combinations of lags and hyperparameters.\n",
    "\n",
    "4. If `return_best = True`, the original forecaster is trained with the best lags and hyperparameters configuration found during the grid search process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748732ed",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "When using <b>backtesting</b> as the validation strategy, the computational cost of the tuning largely depends on the strategy used to evaluate each hyperparameter combination. In general, the more re-trainings required, the longer the tuning process will take.\n",
    "\n",
    "To speed up the prototyping phase, a two-step approach is recommended. First, run the search with <code>refit=False</code> to explore a broad range of values quickly. Then, refine the search within the most promising region using a tailored backtesting strategy aligned with the specific needs of the use case.\n",
    "\n",
    "For more guidance, refer to the following resource: <a href=\"../user_guides/backtesting.html#which-strategy-should-i-use\">Which backtesting strategy should I use?</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10187b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1578583c0f49bb8822c3d745f23a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b963fbe4504e988a1be7cb688dcfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.04387531272712768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>lags_1</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>lags_3</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>lags_2</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               lags lags_label  \\\n",
       "0                         [1, 2, 3]     lags_1   \n",
       "1                         [1, 2, 3]     lags_1   \n",
       "2                         [1, 2, 3]     lags_1   \n",
       "3                     [1, 2, 3, 20]     lags_3   \n",
       "4                     [1, 2, 3, 20]     lags_3   \n",
       "5                     [1, 2, 3, 20]     lags_3   \n",
       "6                         [1, 2, 3]     lags_1   \n",
       "7                         [1, 2, 3]     lags_1   \n",
       "8                         [1, 2, 3]     lags_1   \n",
       "9                     [1, 2, 3, 20]     lags_3   \n",
       "10                    [1, 2, 3, 20]     lags_3   \n",
       "11                    [1, 2, 3, 20]     lags_3   \n",
       "12  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "13  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "14  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "15  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "16  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "17  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]     lags_2   \n",
       "\n",
       "                                    params  mean_squared_error  max_depth  \\\n",
       "0    {'max_depth': 5, 'n_estimators': 100}            0.043875          5   \n",
       "1   {'max_depth': 10, 'n_estimators': 100}            0.043875         10   \n",
       "2   {'max_depth': 15, 'n_estimators': 100}            0.043875         15   \n",
       "3   {'max_depth': 10, 'n_estimators': 100}            0.044074         10   \n",
       "4    {'max_depth': 5, 'n_estimators': 100}            0.044074          5   \n",
       "5   {'max_depth': 15, 'n_estimators': 100}            0.044074         15   \n",
       "6    {'max_depth': 10, 'n_estimators': 50}            0.045423         10   \n",
       "7    {'max_depth': 15, 'n_estimators': 50}            0.045423         15   \n",
       "8     {'max_depth': 5, 'n_estimators': 50}            0.045423          5   \n",
       "9    {'max_depth': 10, 'n_estimators': 50}            0.046221         10   \n",
       "10   {'max_depth': 15, 'n_estimators': 50}            0.046221         15   \n",
       "11    {'max_depth': 5, 'n_estimators': 50}            0.046221          5   \n",
       "12  {'max_depth': 10, 'n_estimators': 100}            0.047896         10   \n",
       "13   {'max_depth': 5, 'n_estimators': 100}            0.047896          5   \n",
       "14  {'max_depth': 15, 'n_estimators': 100}            0.047896         15   \n",
       "15    {'max_depth': 5, 'n_estimators': 50}            0.051399          5   \n",
       "16   {'max_depth': 10, 'n_estimators': 50}            0.051399         10   \n",
       "17   {'max_depth': 15, 'n_estimators': 50}            0.051399         15   \n",
       "\n",
       "    n_estimators  \n",
       "0            100  \n",
       "1            100  \n",
       "2            100  \n",
       "3            100  \n",
       "4            100  \n",
       "5            100  \n",
       "6             50  \n",
       "7             50  \n",
       "8             50  \n",
       "9             50  \n",
       "10            50  \n",
       "11            50  \n",
       "12           100  \n",
       "13           100  \n",
       "14           100  \n",
       "15            50  \n",
       "16            50  \n",
       "17            50  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = {\n",
    "    'lags_1': 3,\n",
    "    'lags_2': 10,\n",
    "    'lags_3': [1, 2, 3, 20]\n",
    "}\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = '2001-01-01 23:59:00',  # Same as len(data.loc[:end_train])\n",
    "         refit              = False\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              cv            = cv,\n",
    "              metric        = 'mean_squared_error',\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True\n",
    "          )\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2b2f2e0",
   "metadata": {},
   "source": [
    "Since `return_best = True`, the forecaster object is updated with the best configuration found and trained with the whole data set. This means that the final model obtained from grid search will have the best combination of lags and hyperparameters that resulted in the highest performance metric. This final model can then be used for future predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a718228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 {\n",
       "            font-family: 'Arial', sans-serif;\n",
       "            font-size: 0.9em;\n",
       "            color: #333333;\n",
       "            border: 1px solid #ddd;\n",
       "            background-color: #f0f8ff;\n",
       "            padding: 5px 15px;\n",
       "            border-radius: 8px;\n",
       "            max-width: 600px;\n",
       "            #margin: auto;\n",
       "        }\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 h2 {\n",
       "            font-size: 1.5em;\n",
       "            color: #222222;\n",
       "            border-bottom: 2px solid #ddd;\n",
       "            padding-bottom: 5px;\n",
       "            margin-bottom: 15px;\n",
       "            margin-top: 5px;\n",
       "        }\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 details {\n",
       "            margin: 10px 0;\n",
       "        }\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 summary {\n",
       "            font-weight: bold;\n",
       "            font-size: 1.1em;\n",
       "            color: #000000;\n",
       "            cursor: pointer;\n",
       "            margin-bottom: 5px;\n",
       "            background-color: #b3dbfd;\n",
       "            padding: 5px;\n",
       "            border-radius: 5px;\n",
       "        }\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 summary:hover {\n",
       "            color: #000000;\n",
       "            background-color: #e0e0e0;\n",
       "        }\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 ul {\n",
       "            font-family: 'Courier New', monospace;\n",
       "            list-style-type: none;\n",
       "            padding-left: 20px;\n",
       "            margin: 10px 0;\n",
       "            line-height: normal;\n",
       "        }\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 li {\n",
       "            margin: 5px 0;\n",
       "            font-family: 'Courier New', monospace;\n",
       "        }\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 li strong {\n",
       "            font-weight: bold;\n",
       "            color: #444444;\n",
       "        }\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 li::before {\n",
       "            content: \"- \";\n",
       "            color: #666666;\n",
       "        }\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 a {\n",
       "            color: #001633;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "        .container-89736af1a87d4feb8247d05a3fb04d64 a:hover {\n",
       "            color: #359ccb; \n",
       "        }\n",
       "    </style>\n",
       "    \n",
       "        <div class=\"container-89736af1a87d4feb8247d05a3fb04d64\">\n",
       "            <p style=\"font-size: 1.5em; font-weight: bold; margin-block-start: 0.83em; margin-block-end: 0.83em;\">ForecasterRecursive</p>\n",
       "            <details open>\n",
       "                <summary>General Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Regressor:</strong> LGBMRegressor</li>\n",
       "                    <li><strong>Lags:</strong> [1 2 3]</li>\n",
       "                    <li><strong>Window features:</strong> None</li>\n",
       "                    <li><strong>Window size:</strong> 3</li>\n",
       "                    <li><strong>Series name:</strong> y</li>\n",
       "                    <li><strong>Exogenous included:</strong> False</li>\n",
       "                    <li><strong>Weight function included:</strong> False</li>\n",
       "                    <li><strong>Differentiation order:</strong> None</li>\n",
       "                    <li><strong>Creation date:</strong> 2025-11-25 09:43:40</li>\n",
       "                    <li><strong>Last fit date:</strong> 2025-11-25 09:43:41</li>\n",
       "                    <li><strong>Skforecast version:</strong> 0.19.0</li>\n",
       "                    <li><strong>Python version:</strong> 3.13.9</li>\n",
       "                    <li><strong>Forecaster id:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Exogenous Variables</summary>\n",
       "                <ul>\n",
       "                    None\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Data Transformations</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Transformer for y:</strong> None</li>\n",
       "                    <li><strong>Transformer for exog:</strong> None</li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Training Information</summary>\n",
       "                <ul>\n",
       "                    <li><strong>Training range:</strong> [Timestamp('1991-07-01 00:00:00'), Timestamp('2006-01-01 00:00:00')]</li>\n",
       "                    <li><strong>Training index type:</strong> DatetimeIndex</li>\n",
       "                    <li><strong>Training index frequency:</strong> <MonthBegin></li>\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Regressor Parameters</summary>\n",
       "                <ul>\n",
       "                    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 5, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <details>\n",
       "                <summary>Fit Kwargs</summary>\n",
       "                <ul>\n",
       "                    {}\n",
       "                </ul>\n",
       "            </details>\n",
       "            <p>\n",
       "                <a href=\"https://skforecast.org/0.19.0/api/forecasterrecursive.html\">&#128712 <strong>API Reference</strong></a>\n",
       "                &nbsp;&nbsp;\n",
       "                <a href=\"https://skforecast.org/0.19.0/user_guides/autoregressive-forecaster.html\">&#128462 <strong>User Guide</strong></a>\n",
       "            </p>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "=================== \n",
       "ForecasterRecursive \n",
       "=================== \n",
       "Regressor: LGBMRegressor \n",
       "Lags: [1 2 3] \n",
       "Window features: None \n",
       "Window size: 3 \n",
       "Series name: y \n",
       "Exogenous included: False \n",
       "Exogenous names: None \n",
       "Transformer for y: None \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Differentiation order: None \n",
       "Training range: [Timestamp('1991-07-01 00:00:00'), Timestamp('2006-01-01 00:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: <MonthBegin> \n",
       "Regressor parameters: \n",
       "    {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0,\n",
       "    'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': 5,\n",
       "    'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0,\n",
       "    'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None,\n",
       "    'random_state': 123, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0,\n",
       "    'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': -1} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2025-11-25 09:43:40 \n",
       "Last fit date: 2025-11-25 09:43:41 \n",
       "Skforecast version: 0.19.0 \n",
       "Python version: 3.13.9 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ab71330",
   "metadata": {},
   "source": [
    "## Random search\n",
    "\n",
    "Random search is another hyperparameter tuning strategy available in the **skforecast** library. In contrast to grid search, which tries out all possible combinations of hyperparameters and lags, randomized search samples a fixed number of values from the specified possibilities. The number of combinations that are evaluated is given by `n_iter`.\n",
    "\n",
    "It is important to note that random sampling is only applied to the model hyperparameters, but not to the lags. All lags specified by the user are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395d1e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265a0ac07991402687235f1631df49aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8241f526508241b19a58bae896dc4016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3 4 5] \n",
      "  Parameters: {'n_estimators': np.int64(96), 'max_depth': np.int64(19)}\n",
      "  Backtesting metric: 0.04313147793349785\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 96, 'max_depth': 19}</td>\n",
       "      <td>0.043131</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 94, 'max_depth': 28}</td>\n",
       "      <td>0.043171</td>\n",
       "      <td>94</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 77, 'max_depth': 17}</td>\n",
       "      <td>0.043663</td>\n",
       "      <td>77</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 96, 'max_depth': 19}</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>96</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags       lags_label                                 params  \\\n",
       "0  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'n_estimators': 96, 'max_depth': 19}   \n",
       "1  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'n_estimators': 94, 'max_depth': 28}   \n",
       "2  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'n_estimators': 77, 'max_depth': 17}   \n",
       "3        [1, 2, 3]        [1, 2, 3]  {'n_estimators': 96, 'max_depth': 19}   \n",
       "\n",
       "   mean_squared_error  n_estimators  max_depth  \n",
       "0            0.043131            96         19  \n",
       "1            0.043171            94         28  \n",
       "2            0.043663            77         17  \n",
       "3            0.043868            96         19  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search hyperparameters and lags\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_distributions = {\n",
    "    'n_estimators': np.arange(start=10, stop=100, step=1, dtype=int),\n",
    "    'max_depth': np.arange(start=5, stop=30, step=1, dtype=int)\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results = random_search_forecaster(\n",
    "              forecaster          = forecaster,\n",
    "              y                   = data.loc[:end_val, 'y'],\n",
    "              lags_grid           = lags_grid,\n",
    "              param_distributions = param_distributions,\n",
    "              cv                  = cv,\n",
    "              n_iter              = 5,\n",
    "              metric              = 'mean_squared_error',\n",
    "              return_best         = True,\n",
    "              random_state        = 123,\n",
    "              n_jobs              = 'auto',\n",
    "              verbose             = False,\n",
    "              show_progress       = True\n",
    "          )\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df764b2d",
   "metadata": {},
   "source": [
    "## Bayesian search\n",
    "\n",
    "Grid and random search can yield good results, especially when the search space is well-defined. However, these methods do not consider past results, which limits their ability to focus on the most promising regions and avoid uninformative ones.\n",
    "\n",
    "A more efficient alternative is **Bayesian optimization**, which builds a probabilistic model of the objective function, typically the validation metric (e.g. RMSE, AUC, accuracy). Based on the results observed so far, the algorithm iteratively refines the search, concentrating on regions with the highest potential. This approach reduces the number of evaluations needed by prioritizing the most relevant hyperparameter combinations. It is especially useful when the search space is large or model training is computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8011b4d",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(255,145,0,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #ff9100; border-color: #ff9100; padding-left: 10px; padding-right: 10px\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#ff9100; border-color: #ff1744;\"></i>\n",
    "    <b style=\"color: #ff9100;\"> <span style=\"color: #ff9100;\">&#9888;</span> Warning</b>\n",
    "</p>\n",
    "\n",
    "The <code>lags_grid</code> argument is not required when using <code>bayesian_search_forecaster</code>. Instead, the <code>lags</code> can be included directly in the <code>search_space</code>, allowing them to be optimized jointly with the other regressor hyperparameters during the search.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40bdbc55",
   "metadata": {},
   "source": [
    "In **skforecast**, Bayesian optimization is implemented using **Optuna** and its [`Study object`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study). The goal of the optimization is to **minimize the metric** returned by the validation strategy (either backtesting or one-step-ahead).\n",
    "\n",
    "You can customize the optimization process by passing additional arguments through the `kwargs_create_study` and `kwargs_study_optimize` parameters. These are forwarded to Optuna’s [`create_study`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.create_study.html) and [`optimize method`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study.optimize), respectively.\n",
    "\n",
    "To define the **hyperparameter search space**, the `search_space` argument must be a function that takes an Optuna [Trial object](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial) and returns a dictionary of parameters to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c762a37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fedf2f68d3e473c8eb2b0785dd8f882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 19, 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.126995</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 15, 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.153278</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 13, 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.160396</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 5, 'm...</td>\n",
       "      <td>0.172366</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags                                             params  \\\n",
       "0  [1, 2, 3, 4, 5]  {'n_estimators': 19, 'min_samples_leaf': 3, 'm...   \n",
       "1        [1, 2, 3]  {'n_estimators': 15, 'min_samples_leaf': 4, 'm...   \n",
       "2        [1, 2, 3]  {'n_estimators': 13, 'min_samples_leaf': 3, 'm...   \n",
       "3  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 5, 'm...   \n",
       "\n",
       "   mean_absolute_error  n_estimators  min_samples_leaf max_features  \n",
       "0             0.126995            19                 3         sqrt  \n",
       "1             0.153278            15                 4         sqrt  \n",
       "2             0.160396            13                 3         sqrt  \n",
       "3             0.172366            14                 5         log2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search hyperparameters and lags with Optuna\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "\n",
    "# Search space\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'lags'            : trial.suggest_categorical('lags', [3, 5]),\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),  # Can use a date: '2001-01-01 23:59:00'\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data.loc[:end_val, 'y'],\n",
    "                          search_space          = search_space,\n",
    "                          cv                    = cv,\n",
    "                          metric                = 'mean_absolute_error',\n",
    "                          n_trials              = 10,\n",
    "                          random_state          = 123,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True,\n",
    "                          kwargs_create_study   = {},\n",
    "                          kwargs_study_optimize = {}\n",
    "                      )\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0a970a3",
   "metadata": {},
   "source": [
    "The `best_trial` return contains the details of the trial that achieved the best result during optimization. For more information, refer to the [Study class](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.study.Study.html#optuna.study.Study)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "400b4ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=7, state=1, values=[0.1269945910624239], datetime_start=datetime.datetime(2025, 11, 25, 9, 43, 42, 723265), datetime_complete=datetime.datetime(2025, 11, 25, 9, 43, 42, 776078), params={'lags': 5, 'n_estimators': 19, 'min_samples_leaf': 3, 'max_features': 'sqrt'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'lags': CategoricalDistribution(choices=(3, 5)), 'n_estimators': IntDistribution(high=20, log=False, low=10, step=1), 'min_samples_leaf': IntDistribution(high=10, log=False, low=1, step=1), 'max_features': CategoricalDistribution(choices=('log2', 'sqrt'))}, trial_id=7, value=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optuna best trial in the study\n",
    "# ==============================================================================\n",
    "best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ee978",
   "metadata": {},
   "source": [
    "## One-step-ahead validation\n",
    "\n",
    "**One-Step-Ahead** evaluates model performance using only one-step-ahead forecasts ($t+1$). This method is faster, as it requires fewer iterations, but it only tests the model's performance in the immediate next time step. Use the <code>[OneStepAheadFold](../api/model_selection.html#skforecast.model_selection._split.OneStepAheadFold)</code> class for the one-step-ahead strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2237c2bf",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "For a more detailed comparison of the results (**execution time** and **metric**) obtained with each strategy, visit <a href=\"../faq/parameters-search-backtesting-vs-one-step-ahead.html\">Hyperparameters and lags search: backtesting vs one-step-ahead</a>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac3cb60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcbc199af074fb4b062e1ba5b052707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 20, 'min_samples_leaf': 6, 'm...</td>\n",
       "      <td>0.180137</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 5, 'm...</td>\n",
       "      <td>0.180815</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'n_estimators': 16, 'min_samples_leaf': 9, 'm...</td>\n",
       "      <td>0.187584</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'n_estimators': 14, 'min_samples_leaf': 7, 'm...</td>\n",
       "      <td>0.188359</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>log2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags                                             params  \\\n",
       "0  [1, 2, 3, 4, 5]  {'n_estimators': 20, 'min_samples_leaf': 6, 'm...   \n",
       "1  [1, 2, 3, 4, 5]  {'n_estimators': 14, 'min_samples_leaf': 5, 'm...   \n",
       "2  [1, 2, 3, 4, 5]  {'n_estimators': 16, 'min_samples_leaf': 9, 'm...   \n",
       "3        [1, 2, 3]  {'n_estimators': 14, 'min_samples_leaf': 7, 'm...   \n",
       "\n",
       "   mean_absolute_error  n_estimators  min_samples_leaf max_features  \n",
       "0             0.180137            20                 6         log2  \n",
       "1             0.180815            14                 5         log2  \n",
       "2             0.187584            16                 9         log2  \n",
       "3             0.188359            14                 7         log2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian search with OneStepAheadFold\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "\n",
    "# Search space\n",
    "def search_space(trial):\n",
    "    search_space  = {\n",
    "        'lags'            : trial.suggest_categorical('lags', [3, 5]),\n",
    "        'n_estimators'    : trial.suggest_int('n_estimators', 10, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features'    : trial.suggest_categorical('max_features', ['log2', 'sqrt'])\n",
    "    }\n",
    "    \n",
    "    return search_space\n",
    "\n",
    "\n",
    "# Folds\n",
    "cv = OneStepAheadFold(\n",
    "    initial_train_size = len(data.loc[:end_train])  # Can use a date: '2001-01-01 23:59:00'\n",
    ")\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster(\n",
    "                          forecaster            = forecaster,\n",
    "                          y                     = data.loc[:end_val, 'y'],\n",
    "                          search_space          = search_space,\n",
    "                          cv                    = cv,\n",
    "                          metric                = 'mean_absolute_error',\n",
    "                          n_trials              = 10,\n",
    "                          random_state          = 123,\n",
    "                          return_best           = False,\n",
    "                          n_jobs                = 'auto',\n",
    "                          verbose               = False,\n",
    "                          show_progress         = True,\n",
    "                          kwargs_create_study   = {},\n",
    "                          kwargs_study_optimize = {}\n",
    "                      )\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8279bda4",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with custom metric\n",
    "\n",
    "In addition to standard metrics such as `mean_squared_error` or `mean_absolute_error`, users can define **custom metric functions**, provided they accept the arguments `y_true` (true values), `y_pred` (predicted values) and optionally `y_train` (train values), and return a numeric value (`float` or `int`).\n",
    "\n",
    "This flexibility allows evaluating model performance under specific conditions, for example, focusing only on certain months, days, non-holiday periods, or the last step of the forecast horizon.\n",
    "\n",
    "To illustrate this, consider a scenario where a 12-month forecast is generated, but only the last three months of each year are relevant for evaluation. This can be handled by defining a custom metric function that filters the desired months before computing the error, and then passing that function to the backtesting or hyperparameter tuning process.\n",
    "\n",
    "The example below shows how to optimize model parameters using a custom metric focused on the last three months of each forecasted year.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf534ac",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "More information about <b>time series forecasting metrics</b> can be found in the <a href=\"../user_guides/metrics.html\">Metrics</a> guide.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c7b0fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric\n",
    "# ==============================================================================\n",
    "def custom_metric(y_true, y_pred, y_train=None):\n",
    "    \"\"\"\n",
    "    Calculate the mean squared error using only the predicted values of the last\n",
    "    3 months of the year.\n",
    "    \"\"\"\n",
    "    mask = y_true.index.month.isin([10, 11, 12])\n",
    "    metric = mean_squared_error(y_true[mask], y_pred[mask])\n",
    "    \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "251660d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e8ace60c0c4af088fa953f86ed1e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57fda3e92984b399603c933bd6f37a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3 20] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.0681822427249296\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>custom_metric</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lags     lags_label                                  params  \\\n",
       "0  [1, 2, 3, 20]  [1, 2, 3, 20]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "1  [1, 2, 3, 20]  [1, 2, 3, 20]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "2  [1, 2, 3, 20]  [1, 2, 3, 20]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "3      [1, 2, 3]      [1, 2, 3]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "\n",
       "   custom_metric  max_depth  n_estimators  \n",
       "0       0.068182          5           100  \n",
       "1       0.068182         10           100  \n",
       "2       0.068182         15           100  \n",
       "3       0.070472          5           100  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameter and lags with custom metric\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              cv            = cv,\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              metric        = custom_metric,\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True\n",
    "          )\n",
    "\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f185ba5",
   "metadata": {},
   "source": [
    "## Compare multiple metrics\n",
    "\n",
    "The functions `grid_search_forecaster`, `random_search_forecaster`, and `bayesian_search_forecaster` support the evaluation of **multiple metrics** for each forecaster configuration by passing a `list` of metric functions. This list can include both built-in metrics (e.g. `mean_squared_error`, `mean_absolute_error`) and custom-defined ones.\n",
    "\n",
    "When multiple metrics are provided, the **first metric in the list** is used to select the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53bd6f4",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,191,191,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00bfa5; border-color: #00bfa5; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00bfa5;\"></i>\n",
    "    <b style=\"color: #00bfa5;\">&#128161 Tip</b>\n",
    "</p>\n",
    "\n",
    "More information about <b>time series forecasting metrics</b> can be found in the <a href=\"../user_guides/metrics.html\">Metrics</a> guide.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d58707a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc71afcff5d4883b4579b76a01a3cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f45d9b06a448d8be6382e0be995f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.18359367014650177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>custom_metric</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.070472</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>[1, 2, 3, 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.184901</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lags     lags_label                                  params  \\\n",
       "0      [1, 2, 3]      [1, 2, 3]   {'max_depth': 5, 'n_estimators': 100}   \n",
       "1      [1, 2, 3]      [1, 2, 3]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "2      [1, 2, 3]      [1, 2, 3]  {'max_depth': 15, 'n_estimators': 100}   \n",
       "3  [1, 2, 3, 20]  [1, 2, 3, 20]  {'max_depth': 10, 'n_estimators': 100}   \n",
       "\n",
       "   mean_absolute_error  mean_squared_error  custom_metric  max_depth  \\\n",
       "0             0.183594            0.043875       0.070472          5   \n",
       "1             0.183594            0.043875       0.070472         10   \n",
       "2             0.183594            0.043875       0.070472         15   \n",
       "3             0.184901            0.044074       0.068182         10   \n",
       "\n",
       "   n_estimators  \n",
       "0           100  \n",
       "1           100  \n",
       "2           100  \n",
       "3           100  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search hyperparameter and lags with multiple metrics\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              cv            = cv,\n",
    "              metric        = ['mean_absolute_error', mean_squared_error, custom_metric],\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True\n",
    "          )\n",
    "\n",
    "results.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d21a6eba",
   "metadata": {},
   "source": [
    "## Compare multiple regressors\n",
    "\n",
    "The search process can be easily extended to compare several machine learning models. This can be achieved by using a simple for loop that iterates over each regressor and applying the desired function (for example, `grid_search_forecaster`). This approach allows for a more thorough exploration and can help you select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edf210dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: RandomForestRegressor(random_state=123)\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615795af3f5d46e18e41537080bd979b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3465ad8e28e41dd8739365ad7261ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: LGBMRegressor(random_state=123, verbose=-1)\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671374510a2f4e288f6771464f813c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5075a0266b46398e56aa2f8e6778ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search for regressor: Ridge(random_state=123)\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d2fc1b8fd84c7bb8f0308603313aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4682d5bb71c843d0a3f77524b199f7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>model</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.050180</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.050180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.050907</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.050907</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 20}</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.056990</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.057542</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 20}</td>\n",
       "      <td>0.057542</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.060078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lags       lags_label                                 params  \\\n",
       "1  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]   {'max_depth': 5, 'n_estimators': 50}   \n",
       "0  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'max_depth': 10, 'n_estimators': 50}   \n",
       "3        [1, 2, 3]        [1, 2, 3]  {'max_depth': 10, 'n_estimators': 50}   \n",
       "2        [1, 2, 3]        [1, 2, 3]   {'max_depth': 5, 'n_estimators': 50}   \n",
       "5        [1, 2, 3]        [1, 2, 3]   {'max_depth': 5, 'n_estimators': 20}   \n",
       "4        [1, 2, 3]        [1, 2, 3]  {'max_depth': 10, 'n_estimators': 20}   \n",
       "7  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]  {'max_depth': 10, 'n_estimators': 20}   \n",
       "6  [1, 2, 3, 4, 5]  [1, 2, 3, 4, 5]   {'max_depth': 5, 'n_estimators': 20}   \n",
       "0        [1, 2, 3]        [1, 2, 3]                        {'alpha': 0.01}   \n",
       "1        [1, 2, 3]        [1, 2, 3]                         {'alpha': 0.1}   \n",
       "\n",
       "   mean_squared_error  max_depth  n_estimators          model  alpha  \n",
       "1            0.050180        5.0          50.0  LGBMRegressor    NaN  \n",
       "0            0.050180       10.0          50.0  LGBMRegressor    NaN  \n",
       "3            0.050907       10.0          50.0  LGBMRegressor    NaN  \n",
       "2            0.050907        5.0          50.0  LGBMRegressor    NaN  \n",
       "5            0.056990        5.0          20.0  LGBMRegressor    NaN  \n",
       "4            0.056990       10.0          20.0  LGBMRegressor    NaN  \n",
       "7            0.057542       10.0          20.0  LGBMRegressor    NaN  \n",
       "6            0.057542        5.0          20.0  LGBMRegressor    NaN  \n",
       "0            0.059814        NaN           NaN          Ridge   0.01  \n",
       "1            0.060078        NaN           NaN          Ridge   0.10  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models to compare\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "models = [\n",
    "    RandomForestRegressor(random_state=123), \n",
    "    LGBMRegressor(random_state=123, verbose=-1),\n",
    "    Ridge(random_state=123)\n",
    "]\n",
    "\n",
    "# Hyperparameter to search for each model\n",
    "param_grids = {\n",
    "    'RandomForestRegressor': {'n_estimators': [50, 100], 'max_depth': [5, 15]},\n",
    "    'LGBMRegressor': {'n_estimators': [20, 50], 'max_depth': [5, 10]},\n",
    "    'Ridge': {'alpha': [0.01, 0.1, 1]}\n",
    "}\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 5]\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 3,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False,\n",
    "     )\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "for i, model in enumerate(models):\n",
    "\n",
    "    print(f\"Grid search for regressor: {model}\")\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "    forecaster = ForecasterRecursive(\n",
    "                     regressor = model,\n",
    "                     lags      = 3\n",
    "                 )\n",
    "\n",
    "    # Regressor hyperparameters\n",
    "    param_grid = param_grids[list(param_grids)[i]]\n",
    "\n",
    "    results = grid_search_forecaster(\n",
    "                  forecaster    = forecaster,\n",
    "                  y             = data.loc[:end_val, 'y'],\n",
    "                  param_grid    = param_grid,\n",
    "                  lags_grid     = lags_grid,\n",
    "                  cv            = cv,\n",
    "                  metric        = 'mean_squared_error',\n",
    "                  return_best   = False,\n",
    "                  n_jobs        = 'auto',\n",
    "                  verbose       = False,\n",
    "                  show_progress = True\n",
    "              )\n",
    "    \n",
    "    # Create a column with model name\n",
    "    results['model'] = list(param_grids)[i]\n",
    "    \n",
    "    df_results = pd.concat([df_results, results])\n",
    "\n",
    "df_results = df_results.sort_values(by='mean_squared_error')\n",
    "df_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f77c791",
   "metadata": {},
   "source": [
    "## Saving results to file\n",
    "\n",
    "The results of the hyperparameter search process can be saved to a file by setting the `output_file` argument to the desired path. The results will be saved in a tab-separated values (TSV) format containing the hyperparameters, lags, and metrics of each configuration evaluated during the search. \n",
    "\n",
    "The saving process occurs after each hyperparameter evaluation, which means that if the optimization is stopped in the middle of the process, the logs of the first part of the evaluation have already been stored in the file. This can be useful for further analysis or to keep a record of the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7125be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ff61a9f3624d44a7e2aef4d67e2efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lags grid:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95148b8787143ce82d54d5a5181e048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params grid:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [1 2 3] \n",
      "  Parameters: {'max_depth': 5, 'n_estimators': 100}\n",
      "  Backtesting metric: 0.04387531272712768\n"
     ]
    }
   ],
   "source": [
    "# Save results to file\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(random_state=123, verbose=-1),\n",
    "                 lags      = 10  # Placeholder, the value will be overwritten\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3, 10, [1, 2, 3, 20]]\n",
    "\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Folds\n",
    "cv = TimeSeriesFold(\n",
    "         steps              = 12,\n",
    "         initial_train_size = len(data.loc[:end_train]),\n",
    "         refit              = False\n",
    "     )\n",
    "\n",
    "results = grid_search_forecaster(\n",
    "              forecaster    = forecaster,\n",
    "              y             = data.loc[:end_val, 'y'],\n",
    "              param_grid    = param_grid,\n",
    "              lags_grid     = lags_grid,\n",
    "              cv            = cv,\n",
    "              metric        = 'mean_squared_error',\n",
    "              return_best   = True,\n",
    "              n_jobs        = 'auto',\n",
    "              verbose       = False,\n",
    "              show_progress = True,\n",
    "              output_file   = \"results_grid_search.txt\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f34b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>lags_label</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>[1 2 3]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.051399</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.047896</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 50}</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>[ 1  2  3 20]</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 100}</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               lags                       lags_label  \\\n",
       "0                           [1 2 3]                          [1 2 3]   \n",
       "1                           [1 2 3]                          [1 2 3]   \n",
       "2                           [1 2 3]                          [1 2 3]   \n",
       "3                           [1 2 3]                          [1 2 3]   \n",
       "4                           [1 2 3]                          [1 2 3]   \n",
       "5                           [1 2 3]                          [1 2 3]   \n",
       "6   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "7   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "8   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "9   [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "10  [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "11  [ 1  2  3  4  5  6  7  8  9 10]  [ 1  2  3  4  5  6  7  8  9 10]   \n",
       "12                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "13                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "14                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "15                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "16                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "17                    [ 1  2  3 20]                    [ 1  2  3 20]   \n",
       "\n",
       "                                    params  mean_squared_error  max_depth  \\\n",
       "0     {'max_depth': 5, 'n_estimators': 50}            0.045423          5   \n",
       "1    {'max_depth': 5, 'n_estimators': 100}            0.043875          5   \n",
       "2    {'max_depth': 10, 'n_estimators': 50}            0.045423         10   \n",
       "3   {'max_depth': 10, 'n_estimators': 100}            0.043875         10   \n",
       "4    {'max_depth': 15, 'n_estimators': 50}            0.045423         15   \n",
       "5   {'max_depth': 15, 'n_estimators': 100}            0.043875         15   \n",
       "6     {'max_depth': 5, 'n_estimators': 50}            0.051399          5   \n",
       "7    {'max_depth': 5, 'n_estimators': 100}            0.047896          5   \n",
       "8    {'max_depth': 10, 'n_estimators': 50}            0.051399         10   \n",
       "9   {'max_depth': 10, 'n_estimators': 100}            0.047896         10   \n",
       "10   {'max_depth': 15, 'n_estimators': 50}            0.051399         15   \n",
       "11  {'max_depth': 15, 'n_estimators': 100}            0.047896         15   \n",
       "12    {'max_depth': 5, 'n_estimators': 50}            0.046221          5   \n",
       "13   {'max_depth': 5, 'n_estimators': 100}            0.044074          5   \n",
       "14   {'max_depth': 10, 'n_estimators': 50}            0.046221         10   \n",
       "15  {'max_depth': 10, 'n_estimators': 100}            0.044074         10   \n",
       "16   {'max_depth': 15, 'n_estimators': 50}            0.046221         15   \n",
       "17  {'max_depth': 15, 'n_estimators': 100}            0.044074         15   \n",
       "\n",
       "    n_estimators  \n",
       "0             50  \n",
       "1            100  \n",
       "2             50  \n",
       "3            100  \n",
       "4             50  \n",
       "5            100  \n",
       "6             50  \n",
       "7            100  \n",
       "8             50  \n",
       "9            100  \n",
       "10            50  \n",
       "11           100  \n",
       "12            50  \n",
       "13           100  \n",
       "14            50  \n",
       "15           100  \n",
       "16            50  \n",
       "17           100  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read results file\n",
    "# ==============================================================================\n",
    "pd.read_csv(\"results_grid_search.txt\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_19_py13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
