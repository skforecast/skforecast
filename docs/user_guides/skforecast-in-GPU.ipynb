{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5148957",
   "metadata": {},
   "source": [
    "# Skforecast in GPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ce2a3d8",
   "metadata": {},
   "source": [
    "Traditionally, machine learning algorithms have been executed on CPUs (Central Processing Units)—general-purpose processors capable of handling a wide variety of tasks. However, CPUs are not optimized for the highly parallelized matrix operations that many machine learning algorithms rely on, often resulting in slower training times and limited scalability. In contrast, GPUs (Graphics Processing Units) are specifically designed for parallel processing, capable of performing thousands of simultaneous mathematical operations. This makes them particularly well-suited for training and deploying large-scale machine learning models.\n",
    "\n",
    "Several popular machine learning libraries have implemented GPU acceleration, including **XGBoost**, **LightGBM**, **CatBoost** and **CuML**. By leveraging GPU capabilities, these libraries can dramatically reduce training times and enhance scalability.\n",
    "\n",
    "Despite the significant advantages offered by GPUs (specifically Nvidia GPUs) in accelerating machine learning computations, access to them is often limited due to high costs or other practical constraints. Fortunatelly, **Google Colaboratory (Colab)**, a free Jupyter notebook environment, allows users to run Python code in the cloud, with access to powerful hardware resources such as GPUs. This makes it an excellent platform for experimenting with machine learning models, especially those that require intensive computations.\n",
    "\n",
    "The following sections demonstrate how execute **skforecast** with GPU acceleration to build efficient and powerful forecasting models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b9fd63a",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\" name=\"html-admonition\" style=\"background: rgba(0,184,212,.1); padding-top: 0px; padding-bottom: 6px; border-radius: 8px; border-left: 8px solid #00b8d4; border-color: #00b8d4; padding-left: 10px; padding-right: 10px;\">\n",
    "\n",
    "<p class=\"title\">\n",
    "    <i style=\"font-size: 18px; color:#00b8d4;\"></i>\n",
    "    <b style=\"color: #00b8d4;\">&#9998 Note</b>\n",
    "</p>\n",
    "\n",
    "<p>The following code assumes that the user is executing it in Google Colab with an activated GPU runtime.</p>\n",
    "<ul>\n",
    "    <li><a href=\"https://colab.research.google.com/drive/10PYQFQN9oNkAHh0X7wwyBLQ3JQ_Cm7pP?usp=sharing\">Skforecast in GPU: XGBoost</a></li>\n",
    "    <li><a href=\"https://colab.research.google.com/drive/17Csc70AY-GQA-tvZjq9TYCbmnrNOzslh?usp=sharing\">Skforecast in GPU: LightGBM</a></li>\n",
    "    <li><a href=\"https://colab.research.google.com/drive/1Z-n0kKEnQvY02e9-HxKbkTdLc10RNd_-?usp=sharing\">Skforecast in GPU: CatBoost</a></li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece7fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skforecast version: 0.15.1\n",
      "xgboost version: 2.1.2\n",
      "lightgbm version: 4.5.0\n",
      "catboost version: 1.2.8\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import psutil\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost\n",
    "from catboost import CatBoostRegressor\n",
    "import warnings\n",
    "\n",
    "import skforecast\n",
    "from skforecast.recursive import ForecasterRecursive\n",
    "from skforecast.direct import ForecasterDirect\n",
    "from skforecast.model_selection import backtesting_forecaster, TimeSeriesFold\n",
    "\n",
    "print(f\"skforecast version: {skforecast.__version__}\")\n",
    "print(f\"xgboost    version: {xgboost.__version__}\")\n",
    "print(f\"lightgbm   version: {lightgbm.__version__}\")\n",
    "print(f\"catboost   version: {catboost.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7efc087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "NVIDIA T1200 Laptop GPU\n",
      "Memory Usage:\n",
      "Allocated : 0.0 GB\n",
      "Reserved  : 0.0 GB\n",
      "CPU RAM Free: 6.66 GB\n"
     ]
    }
   ],
   "source": [
    "# Print information abput the GPU and CPU\n",
    "# ==============================================================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated :', round(torch.cuda.memory_allocated(0) / 1024**3, 1), 'GB')\n",
    "    print('Reserved  :', round(torch.cuda.memory_reserved(0) / 1024**3, 1), 'GB')\n",
    "\n",
    "print(f\"CPU RAM Free: {psutil.virtual_memory().available / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2db9943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990-01-01 00:00:00    0.063534\n",
       "1990-01-01 01:00:00    1.382259\n",
       "Freq: h, Name: y, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "# ==============================================================================\n",
    "n = 1_000_000\n",
    "data = pd.Series(\n",
    "    data  = np.random.normal(size=n), \n",
    "    index = pd.date_range(start=\"1990-01-01\", periods=n, freq=\"h\"),\n",
    "    name  = 'y'\n",
    ")\n",
    "data.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "074ca42f",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05bc5e0",
   "metadata": {},
   "source": [
    "When creating the model with XGBoost version >= 2.0, two arguments are need to indicate XGBoost to run in GPU, if it available: `device='cuda'` and `tree_method='hist'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516970c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "# ==============================================================================\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Falling back to prediction using DMatrix due to mismatched devices.\",\n",
    "    category=FutureWarning,\n",
    "    module=\"xgboost.core\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaesc2/miniconda3/envs/skforecast_py12/lib/python3.12/site-packages/xgboost/core.py:729: UserWarning: [11:30:56] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time using GPU: 0 days 00:00:18.447855\n"
     ]
    }
   ],
   "source": [
    "# Create and train forecaster with a XGBRegressor using GPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = XGBRegressor(\n",
    "                                 n_estimators = 1000,\n",
    "                                 device       = 'cuda',\n",
    "                                 verbosity    = 1\n",
    "                             ),\n",
    "                 lags = 50\n",
    "             )\n",
    "\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.fit(y=data)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "\n",
    "print(f\"Training time using GPU: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time using CPU: 0 days 00:00:37.219092\n"
     ]
    }
   ],
   "source": [
    "# Create and train forecaster with a XGBRegressor using CPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = XGBRegressor(n_estimators=1000),\n",
    "                 lags      = 50\n",
    "             )\n",
    "\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.fit(y=data)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "\n",
    "print(f\"Training time using CPU: {elapsed_time}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a27b9011",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e6345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "# ==============================================================================\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\",\n",
    "    category=FutureWarning,\n",
    "    module=\"sklearn.utils.deprecation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ac583",
   "metadata": {},
   "source": [
    "When using **Google colab**, run the following in a notebook cell to ensure LightGBM can utilize the NVIDIA GPU when executing in google colab.\n",
    "\n",
    "```bash\n",
    "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da945f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time using GPU: 0 days 00:00:24.560819\n"
     ]
    }
   ],
   "source": [
    "# Create and train forecaster with a LGBMRegressor using GPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(n_estimators=1000, device='gpu', verbose=-1),\n",
    "                 lags      = 50\n",
    "             )\n",
    "\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.fit(y=data)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "\n",
    "print(f\"Training time using GPU: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acdbf58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time using CPU: 0 days 00:00:31.639930\n"
     ]
    }
   ],
   "source": [
    "# Create and train forecaster with a LGBMRegressor using CPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = LGBMRegressor(n_estimators=1000, device='cpu', verbose=-1),\n",
    "                 lags      = 50\n",
    "             )\n",
    "\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.fit(y=data)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "\n",
    "print(f\"Training time using CPU: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae97578",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7c2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time using GPU: 0 days 00:00:20.636049\n"
     ]
    }
   ],
   "source": [
    "# Create and train forecaster with a CatBoostRegressor using GPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = CatBoostRegressor(n_estimators=1000, task_type='GPU', silent=True, train_dir=None),\n",
    "                 lags      = 50\n",
    "             )\n",
    "\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.fit(y=data)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "\n",
    "print(f\"Training time using GPU: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab6127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time using CPU: 0 days 00:01:13.167325\n"
     ]
    }
   ],
   "source": [
    "# Create and train forecaster with a CatBoostRegressor using CPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                 regressor = CatBoostRegressor(n_estimators=1000, task_type='CPU', silent=True, train_dir=None),\n",
    "                 lags      = 50\n",
    "             )\n",
    "\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.fit(y=data)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "\n",
    "print(f\"Training time using CPU: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c103841e",
   "metadata": {},
   "source": [
    "## GPU vs CPU benchmark\n",
    "\n",
    "The performance advantage of using a GPU depends heavily on the specific task and the size of the dataset. Generally, GPU acceleration offers the greatest benefits when working with large datasets and complex models, where its parallel processing capabilities can significantly reduce training times.\n",
    "\n",
    "In recursive forecasting (`ForecasterRecursive`), the prediction phase must be executed sequentially—each time step depends on the previous prediction. This inherent dependency prevents parallelization during inference, which explains why model fitting is substantially faster on a GPU, while prediction can actually be slower compared to using a CPU.\n",
    "\n",
    "To strike a balance between training speed and prediction efficiency, a practical approach is to fit the model on the GPU and then switch the regressor to use the CPU for prediction by setting `device='cpu'`.\n",
    "\n",
    "For `ForecasterDirect`, however, there is no recursive dependency during prediction. As a result, both training and inference fully benefit from GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7cc742",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create and train forecaster with a XGBRegressor using GPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                regressor = XGBRegressor(\n",
    "                              n_estimators=1000,\n",
    "                              tree_method='hist',\n",
    "                              device=\"cuda\",\n",
    "                              verbosity=1\n",
    "                            ),\n",
    "                lags = 50\n",
    "             )\n",
    "\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.fit(y=data)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "\n",
    "print(f\"Training time using GPU: {elapsed_time}\")\n",
    "\n",
    "# Predict using GPU\n",
    "# ==============================================================================\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.predict(steps=100)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "print(f\"Prediction time using GPU: {elapsed_time}\")\n",
    "\n",
    "# Backtesting using GPU\n",
    "# ==============================================================================\n",
    "cv = TimeSeriesFold(\n",
    "         steps                 = 100,\n",
    "         initial_train_size    = 990_000,\n",
    "         refit                 = False,\n",
    "         verbose               = False\n",
    "     )\n",
    "start_time = pd.Timestamp.now()\n",
    "_ = backtesting_forecaster(\n",
    "        forecaster = forecaster,\n",
    "        y          = data,\n",
    "        cv         = cv,\n",
    "        metric     = 'mean_absolute_error'\n",
    "\n",
    "    )\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "print(f\"Backtesting time using GPU: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3a950",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create and train forecaster with a XGBRegressor using CPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                regressor = XGBRegressor(\n",
    "                              n_estimators=1000,\n",
    "                              tree_method='hist',\n",
    "                              device=\"cpu\",\n",
    "                              verbosity=1\n",
    "                            ),\n",
    "                lags = 50\n",
    "             )\n",
    "\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.fit(y=data)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "print(f\"Training time using CPU: {elapsed_time}\")\n",
    "\n",
    "# Predict using CPU\n",
    "# ==============================================================================\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.predict(steps=100)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "print(f\"Prediction time using CPU: {elapsed_time}\")\n",
    "\n",
    "# Backtesting using CPU\n",
    "# ==============================================================================\n",
    "cv = TimeSeriesFold(\n",
    "         steps                 = 100,\n",
    "         initial_train_size    = 990_000,\n",
    "         refit                 = False,\n",
    "         verbose               = False\n",
    "     )\n",
    "start_time = pd.Timestamp.now()\n",
    "_ = backtesting_forecaster(\n",
    "        forecaster = forecaster,\n",
    "        y          = data,\n",
    "        cv         = cv,\n",
    "        metric     = 'mean_absolute_error'\n",
    "\n",
    "    )\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "print(f\"Backtesting time using CPU: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e62f008",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create and train forecaster with a XGBRegressor using GPU\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterRecursive(\n",
    "                regressor = XGBRegressor(\n",
    "                              n_estimators=1000,\n",
    "                              tree_method='hist',\n",
    "                              device=\"cuda\",\n",
    "                              verbosity=1\n",
    "                            ),\n",
    "                lags = 50\n",
    "             )\n",
    "\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.fit(y=data)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "\n",
    "print(f\"Training time using GPU: {elapsed_time}\")\n",
    "\n",
    "# Predict using CPU\n",
    "# ==============================================================================\n",
    "forecaster.regressor.set_params(device='cpu')\n",
    "start_time = pd.Timestamp.now()\n",
    "forecaster.predict(steps=100)\n",
    "elapsed_time = pd.Timestamp.now() - start_time\n",
    "print(f\"Prediction time using CPU: {elapsed_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast_py11_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
